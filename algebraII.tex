\documentclass[12pt,a4paper]{scrartcl}

\usepackage{includes}
\usepackage{shortcuts}
\usepackage{numbering}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stroppel hat jetzt leider andere Nummerierungsvorlieben... %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlist[enumerate,1]{label=\textup{\arabic*)}}

\renewcommand{\thethmcounter}{\Roman{section}.\arabic{thmcounter}}

\counterwithout{thmcounter}{subsection}
\counterwithin{thmcounter}{section}
\counterwithin{subsection}{section}

\theoremstyle{cplain}
\newtheorem{cor}[thmcounter]{Corollary}
\crefname{cor}{Corollary}{Corollaries}

\theoremstyle{cplain}
\newtheorem{thm}[thmcounter]{Theorem}
\crefname{thm}{Theorem}{Theorems}

\theoremstyle{cplain}
\newtheorem{prop}[thmcounter]{Proposition}
\crefname{prop}{Proposition}{Propositions}

\theoremstyle{definition}
\newtheorem*{deff}{Definition}

% Römische Zahlen...
\setlength{\cftsecnumwidth}{1.3cm}

% Literatur
\usepackage[backend=biber,sorting=none,style=alphabetic]{biblatex}
\addbibresource{literatur.bib}

\title{Algebra II}
\subtitle{Winter Semester 2018/19}
\date{\lastcompiled}

\begin{document}
\begin{otherlanguage}{english}

\maketitle
\tableofcontents
\newpage

\noindent
These are notes of the lecture \enquote{Algebra II}, taught by Prof. Dr. Catharina Stroppel at the University of Bonn in the winter semester 2018/19.

\bigskip

\noindent
Lecture website:\\
\url{http://guests.mpim-bonn.mpg.de/enorton/alg2.html}

\nocite{hungerford}
\nocite{knapp-basic}
\nocite{knapp-advanced}
\nocite{procesi}
\nocite{borel}
\nocite{humphreys}
\nocite{springer}
\printbibliography

\newpage

\lecture{October 8, 2018}

\section{Group actions}
If $G$ is a group, denote by $e \in G$ the neutral element, by $g^{-1}$ the inverse of $g\in G$ and by $gh$ the composition $g \circ h$.
\begin{deff}
  Given a group $G$ and a set $X$, an \emph{action} of $G$ on $X$ is a map
  \begin{eqnarray*}
    G \times X &\to& X \\
    (g,x) &\mapsto& g.x
  \end{eqnarray*}
  such that
  \begin{description}
   \item[(A1)] $e.X = x$ and
   \item[(A2)] $(gh).x = g.(h.x)$
  \end{description}
  for all $x \in X$ and $g,h \in G$. We call then $X$ a \emph{$G$-set}.
\end{deff}
\begin{deff}
  Given a set $X$, define \[ S(X) := \set{f\colon X \to X \given f \text{ bijective}}, \] the \emph{symmetric group} of $X$ (with composition as group multiplication).
  
  Given a $G$-set $X$ and $g\in G$, let $\pi_g \in S(X)$ be defined as $\pi_g(x) = g.x$.
\end{deff}
\begin{lem}
  For any group $G$ and set $X$ we have a bijective correspondence
  \begin{eqnarray*}
    \set{\text{$G$-actions on $X$}} &\xlongleftrightarrow{1:1}& \set{\text{Group homomorphisms $G \to S(X)$}} \\
    \pi &\mapsto& \hat\pi = (g \mapsto (x \mapsto \pi(g,x) = g.x)) \\
    ((g,x)\mapsto \phi(g)(x))=\mathring \phi &\mapsfrom& \phi.
  \end{eqnarray*}
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\paragraph{Examples.}
Let $G$ be a group.
\begin{enumerate}
  \item $G$ acts on itself by
  \begin{itemize}
    \item left multiplication: $g.x = gx$ (left regular action)
    \item \enquote{right multiplication}: $g.x = xg^{-1}$ (right regular action)
    \item conjugation $g.x = gxg^{-1}$
  \end{itemize}
  \item Any set $X$ is a $G$-set via the \emph{trivial action} $g.x = x$.
  \item Let $X,Y$ be $G$-sets. then $G$ acts on $\Maps(X,Y) := \set{f\colon X\to Y}$ via $(g.f)(x) = g.(f(g^{-1}.x))$. Special case: the action $Y$ is trivial, then $(g.f)(x) = f(g^{-1}.x)$.
\end{enumerate}

\begin{deff}
  Let $X,Y$ be $G$-sets. A map $f\colon X\to Y$ is called \emph{$G$-equivariant} if $f(g.x) = g.f(x)$ for all $g\in G$ and $x \in X$. We write \[\Hom_G(X,Y) := \set{f\colon X\to Y \given \text{$f$ is $G$-equivariant}}.\]
\end{deff}
\begin{lem}
  Let $G$ be a group.
  \begin{enumerate}
    \item If $X$ is a $G$-set then $\id_X\in \Hom_G(X,X)$.
    \item If $X,Y,Z$ are $G$-sets, $f_1 \in \Hom_G(X,Y)$ and $f_2 \in \Hom_G(Y,Z)$ then $f_2 \circ f_1 \in \Hom_G(X,Z)$.
  \end{enumerate}
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\paragraph{Examples.}
Let $G$ be a group.
\begin{enumerate}
  \item If $G$ acts on itself by left multiplication then
  \begin{eqnarray*}
    \Hom_G(G,G) &\cong& G \quad\text{(as sets)} \\
    f &\mapsto& f(e) \\
    (x\mapsto xa) = m_a &\mapsfrom& a.
  \end{eqnarray*}
  \item If $X,Y$ are trivial $G$-sets then $\Hom_G(X,Y) = \Maps(X,Y)$.
\end{enumerate}

% TODO besseres Symbol für Menge der Orbits
\begin{deff}
  Let $X$ be a $G$-set. For $x\in X$ let $G_x = \set{g.x \given g \in G}$ be the \emph{orbit} of $x$. We write \[ \orbits GX := \set{G_x \given x \in X}.\]
\end{deff}
\medskip
Note that $G_x = G_y$ iff $y \in G_x$.

\paragraph{Remark.}
We can view $\orbits GX$ as a $G$-set via the trivial action. Then $\can\colon X \to \orbits GX,x \mapsto G_x$ is $G$-equivariant.

\begin{deff}
  Let $X$ be a $G$-set. Then \[X^G := \set{x \in X \given \forall g\in G: g.x = x}\] is the \emph{set of $G$-fixed points} or \emph{$G$-invariants} in $X$.
\end{deff}
\begin{lem}
  Let $X,Y$ be $G$-sets and $f\in \Hom_G(X,Y)$. Then, $f(X^G) \subseteq Y^G$.
\end{lem}
\begin{proof}
  Let $x\in X^G$. For all $g\in G$, we have $g.f(x) = f(g.x) = f(x)$. Therefore, $f(x) \in Y^G$.
\end{proof}

\medskip
Thus, $f$ induces a map $f^G\colon X^G \to Y^G$ by restriction.

\begin{lem}
  Let $G$ be a group.
  \begin{enumerate}
    \item If $X$ is a $G$-set then $\id_X^G = \id_{X^G}$.
    \item If $X,Y,Z$ are $G$-sets, and $f_1 \in \Hom_G(X,Y)$ and $f_2\in \Hom_G(Y,Z)$ then $(f_2\circ f_1)^G = f_2^G \circ f_1^G$.
  \end{enumerate}
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}
\begin{lem}
  Let $X,Y$ be $G$-sets. Then $\Hom_G(X,Y) = \Maps(X,Y)^G$.
\end{lem}
\begin{proof}
  $f \in \Hom_G(X,Y) \Leftrightarrow \forall g\in G,x \in X: f(g.x) = g.f(x) \Leftrightarrow \forall g\in G,x \in X:g^{-1}.f(g.x) = g^{-1}.(g.f(x)) = f(x) \Leftrightarrow \forall g\in G,x \in X: g.f(g^{-1}.x) = f(x) \Leftrightarrow f\in \Maps(X,Y)^G$.
\end{proof}
\begin{deff}
  Let $X$ be a $G$ set and $k$ a field. A map $f\colon X\to k $ is \emph{$G$-invariant} if $f(g.x) = f(x)$ for all $g \in G$ and $x\in X$.
\end{deff}

\paragraph{Example.}
Let $G= \fak\IZ{2\IZ} = \set{e,s}$ and $k=\IR$. Let $G$ act on $\IR$ by $s.\lambda = -\lambda$. Any polynomial $p(t) \in \IR[t]$ can be viewed as an element in $\Maps(\IR,\IR)$. Then $p(t) = \sum a_it^i$ is $G$-invariant iff $p(t)$ is even (i.e. $a_i=0$ for odd $i$).
\begin{proof}
  \begin{align*}
    \qedherea
    &\phantom{{}\Leftrightarrow{}}\quad \text{$p(t)$ is $G$-invariant} \\
    &\Leftrightarrow\quad \forall \lambda \in \IR: p(s.\lambda) = p(\lambda) \\
    &\Leftrightarrow\quad \forall \lambda \in \IR: p(-\lambda) = p(\lambda) \\
    &\Leftrightarrow\quad \forall \lambda \in \IR: \sum_i (-1)^ia_i \lambda^i = \sum_i a_i \lambda^i \\
    &\Leftrightarrow\quad \forall \lambda \in \IR: 2 \sum_{\text{$i$ odd}} a_i\lambda^i = 0 \\
    &\Leftrightarrow\quad \text{$a_i=0$ for all odd $i$}
    \qedhere
  \end{align*}
\end{proof}

\paragraph{Remark.}
$f\colon X \to k$ is $G$-invariant iff $f\in \Maps(X,k)^G$ where we have trivial $G$-action on $k$.

\begin{lem}[Universal property of invariant maps]
  Let $X$ be a $G$-set, $k$ a field (or a commutative ring with $1$). Then $f\colon X \to k$ is $G$-invariant iff $f$ factors through $\can$ (i.e. $\exists! \ol f\colon \orbits GX \to k$ such that $f = \ol f \circ \can$).
  \begin{center}
    \begin{tikzcd}
      X \arrow{r}{f} \arrow[swap]{d}{\can} & k \\
      \orbits GX \arrow[dashed,swap]{ru}{\exists!\ol f}
    \end{tikzcd}
  \end{center}
\end{lem}
\begin{proof}
  \begin{align*}
    \qedherea
    &\phantom{{}\Leftrightarrow{}}\quad \text{$f$ is $G$-invariant} \\
    &\Leftrightarrow\quad \forall g\in G, x \in X : f(g.x) = f(x) \\
    &\Leftrightarrow\quad \text{$f$ is constant on orbits} \\
    &\Leftrightarrow\quad \text{$\ol f$ exists (namely $\ol f(G_x) = f(x)$, obviously unique)}
    \qedhere
  \end{align*}
\end{proof}
\begin{lem} \label{lem:I.7}
  Let $X$ be a finite $G$-set and $k$ a field (or commutative ring with $1$). Then:
  \begin{enumerate}
    \item\label{lem:I.7:1} $\Maps(X,k)$ is a $k$-vector space (or $k$-module) with pointwise addition and scalar multiplication.
    \item\label{lem:I.7:2} A $k$-basis of $\Maps(X,k)$ is given by \[ \Xs_x\colon y \mapsto \begin{cases*} 1 & if $x = y$ \\ 0 & otherwise \end{cases*}\] where $x \in X$.
    \item\label{lem:I.7:3} $\Maps(X,k)^G$ forms a subspace (or submodule) with basis \[ \Xs_\Gs \colon y \mapsto \begin{cases*} 1 & if $y \in \Gs$ \\ 0 & otherwise \end{cases*} \] where $\Gs \in \orbits GX$.
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:I.7:\arabic*}]
    \item Clear.
    \item \begin{description}
            \item[Generating system:] Let $f \in \Maps(X,k)$. Then $f= \sum_{x\in X}f(x)\Xs_x$, as we have $\sum_{x\in X}f(x)\Xs_x(y) = f(y)$ for all $y \in X$.
            \item[Linear independence:] Let $\sum_{x \in X} a_x\Xs_x = 0$ for some $a_x \in k$. Thus, $\sum_{x \in X} a_x\Xs_x(y) = 0$ for all $y \in X$, and we have $a_y = 0$ for all $y \in X$.
          \end{description}
    \item \begin{description}
            \item[Generating system:] Let $f \in \Maps(X,k)^G$. Hence, $f$ is constant on orbits, and we have $f = \sum_{\Gs \in \orbits GX} a_\Gs \Xs_\Gs$ with $a_\Gs = f(x)$ for $x \in \Gs$.
            \item[Linear independence:] As in \ref{lem:I.7:2}.
            \qedhere
          \end{description}
  \end{enumerate}
\end{proof}

If $X$ is an infinite set we often replace $\Maps(X,k)$ by \[kX := \set{f\colon X \to k \given \text{$\supp f$ is finite}} \] where $\supp f := \set{ x \in X \given f(x) \neq 0}$ is the \emph{support} of $f$.

\paragraph{Note.}
We have
\begin{align*}
  \supp(f_1+f_2) &\subseteq \supp f_1 \cup \supp f_2, \\
  \supp(\lambda f) &\subseteq \supp f
\end{align*}
for all $f_1,f_2,f\in \Maps(X,k)$ and $\lambda \in k\setminus \set0$. Thus, $kX \subseteq \Maps(X,k)$ together with the $0$-function is a vector space (usually just call it $kX$ as well).

$kX$ is preserved under $G$-action. Let $f \in kX, g \in G$. Then 
\begin{align*}
  &\phantom{{}\Leftrightarrow{}}\quad (g.f)(x) \neq 0 \\
  &\Leftrightarrow\quad f(g^{-1} .x ) \neq 0 \\
  &\Leftrightarrow\quad g^{-1}.x \in \supp f\\
  &\Leftrightarrow\quad x \in \underbrace{\set{g.y \given y \in \supp f}}_{\text{finite}}.
\end{align*}

\cref{lem:I.7} generalizes to $kX$.

\begin{lem} \label{lem:I.8}
  Let $G$ be a group and $R$ a ring. Let $G$ act on $R$ by ring homomorphisms (i.e. if $\pi\colon R \to R$ is the action then $\pi_g\colon R\to R$ is a ring homomorphism for all $g\in G$) then $R^G$ is a subring of $R$.
\end{lem}
\begin{proof}
  Let $r_1,r_2 \in R^G$. To show: $r_1+r_2,r_1r_2 \in R^G$. For $g \in G$ we have $g.(r_1+r_2) = \pi_g(r_1+r_2) = \pi_g(r_1) + \pi_g(r_2) = g.r_1 + g.r_2 = r_1+r_2$. Similarly, $g.(r_1r_2) = r_1r_2$.
\end{proof}

\paragraph{Example.} Even polynomials form a subring of $\IR[t]$.

\begin{deff}
  If $G,H$ are groups and $X$ a $G$-set and an $H$-set then the two actions \emph{commute} if \[g.(h.x) = h.(g.x)\] for all $g\in G$, $h\in H$ and $x \in X$.
\end{deff}

\lecture{October 11, 2018}

\section{Representations of groups}
\begin{deff}
  Let $G$ be a group, $V$ a $k$-vector space and $G\times V \to V$ an action. This action is \emph{linear} if $\pi_g\colon V\to V$ is a linear map for all $g\in G$. Then $V$ is called a \emph{$G$-space} or a \emph{representation} of $G$.
\end{deff}

\paragraph{Example.} If $V$ is a $k$-vector space then $\GL(V)$ acts linearly on $V$ by $g.v = g(v)$ for all $g \in \GL(V)$ and $v\in V$. We call this the \emph{standard representation}.

\paragraph{Remark.}
We have a bijection
\begin{eqnarray*}
  \set{\text{linear $G$-actions on $V$}} &\xleftrightarrow{1:1}& \set{\text{group homomorphisms $G \to \GL(V)$}}, \\
  \pi &\mapsto& (g \mapsto \pi_g).
\end{eqnarray*}

\paragraph{Examples.}
\begin{enumerate}
  \item Let $X$ be a $G$-set. Then $kX$ is a representation (the \emph{regular representation} of $kX$) of $G$ via \[ g.\pa{\sum_{x\in X} a_x \Xs_x} = \sum_{x \in X} a_x \Xs_{g.x}. \]
  \item Let $V$ and $W$ be representations of $G$ over $K$. Then the $G$-action on $\Maps(V,W)$ induces a $G$-action on $\Hom_k(V,W) = \set{f\colon V\to W \given \text{$f$ $k$-linear}}$.
  \item Let $V$ and $W$ be representations of $G$ over $k$. Then $V \oplus W$ and $V\tp W$ are representations of $G$, called direct sum and tensor product via $g.(v,w) = (g.v,g.w)$ and $g.(v\tp w) = (g.v)\tp (g.w)$ extended linearly.
\end{enumerate}

\begin{deff}
  Let $V$ be a representation of $G$ over $k$.
  \begin{itemize}
    \item A \emph{subrepresentation} of $V$ is a vector subspace $U$ of $V$ such that $g.u \in U$ for all $g \in G$ and $u \in U$. It is \emph{proper} if $0 \neq U \neq V$.
    \item $V$ is \emph{irreducible} if $V\neq 0$ and there is no proper subrepresentation.
    \item $V$ is \emph{indecomposable} if it cannot be written as a decomposition $V=U_1 \oplus U_2$ such that $U_1$ and $U_2$ are proper subrepresentations.
    \item $V$ is \emph{completely reducible} if $V = \sum_{i \in I} V_i$ where $V_i$ are irreducible subrepresentations (for some set $I$).
  \end{itemize}
\end{deff}

\paragraph{Example.}
Let \[ G = \set*{\begin{pmatrix}a&b\\0&c\end{pmatrix} \given a,b,c \in \IC, a,c \neq 0 } \] act on $V = \IC^2$ by standard action. Then $U = \gen{\begin{pmatrix}1\\0\end{pmatrix}}$ is a proper subrepresentation of $V$, but $V$ is not irreducible. But $V$ is indecomposable since $U$ is the unique proper subrepresentation. To see this, assume $U' = \gen{\begin{pmatrix}x\\y\end{pmatrix}}$ to be a proper subrepresentation. Then \[ \begin{pmatrix}1&1\\0&1\end{pmatrix} \begin{pmatrix}x\\y\end{pmatrix} = \begin{pmatrix}x+y\\y\end{pmatrix} \in U', \] and as $U'$ is a subspace, we have $\begin{pmatrix}y\\0\end{pmatrix} \in U'$ and therefore $U' = U$. $V$ is also not completely irreducible.

\begin{deff}
  Let $G$ be a group and $k$ a field. The group algebra of $G$ over $k$ is the $k$-algebra given by the $k$-vector space \[ kG = \set{f \colon G \to k \given \text{$\supp f$ is finite}} \] with multiplication given by convolution of functions \[ (f_1\cdot f_2)(x) = \sum_{y \in G} f_1(y)f_2(y^{-1}x) \] with unit $1 = \Xs_e$.
\end{deff}
Indeed, we have
\begin{align*}
  (f\cdot \Xs_e)(x) &= \sum_{y \in G} f(y) \underbrace{\Xs_e(y^{-1}x)}_{\mathclap{\text{nonzero iff $y = x$}}} = f(x)  &&\text{and}
  &(\Xs_e \cdot f)(x) &= \sum_{y \in G} \underbrace{\Xs_e(y)}_{\mathclap{\text{nonzero iff $y = 1$}}}f(y^{-1}x) = f(x)
\end{align*}
for all $f \in kG$. It remains to check associativity and distributivity.

\paragraph{Remark.} The group algebra can be defined in the same way over any commutative ring with $1$. We write \[ \sum_{g \in G} a_g g := \sum_{g \in G} a_g \Xs_g \] where $a_g \in k$ and almost all $a_g = 0$.

\begin{lem}
  The algebra structure on $kG$ is given by extending the multiplication on $G$ bilinearly.
\end{lem}
\begin{proof}
  We have \[ (\Xs_g \cdot \Xs_h) (x) = \sum_{y \in G} \Xs_g(y) \Xs_h(y^{-1}x) = \begin{cases*}
                                                                                  1 & if $h = g^{-1}x$ \\
                                                                                  0 & otherwise
                                                                                \end{cases*} = \Xs_{gh}(x). \]
  By definition the convolution product extends this bilinearly.
\end{proof}

\paragraph{Note.} $kG$ is commutative iff $G$ is abelian.

\begin{lem} \label{lem:II.2}
  Let $G$ be a group and $V$ a $k$-vector space. Then
  \begin{eqnarray*}
    \set{\text{linear $G$-actions on $V$}} &\xleftrightarrow{1:1}& \set{\text{$kG$-module structures on $V$}}, \\
    (G \times V \to V) &\mapsto& \pa{\pa{\sum_{g\in G} a_g g}.v := \sum_{g\in G} a_g (g.v)}.
  \end{eqnarray*}
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{deff}
  Let $V$ and $W$ be representations of $G$ over $k$. A \emph{morphism} (of representations) from $V$ to $W$ si a linear, $G$-equivariant map $f\colon V\to W$. Denote $\Hom_G(V,W) := \set{f \colon V \to W \text{ morphisms of representations}}$ and $\End_G(V) := \Hom_G(V,V)$.
\end{deff}

\paragraph{Note.} $\Hom_G(V,W)$ is a vector space. Write $V \cong W$ if there exists an isomorphism $V \to W$.

\begin{lem}
  Let $G$ be a group and $k$ a field. Representations of $G$ over $k$ together with morphisms of representations  form a category $\Rep_k(G)$.
\end{lem}
\begin{proof}
  See \cref{lem:II.2}.
\end{proof}

\paragraph{Example.} For a field $k$, the $k$-vector spaces together with $k$-linear maps form a category $\Vect_k$.

\begin{cor}
  Let $k$ be a field. The assignments
  \begin{eqnarray*}
    F \colon \Rep_k(G) &\to& \Vect_k\\
    V &\mapsto& V^G \\
    f &\mapsto& f^G\colon V^G \to W^G
  \end{eqnarray*}
  define a functor from $\Rep_k(G)$ to $\Vect_k$, the functor of $G$-invariants.
\end{cor}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{lem} \label{lem:II.5}
  If $f\colon V \to W$ is a morphism of representations of $G$ then $\ker f$ and $\im f$ are subrepresentations of $V$ respectively $W$.
\end{lem}
\begin{proof}
  $\ker f$ and $\im f $ are subspaces since $f$ is linear. Let $g \in G$ and $x \in\ker f$. Then $f(g.x) = g.f(x) = g.0 = 0$ and $g.x \in \ker f$, thus $\ker f $ is a subrepresentation.
  
  Let $y \im f$ and $x \in V$ with $f(x) = y$. We get $g.y = g.(f(x)) = f(g.x) \im f$.
\end{proof}

\paragraph{Remark.} It can be shown that $\Rep_k(G)$ is an abelian category.

\begin{lem}[Schur's lemma] \label{lem:schur}
  Let $G$ be a group and $V,W$ irreducible representations of $G$ over $k$.
  \begin{enumerate}
    \item\label{lem:schur:1} $\Hom_G(V,W) = 0$ if $V \ncong W$. If $V \cong W$, we have $\Hom_G(V,W) \neq 0 $ and every non-zero morphism is an isomorphism.
    \item\label{lem:schur:2} If $k = \ol k$ and $V$ and $W$ are finite-dimensional then \[ \Hom_G(V,W) \cong \begin{cases*}
                                                                                            k & if $V \cong W$ \\
                                                                                            0 & if $V \ncong W$
                                                                                          \end{cases*} \]
    as representations.
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:schur:\arabic*}]
    \item Assume $V \cong W$ and $0\neq f \in \Hom_G(V,W)$. This implies $\ker f \neq V$ and $\im F \neq 0$. By \cref{lem:II.5} it follows $\ker f = 0$ and $\im f = W$, since $f$ is a morphism and $V$ and $W$ are irreducible. As $f$ is linear, $f$ is an isomorphism.
    \item Assume $V \cong W$ and $0\neq \alpha,\beta \in \Hom_G(V,W)$. It is enough to show $\beta = \lambda\alpha$ for some $\lambda \in k$. By \ref{lem:schur:1} $\alpha$ has an inverse $\alpha^{-1}$ (which is again a morphism) and we have $\alpha^{-1}\circ\beta \in \End_G(V)$. If $k=\ol k$ and $V$ is finite-dimensional $\alpha^{-1}\circ\beta$ has eigenvectors. We define $K := \ker(\alpha^{-1}\circ\beta -\lambda\id_V) \neq 0$ for some $\lambda \in k$. Now $\alpha^{-1}\circ\beta - \lambda \id_v \in \End_G(V)$ (the reader may check this statement), thus $K$ is a subrepresentation of $V$, hence $K=V$, since $V$ is irreducible and $K \neq 0$. Therefore, $\alpha^{-1}\circ\beta = \lambda\id_V$ and $\beta = \lambda \alpha$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{cor}
  Let $k=\ol k$ and $V_i$ ($1 \le i \le r$) be pairwise non-isomorphic irreducible finite-dimensional representations of $G$ over $k$. Let $W_i := V_i^{\oplus n_i} := V_i \oplus \ldots \oplus V_i$ for some $n_i \in \Z_{>0}$ (a representation of $G$). Then \[ \End_G(W_1 \oplus \ldots \oplus W_r) \cong \M_{n_1\times n_1}(k) \oplus \ldots \oplus M_{n_r \times n_r}(k) \] as algebras.
\end{cor}
\begin{proof}
  We have
  \begin{align*}
    \End_G(W_1\oplus \ldots\oplus W_r) &= \Hom_G\pa{\bigoplus_{i=1}^r\bigoplus_{j=1}^{n_i} V_i,\bigoplus_{i=1}^r\bigoplus_{j=1}^{n_i} V_i } \\
    \intertext{and by \namereff{lem:schur}, since $V_i \cong V_i$, and $\End_G(V_i)\cong k$, we get}
    &\cong \End_G(V_1^{\oplus n_1}) \oplus \ldots \oplus \End_G(V_r^{\oplus n_r})\\ & \cong \M_{n_1\times n_1}(k) \oplus \ldots \oplus M_{n_r \times n_r}(k).
    \qedhere
  \end{align*}
\end{proof}

\lecture{October 15, 2018}

\begin{thm}[Maschke's theorem] \label{thm:maschke}
  Let $G$ be a finite group and $k$ a field such that $\chr k \nmid \abs G$ (in particular $\chr k = 0$ is allowed). The the finite-dimensional representations of $G$ over $k$ are completely reducible.
\end{thm}
\begin{proof}
  It is enough to show that for any finite-dimensional representation $V$ of $G$ the following holds: any subrepresentation $U$ of $V$ has a complement in $W$ in $V$ which is again a subrepresentation; so $V = U \oplus W$ as representations. Let $U$ be such a subrepresentation and choose a vector space complement $U'$ so $V = U \oplus U'$ as vector spaces.
  
  Define now $\hat p\colon V \to U $ by \[ \hat p(v) = \frac1{\abs G} \sum_{g \in G}\underbrace{g^{-1}.\underbrace{p(g.v)}_{\in U}}_{\in U} \in U. \]
  Now:
  \begin{itemize}
    \item We have ${\displaystyle\hat p(u) = \frac1{\abs G} \sum_{g\in G} g^{-1} .p(g.h.v) = \frac1{\abs G}\sum_{g \in G}g^{-1}.g.u = u }$ for all $u\in U$.
    \item $\hat p$ is $G$-equivariant, as for any $h\in G$ and $v\in V$
    \begin{align*}
      \hat p(h.v) &= \frac1{\abs G} \sum_{g \in G}g^{-1}.p(g.h.v) = \frac1{\abs G} \sum_{g\in G} h.(h^{-1}.(g^{-1}.p(g.h.v)) \\
      &= h.\pa{\frac1{\abs G} \sum_{g \in G} (gh)^{-1}.p((gh).v)} = h.\pa{\frac1{\abs G} \sum_{g \in G} g^{-1}.p(g.v)} = h.\hat p(v).
    \end{align*}
  \end{itemize}
  Therefore, $V = \im \hat p \oplus \ker \hat p = U \oplus \ker \hat p$ since $\hat p$ is $G$-equivariant. $W := \ker \hat p$ is a subrepresentation of $V$.
\end{proof}
\paragraph{Warning.}
\namereff{thm:maschke} does not hold in general if $\chr k \mid \abs G$. For example, take $G = \fak \IZ{2\IZ} = \set{e,s}$, $k = \IF_2$ and $V = kG$ the regular representation. Then $\gen{e+s}_k$ is a $1$-dimensional subrepresentation, but in fact the unique one. Therefore, it has no complement. (Note: if $\chr k \neq 2$ then $\gen{e+s}_k$ is also a $1$-dimensional subrepresentation and a complement of the above one).

\section{Invariant polynomial functions}

\subsection{Gradings and filtrations}
\begin{deff}
  Let $A$ be a $k$-algebra. A \emph{grading} (or \emph{$\IZ$-grading}) on $A$ is a decomposition \[ A = \bigoplus_{i\in IZ} A_i\] into vector subspaces $A_i$ such that $A_iA_j \subseteq A_{i+j}$ for all $i,j\in \IZ$. We call then $A$ a \emph{graded algebra}. The $A_i$ ($i \in \IZ$) are the \emph{graded} (or \emph{homogeneous}) \emph{components}. An element $a_i \in A_i$ is called \emph{homogeneous} (of degree $i$).
\end{deff}
\begin{deff}
  A \emph{grading} of a ring $R$ is a decomposition $R = \bigoplus_{i \in \IZ} R_i$ into $\IZ$-modules such that $R_iR_j \subseteq R_{i+j}$ for all $i,j\in \IZ$. We call then $R$ a \emph{graded} ring and the $R_i$ the \emph{graded}/\emph{homogeneous components}.
\end{deff}

\begin{lem}
  Let $k$ be a field and $A$ a $k$-algebra with $1$.
  \[ A = \bigoplus_{i \in \IZ} A_i\text{ is a graded algebra.} \quad \Longleftrightarrow \quad A = \bigoplus_{i \in \IZ} A_i \text{ is a graded ring and $k1 \subseteq A_0$.} \]
\end{lem}
\begin{proof}
  \leavevmode
  \begin{description}
    \item[\enquote{$\Leftarrow$}] $A= \bigoplus _{ i\in\IZ}A_i$ is a decomposition into $k$-vector spaces; in particular into $\IZ$-modules. We have to show $k1 \subseteq A_0$.
    
    Write $1 = \sum_{i \in \IZ} e_i$ with $e_i \in A_i$ and almost all $e_i=0$. Then for any $a \in A_j$ we have $a = a1 = \sum_{i \in \IZ}ae_i$. As $ae_i\in A_{j+i}$, we have $a = ae_0$ because the sum $A=\bigoplus_{i \in \IZ}A_i$ is direct. Similarly we get $e_0a = a$. Thus, $e_0 = a = ae_0$ for all $a\in A$, and we have $1 = e_0 \in A_0$ and finally $k1 = ke_0 \subseteq A_0$ since $A_0$ is a vector space.
    \item[\enquote{$\Rightarrow$}] We have to show that $A_i$ is closed under scalar multiplication for all $i \in \IZ$. Let $\lambda \in k$ and $i\in \IZ$. Then $\lambda A_i = (\lambda1)A_i \subseteq A_0A_i \subseteq A_{0+i} = A_i$.
    \qedhere
  \end{description}
\end{proof}

\paragraph{Examples.}
\begin{enumerate}
  \item Let $A$ be any $k$-algebra. It is a graded algebra via the \enquote{stupid grading} $A = \bigoplus_{i \in \IZ} A_i$ where \[ A_i = \begin{cases*}
                                 A & if $i=0$, \\
                                 0 & if $i \neq 0$.
                               \end{cases*} \]
  \item Let $R= \IZ$ or $R = k$ for a field. Then $A= R[X_1,\ldots,X_n]$ is a graded ring respectively a graded algebra where $A= \sum_{i \in \IZ} A_i$ is given by \[ A_i = \begin{cases*}
                                                                 0 & if $i<0$, \\
                                                                 \gen{\set*{X_1^{a_1}\cdots X_n^{a_n} \given \sum_{j=1}^n a_j =i}}_R & else,
                                                               \end{cases*} \]
  because clearly the monomials $X_1^{a_1}\cdots X_n^{a_n}$ with $a_i \in \IZ_{\ge0}$ (and by convention $X_1^0\cdots X_n^0=1$) form an $R$-basis of $R[X_1,\ldots,X_n]$ and $(X_1^{a_1}\cdots X_n^{a_n})(X_1^{b_1}\cdots X_n^{b_n}) = (X_1^{a_1+b_1}\cdots X_n^{a_n+b_n})$, so that $a_ia_j \in A_{i+j}$ for all basis elements $a_i \in A_i$ and $a_j \in A_j$ (then also $A_iA_j \subseteq A_{i+j}$).
  \item Let $V$ be a $k$-vector space. Consider the vector space \[ \T(V) := k \oplus V \oplus (V \tp V) \oplus \ldots = k \oplus \bigoplus_{d\ge1} V^{\tp d} =: \bigoplus_{d \ge 0} V^{\tp d}, \] the \emph{tensor algebra}.
  We claim that $\T(V)$ is an algebra by setting \[ (\underbrace{v_{i_1} \tp \ldots \tp v_{i_d}}_{\in V^{\tp d}})(\underbrace{v_{j_1} \tp \ldots \tp v_{j_{d'}}}_{\in V^{\tp d'}}) = \underbrace{v_{i_1} \tp \ldots \tp v_{i_d} \tp v_{j_1} \tp \ldots \tp v_{j_{d'}}}_{\in V^{\tp (d+d')}} \] for any $v_{i_r}, v_{j_s}$ in a chosen basis $\set{v_i \given i \in I}$ of $V$ ($1 \le r \le d$, $1 \le s \le d'$) and extended linearly to $\T(V)$ with \begin{align*} \underbrace{\lambda}_{\in V^{\tp 0}} \cdot \underbrace{v}_{\in V^{\tp d}} & := \underbrace{\lambda v}_{\in V^{\tp d}} &&\text{and} & \underbrace{v}_{\in V^{\tp d}} \cdot \underbrace{\lambda}_{\in V^{\tp 0}} & := \underbrace{\lambda v}_{\in V^{\tp d}} . \end{align*}
  
  We also claim that $\T(V) = \bigoplus_{i \in \IZ} \T(V)_i$ with \[ \T(V)_i := \begin{cases*}
                                                                                 V^{\tp i} & if $i \ge 0$ \\
                                                                                 0 & otherwise
                                                                               \end{cases*} \]
  is then a graded algebra.
\end{enumerate}

\begin{deff}
  Let $A$ be a $k$-algebra. A \emph{filtration} of $A$ is a (possibly infinite) sequence $F_\bullet(A)$ of vector subspaces of the form \[ 0 = F_{-1}(A) \subseteq F_0(A) \subseteq F_1(A) \subseteq \ldots \subseteq A \] such that
  \begin{enumerate}
    \item\label{def:filtered algebra:1} $F_i(A)F_j(A) \subseteq F_{i+j}(A)$ for all $i,j \in \IZ_{\ge -1}$ and
    \item\label{def:filtered algebra:2} $\displaystyle \bigcup_{i \ge -1} F_i(A) = A$.
  \end{enumerate}
  An algebra with a filtration is a \emph{filtered} algebra.
\end{deff}

\begin{prop}
  If $A$ is a filtered algebra with filtration $F_\bullet (A)$ then we can consider the vector space \[ \gr A := \bigoplus_{i \in \IZ} (\gr A)_i \quad\text{where}\quad (\gr A)_i = \begin{cases*}
                                                                          \fak{F_i(A)}{F_{i-1}(A)} & if $i \ge 0$, \\
                                                                          0 & if $i<0$.
                                                                        \end{cases*} \]
  Then $\gr A$ becomes a graded algebra by defining the multiplication \[ (a + F_{i-1}(A))(b+F_{j-1}(A)) := ab + F_{i+j-1}(A) \] for any $a \in F_i(A)$ and $b \in F_j(A)$. It is called the \emph{associated graded algebra} to the filtered algebra $(A,F_\bullet(A))$.
\end{prop}
\begin{proof}
  We have to show that the multiplication is well-defined. Note that we have
  \begin{alignat*}{2}
    F_{i-1}(A) b &\subseteq F_{i-1}(A)F_j(A) &&\subseteq F_{i+j-1}(A), \\
    aF_{j-1}(A) &\subseteq F_i(A)F_{j-1}(A)  &&\subseteq F_{i+j-1}(A), \\
    F_{i-1}(A) F_{j-1}(A) & \subseteq F_{i+j-2}(A) && \subseteq F_{i+j-1}(A).
  \end{alignat*}
  Therefore, we have \[(a + F_{i-1}(A))(b+F_{j}(A))=(c + F_{i-1}(A))(d+F_{j}(A))\] if $a+F_{i-1}(A) = c+F_{i-1}(A)$ in $\fak{F_{i+j}(A)}{F_{i+j-1}(A)}$ and $b+F_j(A) = d+F_j(A)$ for all $a,c \in F_j(A)$ and $b,d \in F_j(A)$.
  
  Associativity and distributivity follow from the same properties in $A$.
\end{proof}

\begin{prop}
  Let $A = \bigoplus_{i \in \IZ}A_i$ be a graded algebra such that $A_i = 0$ for $i <0$. Then define \[ F_j(A) = \bigoplus_{\mathclap{0\le i \le j}} A_i \] for all $j \ge 0$. Then \begin{equation} 0 =: F_{-1}(A) \subseteq F_0(A) \subseteq F_1(A) \subseteq \ldots \subseteq A \tag{*}\label{prop:III.3:eq} \end{equation} turns into a filtered algebra.
\end{prop}
\begin{proof}
  Obviously $F_j(A) \subseteq A$ are vector subspaces for all $j \ge -1$ and \eqref{prop:III.3:eq} is a sequence of nested vector spaces.
  \begin{enumerate}
    \item[\ref{def:filtered algebra:2}] Any $a \in A$ can be written as $a = \sum_{i=0}^\infty a_i$ with $a_i \in A_i$ where almost all $a_i = 0$. There exists $j>0$ such that $a \in F_j(A)$ and we have \[ A \subseteq \bigcup_{j \ge -1} F_j(A). \]
    \item[\ref{def:filtered algebra:1}] Let $A \in F_r(A)$ and $b \in F_s(A)$. We can write $a = \sum_{i=1}^r a_i$ and $b = \sum_{i=1}^sb_i$ for some $a_i,b_i \in A_i$. Thus we get \begin{align*} ab \in \sum_{{\substack{0\le i \le r\\0\le j \le s}}} \underbrace{a_ib_j}_{A_{i+j}} \in \bigoplus_{l=0}^{r+s}A_l = F_{r+s}(A). \qedhereb \end{align*}
  \end{enumerate}
\end{proof}

\paragraph{Remark.}
At this point Professor Stroppel seems not to have numbered this proposition in her notes. Therefore, the next Lemma will have the same number.
\addtocounter{thmcounter}{-1}

\paragraph{Examples.}
\begin{enumerate}
  \item Let $R = \IZ$ or $R=k$ a field. Consider $A=R[X_1,\ldots,X_n]$. This is a filtered algebra by setting \[ F_j(A) = \gen{\set*{X_1^{a_1}\cdots X_n^{a_n} \given \sum_{i=1}^na_i = j}}_R \] for $j\ge 0$ ($F_{-1}(A) = 0$).
  \item Let $R=k[t]$ for any field $k$. Consider $\End_k(k[t])$ (linear endomorphisms). There are the two following interesting elements in $\End_k(k[t])$:
  \begin{xalignat*}{2}
    X\colon k[t] &\to k[t] & \qquad \partial\colon k[t] &\to k[t] \\
    p & \mapsto tp & \qquad p &\mapsto p' := \text{formal derivation}
  \end{xalignat*}
  Let $A$ be the subalgebra of $\End_k(k[t])$ generated by $X$ and $\partial$. This is called the (first) \emph{Weyl algebra} $\As_1$.
  
  We claim that $A$ has basis $\set{X^a\partial^b \given a,b \in \IZ_{\ge 0}}$ (with $X^0\partial^0 = 1$). The reader may check this using the formula $\partial X = X\partial + \id$. Furthermore, one can define a filtration on $A$ via $F_j(A) = \gen{\set{X^a\partial^b \given a+b \le j}}$ for $j \ge 0$.
\end{enumerate}

\lecture{October 18, 2018}

\paragraph{Remark.}
For $(A,F_\bullet(A))$ a filtered algebra the canonical map
\begin{eqnarray*}
  \can\colon A &\to& \gr A = \bigoplus_{i\ge0}\fak{F_i(A)}{F_{i-1}(A)} \\
  a &\mapsto& (a+F_{i-1}(A))_{i\ge0}
\end{eqnarray*}
is in general \emph{not} an algebra homomorphism.

\begin{deff}
  Let $A = \bigoplus_{i\in\IZ} A_i$ be a graded algebra and $M$ and $A$-module. Then a \emph{grading} on $M$ is a decomposition $M=\bigoplus_{i\in\IZ}M_i$ into vector spaces such that $A_iM_j \subseteq M_{i+j}$ for all $i,j\in \IZ$. Then $M$ is called a \emph{graded} module.
  
  For graded $A$-modules $M=\bigoplus_{i\in\IZ}M_i$ and $N=\bigoplus_{i\in\IZ}N_i$, a morphism of graded $A$-modules from $M$ to $N$ is a morphism $f\colon M \to N$ of $A$-modules such that $f(M_i)\subseteq N_i$ for all $i\in\IZ$.
\end{deff}

\paragraph{Remark.} Graded $A$-modules with graded $A$-module homomorphisms form a category (where $A$ is a graded algebra).

\subsection{Symmetric polynomials}
\begin{deff}
  Let $k$ b a field. Let $G := S_n = S(\set{1,\ldots,n})$ act linearly on $K[X_1,\ldots,X_n]$ by \begin{equation} g. X_1^{a_1}X_2^{a_2}\cdots X_n^{a_n} = X_{g(1)}^{a_1}X_{g(2)}^{a_2}\cdots X_{g(n)}^{a_n}. \tag{*}\label{def:symmetric poly:eq} \end{equation}
  A polynomial in $k[X_1,\ldots,X_n]^G$ is called a \emph{symmetric} polynomial (in $n$ variables).
\end{deff}

\paragraph{Remark.} We could replace $k$ by any commutative ring $R$ with $1$ and extend \eqref{def:symmetric poly:eq} $R$-linearly to get an action of $G$ on $R[X_1,\ldots,X_n]$.

\paragraph{Examples.}
In $K[X_1,X_2,X_3]^{S_3}$ we have e.g. the following elements:
\begin{align*}
  p_2^{(3)} &= X_1^2+X_2^2+X_3^2 \\
  h_2^{(3)} &= X_1^2+X_1X_2+X_1X_3+X_2^2+X_2X_3+X_3^2 \\
  e_2^{(3)} &= X_1X_2+X_1X_3+X_2X_3 \\
  m_{(4,4,2)}^{(3)} &= X_1^4X_2^4X_3^2+X_1^4X_2^2X_3^4+X_1^2X_2^4X_3^4+X_1^2X_2^4X_3^4
\end{align*}

\begin{deff}
  Let $n\in \IZ_{>0}$ and $r\in\IZ_{\ge0}$. Define the symmetric polynomials
  \begin{align*}
    p_r^{(n)} &:= X_1^r+X_2^r+\ldots+X_n^r, \\ \intertext{the $r$-th \emph{power symmetric polynomial} (with $p_0^{(n)} = n$),}
    h_r^{(n)} &:= \sum_{\abs a = r}X_1^{a_1}X_2^{a_2}\cdots X_n^{a_n} \\ \intertext{where $a = (a_i)_{1\le i\le n}\in \IZ_{\ge 0}^n$ with $\abs a = \sum_{i=1}^na_i$, the $r$-th \emph{complete symmetric polynomial} ($h_0^{(n)} = 1$),}
    e_r^{(n)} &:= \sum_{\mathclap{1\le i_1<\ldots<i_r\le n}} X_{i_1} X_{i_2}\cdots X_{i_r} = \sum_{\substack{I \subseteq \set{1,\ldots,n}\\\abs I = r}} \prod_{i \in I}X_i, \\ \intertext{the $r$-th \emph{elementary symmetric polynomial} (with $e_0^{(n)} = 1$ and $e_r^{(n)} = 0$ if $r>n$).}
  \end{align*}
\end{deff}

\begin{lem}
  For all $n\in \IZ_{>0}$ we have in $\IZ[X_1,\ldots,X_n][t]$ \[ \prod_{i=1}^n (t-X_i) = t^n-e_1^{n}t^{n-1}+e_2^{(n)}t^{n-2}+\ldots+(-1)^ne_n^{(n)}. \]
\end{lem}
\begin{proof}
  The coefficient of $t^{n-j}$ on the left hand side equals \begin{align*} \sum_{\mathclap{i \le i_1 < \ldots < i_j \le n}} (-X_{i_1})(-X_{i_2})\cdots(-X_{i_j}) = (-1)^j e_j^{(n)}. \qedhereb \end{align*}
\end{proof}

\begin{thm}[Fundamental theorem of symmetric polynomials] \label{thm:symmetric polys}
  The elementary symmetric polynomials $e_1^{(n)},\ldots,e_n^{(n)}$ generate $k[X_1,\ldots,X_n]^{S_n}$ as a $k$-algebra. Moreover they are algebraically independent over $k$. That means
  \begin{eqnarray*}
    k[X_1,\ldots,X_n]^{S_n} &\to& k[t_1,\ldots,t_n] \\
    e_j^{(n)} &\mapsto& t_j
  \end{eqnarray*}
  is an isomorphism of algebras.
\end{thm}

\begin{lem} \label{lem:III.5/6}
  Let $G$ be a group and $V_i$ ($i\in I$) representations of $G$ (over some fixed field $k$). Then \[ \pa{\bigoplus_{i\in I}V_i}^G = \bigoplus_{i \in I}V_i^G \] as vector subspaces of $\bigoplus_{i\in I} V_i$. 
\end{lem}
\begin{proof}
  \leavevmode
  \begin{description}
    \item[\enquote{$\supseteq$}] Obvious.
    \item[\enquote{$\subseteq$}] Let $v = \sum_{i\in I}v_i \in \pa{\bigoplus_{i\in I}V_i}^G$. Then we have \[ v = g.v = g. \pa{\sum_{i\in I}v_i} = \sum_{i \in I}g.v_i \] for all $g \in G$ since the sum is direct. We get $v_i = g.v_i$ for all $i\in I$ and $g \in G$, and therefore $v_i \in V_i^G$ for all $i\in I$.
    \qedhere
  \end{description}
\end{proof}

\begin{lem}
  A polynomial $f \in k[X_1,\ldots,X_n]$ is symmetric if and only if its homogeneous parts $f_i \in k[X_1,\ldots,X_n]$ are symmetric.
\end{lem}
\begin{proof}
  Let $A = k[X_1,\ldots,X_n] = \sum_{i\in \IZ}k[X_1,\ldots,X_n]_i$ the decomposition (since $A$ is a graded algebra) where \[ k[X_1,\ldots,X_n]_i = \begin{cases*}
                                            0 & if $i < 0$, \\
                                            \gen{\set*{X_1^{a_1}\cdots X_n^{a_n}\given \sum_{j=1}^na_j = i}} & otherwise.
                                          \end{cases*} \]
  $G = S_n$ acts on $A$ as above and preserves $k[X_1,\ldots,X_n]_i =: A_i$. By \cref{lem:III.5/6} we get \begin{align*} k[X_1\ldots,X_n]^{S_n} = A^G = \bigoplus_{i\in\IZ}A_i^G = \bigoplus_{i\in\IZ}k[X_1,\ldots,X_n]_i^{S_n} \qedhereb \end{align*}
\end{proof}

The following formula holds for all $1 \le r \le n$ ($n \in \IZ_{>0}$). \[ e_r^{(n)} = e_r^{(n-1)} + X_ne_{r-1}^{(n-1)} \]
\begin{proof}
  \begin{align*}
    \qedherea
    e_r^{(n)} &= \sum_{\substack{I \subseteq \set{1,\ldots,n}\\\abs I = r}} \prod_{i \in I}X_i = \sum_{\substack{I \subseteq \set{1,\ldots,n-1}\\\abs I = r}} \prod_{i \in I}X_i + X_n \sum_{\substack{I \subseteq \set{1,\ldots,n-1}\\\abs I = r-1}} \prod_{i \in I}X_i \\ &= e_r^{(n-1)} + X_ne_r{-1}^{(n-1)}
    \qedhereb
  \end{align*}
\end{proof}

\begin{lem} \label{lem:III.8}
  A polynomial $f\in k[X_1,\ldots,X_n]$ is symmetric if and only if it can be expressed as a polynomial in the $e_r^{(n)}$'s (over $k$).
\end{lem}
\begin{proof}
  \leavevmode
  \begin{description}
    \item[\enquote{$\Rightarrow$}] We have $e \in k[X_1,\ldots,X_n]^{S_n}$. But $k[X_1,\ldots,X_n]^{S_n}$ is a subring, even a subalgebra.
    \item[\enquote{$\Leftarrow$}] Let $f \in k[X_1,\ldots,X_n]^{S_n}$ a symmetric polynomial. We use induction on $n$.
    
    For $n=1$ we have $k[X_1]^{S_1} = k[X_1]^{\set e} = k[X_1] = k\br{e_1^{(1)}}$.
    
    Assume the lemma for $n-1$. Let $d = \deg f$. If $d \le 1$, the claim is obvious. Let $d \ge 2$ and assume the lemma holds for any symmetric polynomial $h$ with $\deg h < d$.
    
    Consider
    \begin{eqnarray*}
      q \colon k[X_1,\ldots,X_n] &\to& \fak{k[X_1,\ldots,X_n]}{(X_n)} \cong k[X_1,\ldots,X_{n-1}], \\
      p(x_1,\ldots,x_n) &\mapsto& p(x_1,\ldots,x_{n-1},0).
    \end{eqnarray*}
    Check that $q$ is an algebra homomorphism. We have:
    \begin{itemize}
      \item $q(e_j^{(n)}) = e_j^{(n-1)}$ for all $0\le j >n$.
      \item $q(e_n^{(n)}) = 0$.
      \item $q(f) \in k[X_1,\ldots,X_n]^{S_{n-1}}$, because for $g \in S_{n-1}$
      \begin{align*}
        g.(q(f)) &= (q(f))(X_{g^{-1}(1)},X_{g^{-1}(2)},\ldots,X_{g^{-1}(n-1)})) \\
        &= q(f(X_{g^{-1}(1)},X_{g^{-1}(2)},\ldots,X_{g^{-1}(n)})) \\
        &= q((g.f)(X_1,\ldots,X_n)) \\ \intertext{and as $f$ is symmetric,}
        &= q(f).
      \end{align*}
    \end{itemize}
    By induction $q(f)$ is a polynomial $P\pa{e^{(n-1)}_1,\ldots,e_{n-1}^{(n-1)}}$ in $e^{(n-1)}_1,\ldots,e_{n-1}^{(n-1)}$. Set $g= P\pa{e_1^{(n)},\ldots,e_{n-1}^{(n)}}\in k[X_1,\ldots,X_n]$. Because $q$ is an algebra homomorphism we have \[q(g) = P\pa{q\pa{e_1^{(n)}},\ldots,q\pa{e_n^{(n)}}} = P\pa{e_1^{(n-1)},\ldots,e_{n-1}^{(n-1)},0} = q(f). \] Therefore, $q(f-g) = 0$ in $\fak{k[X_1,\ldots,X_n]}{(X_n)}$, and we get $X_n \mid f-g$.
    
    By assumption, $f$ is symmetric, by construction, $g$ is symmetric. Thus, $f-g$ is symmetric, and $X_i \mid f-g$ for all $1 \le i \le n$, and we have $X_1X_2\cdots X_n \mid f-g$. Set \[ h = \frac{f-g}{X_1X_2\cdots X_n} = \frac{f-g}{e_n^{(n)}} \] (here we use that $k[X_1,\ldots,X_n]$ is a unique factorization domain). Now due to $\deg g \le \deg f = d$ we have $\deg h < d $. By induction on degree $h$ canb e written as apolynomial in the $e_1^{(n)},\ldots,e_n^{(n)}$. Then, $f -g = e_n^{(n)}h$ as well as $f= e_n^{(n)}h +g$ can be written as such a polynomial by definition of $g$.
    \qedhere
  \end{description}
\end{proof}

\begin{proof}[Proof ot the \namereff{thm:symmetric polys}]
  \leavevmode\\
  We still have to show that the $e_1^{(n)},\ldots,e_n^{(n)}$ are algebraically independent (over $k$). We use induction on $n$. For $n=1$ we have $k[X_1]^{S_1} = k[X_1] = k[e_1^{(1)}]$.
  
  Assume the claim holds for $n-1 \ge 1$, but it does not hold for $n$. Then there exists a polynomial $0 \neq P \in k[t_1,\ldots,t_n]$ such that $P\pa{e_1^{(n)},\ldots,e_n^{(n)}}=0$. Let $P$ be of minimal possible degree. Then \[ 0 = q\pa{P\pa{e_1^{(n)},\ldots,e_n^{(n)}}} = P\pa{q\pa{e_1^{(n)}},\ldots,q\pa{e_n^{(n)}}} = P\pa{e_1^{(n-1)},\ldots,e_{n-1}^{(n-1)},0} \] and by induction hypothesis $X_n \mid P$.
  
  Therefore, there exists a $\hat p \in k[t_1,\ldots,t_n]$ such that $P = t_n \hat P$. In particular $\hat P \neq 0$ and $\deg \hat P < \deg P$. We have $0 = P\pa{e_1^{(n)},\ldots,e_n^{(n)}} = e_n^{(n)}\hat P \pa{e_1^{(n)},\ldots,e_n^{(n)}}$. Thus, $\hat P\pa{e_1^{(n)},\ldots,e_n^{(n)}} = 0$ since $e_n^{(n)} \neq 0$ and $P \mid 0$. This contradicts the minimality of $\deg P$.
\end{proof}

\paragraph{Remark.} The proof gives an algorithm how to express a symmetric polynomial $f$ in the $e_1^{(n)},\ldots,e_n^{(n)}$.

\paragraph{Remark.} The proof and theorem also hold for $\IZ[X_1,\ldots,X_n]^{S_n}$.

\bigskip

To better understand the interaction ot the symmetric polynomials $e_r^{(n)}$, $p_r^{(n)}$ and $h_i^{(n)}$ we use \emph{generating series} in $k[X_1,\ldots,X_n]\llbracket t\rrbracket$. For fix $n\in \IZ_{>0}$ we define
\begin{align*}
  E(t) & := \sum_{r=0}^ne_r^{(n)}t^r, & H(t) & := \sum_{r\ge0}h_r^{(n)}t^r, & P(t) & := \sum_{r\ge 0} p_{r+1}^{(n)}t^r.
\end{align*}

\begin{lem} \label{lem:III.9}
  \leavevmode
  \begin{enumerate}
    \item\label{lem:III.9:1} $\displaystyle E(t) = \prod_{i=1}^n (1+X_it)$
    \item\label{lem:III.9:2} $\displaystyle H(t) = \prod_{i=1}^n\frac1{1-X_it}$
    \item\label{lem:III.9:3} $\displaystyle P(t) = \sum_{i=1}^n \frac1{1-X_it}$
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:III.9:\arabic*}]
    \item Clear.
    \item $1-X_it$ is invertible in $k[X_1,\ldots,X_n]\llbracket t\rrbracket$, namely with the inverse $Q_i(t) = \frac1{1-X_it} := 1+X_i+X_i^2t^2 + \ldots$. Then $ \prod_{i=1}^n \frac1{1-X_it} = Q_1(t)Q_2(t)\cdots Q_n(t)$. But here the coefficient of $t_j$ equals $h_j^{(n)}$.
    \item Left to the reader. \qedhere
  \end{enumerate}
\end{proof}

\begin{cor} \label{cor:III.10}
  For all $s \ge 1$ we have \[ h_s^{(n)} - e_1^{(n)}h_{s-1}^{(n)} + e_2^{(n)}h_{s-2}^{(n)} - \ldots + (-1)^se_sh_0^{(n)} = 0. \] The same holds with $e$ and $h$ swapped.
\end{cor}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{cor}
  For all $j\ge 1$ we have \[ jh_j^{(n)} = p_1^{(n)}h_{j-1}^{(n)} + p_2^{(n)}h_{j-2}^{(n)} + \ldots + p_{j-1}^{(n)}h_1^{(n)}+p_j^{(n)}h_0^{(n)}. \]
\end{cor}
\begin{proof}
  Let $H^r(t)$ be the formal derivation of $H(t)$ with respect to $t$, so $H_r'(t) = \sum_{r\ge 0}rh_r^{(n)}t^{r-1}$. On the other hand (by \cref{lem:III.9}) \[ H'(t) = \sum_{i=1}^n\pa{\frac{X_i}{(1-X_it)^2}\prod_{j\neq i}\frac1{1-X_jt}} = \sum_{i=1}^n\frac{X_i}{1-X_it}\pa{\prod_{j=1}^n\frac1{1-X_jt}}. \] By comparing coefficients of $t^{r-1}$ we get \[ rh_r^{n} = \sum_{s=1}^rp_s^{(n)}h_{r-s}^{(n)} \] using \cref{lem:III.9} \ref{lem:III.9:2} and \ref{lem:III.9:3}.
\end{proof}

\lecture{October 22, 2018}

\begin{cor}[Newton identities]
  For all $r \ge 0$ one has \[ p_r^{(n)} - e_1^{(n)}p_{r-1}^{(n)} + \ldots + (-1)^re_r^{(n)}p_0^{(n)} = 0. \]
\end{cor}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{cor} \label{cor:III.12}
  Let $k$ be a field or $k= \IZ$. There exist polynomials $F_1,\ldots,F_n \in k[t_1,\ldots,t_n]$ such that \[ h_j^{(n)} = F_j(e_1^{(n)},\ldots,e_n^{(n)}) \quad\text{und}\quad e_j^{(n)}=F_j\pa{h_1^{(n)},\ldots,h_n^{(n)}} =0 \] for all $1 \le j \le n$.
\end{cor}
\begin{proof}
  We have $h_1^{(n)} = X_1 + \ldots+X_n = e_1^{(n)}$. Set $F_1(t_1,\ldots,t_n) = t_1$. Now assume $F_1,\ldots,F_{s-1}$ exist for $1\le s \le n$. Define \[ F_s := t_1F_{s-1}-t_2F_{s-2} + \ldots + (-1)^{s-2}t_{s-1} +(-1)^{s-1}t_s. \] By induction and \cref{cor:III.10} we get \[ F_s = e_1^{(n)}h_{s-1}^{(n)} - e_2^{(n)}h_{s-2}^{(n)} + \ldots +(-1)^{s-2}e_{s-1}^{(n)}h_1+(-1)^{s-1}e_s^{(n)}h_0^{(n)} = h_s^{(n)}. \]
  By switching th ole of the $e$'s and $h$'s (using $e_1^{(n)} = h_1^{(n)}$) and \cref{cor:III.10} again gives $F_s\pa{h_1^{(n)},\ldots,h_n^{(n)}} = e_s^{(n)}$.
\end{proof}

\begin{thm} \label{thm:III.13}
  Let $k$ be a field. Then there exists a unique algebra homomorphism 
  \begin{eqnarray*}
    \hat\Phi\colon k[X_1,\ldots,X_n]^{S_n} &\to& k[X_1,\ldots,X_n]^{S_n} \\
    e_j^{(n)} &\mapsto& h_j^{(n)}
  \end{eqnarray*}
  for all $0 \le j \le n$. Moreover ${\hat\Phi}^2 = \id$ and so $\hat\Phi$ is an isomorphism.
\end{thm}
\begin{proof}
  By the \namereff{thm:symmetric polys} we have an isomorphism of algebras
  \begin{eqnarray*}
    \Phi\colon k[X_1,\ldots,X_n]^{S_n} &\to& k[t_1,\ldots,t_n], \\
    e_j^{(n)} &\mapsto& t_j.
  \end{eqnarray*}
  By the universal property of the polynomial ring we have a unique algebra homomorphism
  \begin{eqnarray*}
    \ol\Phi\colon k[t_1,\ldots,t_n] &\to& k[X_1,\ldots,X_n]^{S_n}, \\
    t_j &\mapsto& h_j^{(n)}.
  \end{eqnarray*}
  Now set $\hat\Phi := \ol\Phi \circ \Phi$. This is an algebra homomorphism.
  
  We have to show that ${\hat\Phi}^2 = \id$. Since the $e_j^{(n)}$ generate $k[X_1,\ldots,X_n]^{S_n}$ as an algebra, it is enough to show that $\hat\Phi\pa{e_j^{(n)}} = h_j^{(n)}$ for all $0 \le j \le n$. By \cref{cor:III.12} and construction of $\hat\Phi$ we get \[ \hat\Phi\pa{h_j^{(n)}} = \hat\Phi\pa{F_j\pa{e_1^{(n)},\ldots,e_n^{(n)}}} = F_j\pa{\hat\Phi\pa{e_1^{(n)}},\ldots,\hat\Phi\pa{e_n^{(n)}}} = F_j\pa{h_1^{(n)},\ldots,h_n^{(n)}} = e_j^{(n)} \] for all $0 \le j \le n$.
\end{proof}

\begin{thm} \label{thm:III.14}
  Let $k$ be a field with $\chr k=0$ or $\chr k>n$. Then the $p_1^{(n)},\ldots,p_n^{(n)}$ generate $k[X_1,\ldots,X_n]^{S_n}$ as a $k$-algebra and they are algebraically independent over $k$.
\end{thm}
\begin{proof}
  Left to the reader.
\end{proof}

\paragraph{Remark.}
\cref{thm:III.14} does not hold over $\IZ$. Consider $\IQ[X_1,X_2]^{S_2}$. There we have $e_2^{(2)} = \frac12\pa{\pa{p_1^{(2)}}^2-p_2^{(2)}}$, as one has $(X_1+X_2)^2 - (X_1^2 + X_2^2) = 2X_1X_2$. If the theorem holds for $k=\IZ$ then there exists an $F \in \IZ[t_1,t_2]$ such that $F\pa{p_1^{(2)},p_2^{(2)}} = e_2^{(n)}$. Viewed as a polynomial in $\IQ[t_1,t_2]$ we have $\frac12t_1^2-\frac12t_2-F(t_1,t_2) = G(t_1,t_2)$. It satisfies $G\pa{p_1^{(2)},p_2^{(2)}} = 0$. This implies $G = 0$ because $p_1^{(2)}$ and $p_2^{(2)}$ are algebraically independent over $IQ$. But this contradicts $F \in \IZ[t_1,t_2]$.

\bigskip

We want to find a basis of $k[X_1,\ldots,X_n]^{S_n}$. This is another natural occurence of power series.

\begin{deff}
  Let $A = \bigoplus_{i\in\IZ}A_i$ be a graded algebra. Assume $A_i = 0$ for $i<0$ (\emph{non-negatively graded}) and $\dim A_i <\infty$ for all $i \in \IZ$. Then define the \emph{Hilbert series} \[ P_A(t) = \sum_{i\ge 0} (\dim A_i)t^i \in \IN_0\llbracket t \rrbracket \] (in particular, if $\dim A < \infty$, we have $P_A(t) \in \IN_0[t]$).
\end{deff}

\paragraph{Examples.}
\begin{enumerate}
  \setcounter{enumi}{-1}
  \item\label{ex:hs:1} For $k$ a field let $A = k[t]$ with standard grading $\bigoplus_{i\ge0}\gen{t^i}$. Then we get \[ P_A(t) = 1+t+t^2+\ldots = \frac1{1-t}. \] (Note that $P_A(t)$ is not defined for the \enquote{stupid} grading.)
  \item If $A=\bigoplus_{i\in\IZ}$ and $B = \bigoplus_{i\in\IZ}B_i$ are non-negatively graded algebras with $\dim A< \infty>\dim B$ and $\dim A_i <\infty>\dim B_i$ for all $i \in \IZ$. Then $A \tp B$ is an algebra, even a graded ring via \[ A \tp B = \bigoplus_{i\in \IZ} (A\tp B)_i \quad\text{where}\quad (A\tp B)_i = 
  \begin{cases*}
    0 & if $i < 0$, \\
    \bigoplus_{r=0}^i A_r \tp B_{i-r} & \text{otherwise}.
  \end{cases*}
  \]
  
  It is clear that the $(A\tp B)_i \subseteq A\tp B$ are vetorspaces and $\bigoplus_{i\in\IZ}(A\tp B)_i = A\tp B$ by choosing a homogeneous basis of $A$ and $B$.
  
  We have to check that $(A \tp B)_i(A\tp B)_j \subseteq (A\tp B)_{i+j}$ for all $i,j \in \IZ$. We can assume $i,j \ge 0$ and check the property on a basis. We have \[\underbrace{(a \tp b)}_{\mathclap{\in A_i\tp B_{i-r} \subseteq (A \tp B)_i}}\overbrace{(c \tp d)}^{\mathllap{\in A_s \tp B_{j-2}\subseteq (A \tp B)_j}} = \underbrace{ac}_{\mathclap{\in A_iA_s \subseteq A_{i+s}}} \tp \overbrace{bd}^{\mathclap{\in B_{i-r}B_{j-s} \subseteq B_{i+j-r-s}}}, \] and we get $ac \tp bd \in A_{i+s}\tp B_{i+j-(r+s)} \subseteq (A \tp B)_{i+j}$. Thus, $A\tp B$ is a non-negatively graded ring. We have $\dim(A \tp B)_i = \sum_{r=0}^i\dim A_r \dim B_{i-r}$, which results in \[ P_{A \tp B}(t) = P_A(t)P_B(t). \]
  
  We now consider the special case $A = k[X_1,\ldots,X_n]$ with standard grading. There is an isomorphism of algebras
  \begin{equation*}
  \begin{aligned}
    A \;\;&\cong&& k[t_1] \tp k[t_2] \tp \ldots \tp k[t_n], \\
    X_1^{a_1}X_2^{a_2}\cdots X_n^{a_n} \;\;&\mapsfrom&& t_1^{a_1}\tp t_2^{a_2}\tp \ldots\tp t_n^{a_n}.
  \end{aligned} \tag{*}\label{ex:blub}
  \end{equation*}
  Thus $P_A(t) = P_{k[t_1]}(t)\cdots P_{k[t_n]}(t)$ with the standard grading on $k[t_i]$. (Note that \eqref{ex:blub} becomes a graded algebra isomorphism.) Hence \[ P_A(t) = (1+t+t^2+\ldots)(1+t+t^2+\ldots)\cdots(1+t+t^2+\ldots) = \prod_{i=1}^n\frac1{1-t}. \]
  Then \[ P_A(t) = \sum_{j\ge 0}\binom{n+j+1}{n-1} t^j \] where the binomial coefficient counts all the ways o create $t^j$ from the $r$ factors. We want the number of tuples $(j_1,\ldots,j_n) \in \IZ_{\ge 0}^n$ with $j_1+\ldots+j_n = j$. We can think of this by choosing $n-1$ points as \enquote{barriers} out of $n+j-1$ points.
  
  For $n=1$, we have $\binom{n+j-1}0 = 1$, see \ref{ex:hs:1}. For $n=2$, $\binom{j+1}j$ is the number of monomials.
  \item By the \namereff{thm:symmetric polys} we have an isomorphism of algebras \[ \Phi\colon k[X_1,\ldots,X_n] \cong k[t_1,\ldots,t_n],\] but this is not an isomorphism of graded algebras if we choose the standard gradings on $k[X_1,\ldots,X_n]$ and $k[t_1,\ldots,t_n ]$.
  
  Define a grading on $k[t_1,\ldots,t_n]$ by $k[t_1,\ldots,t_n]_i := \Phi\pa{k[X_1,\ldots,X_n]^{S_n}}$. Because $\Phi$ is an isomorphism of algebras (in particular of vector spaces) we have \[A = k[t_1,\ldots,t_n] = \bigoplus_{i\ge0} k[t_1,\ldots,t_n]_i.\]
  We want to calculate $P_A(t)$ with this grading.
  
  We have \[ k[t_1,\ldots,t_n] \cong k[t_1] \tp k[t_2] \tp \ldots \tp k[t_n] \] as algebras and as graded algebras by setting $t_i \in k[t_i]$ in degree $i$ (since $t_j$ corresponds to $e_j^{(n)}$ which has degree $j$). Therefore \[ P_A(t) = \underbrace{(1+t+t^2+\ldots)}_{\text{$t_1$ is of degree $1$}}\underbrace{(1+t^2+t^4+\ldots)}_{\text{$t_2$ is of degree $2$}}\cdots \underbrace{(1+t^n+t^{2n}+\ldots)}_{\text{$t_n$ is of degree $n$}} = \prod_{j=1}^n\frac1{1-t^j}. \]
  We now focus on how to express the coefficient of $t^j$ in $P_A(t)$ explicitly. The coefficient of $t_j$ equals the number of tuples $(a_1,\ldots,a_n)\in \IZ_{\ge0}^n$ satisfying $1a_1+2a_2+\ldots+na_n = j$.
  
  For visualization, consider the following Young diagram consisting of $j$ squares.
  \begin{center}
    \ytableausetup{mathmode, boxsize=0.6cm}
    \begin{ytableau}
      a_n & a_n & a_n &a_n & \none[\dots]
      & a_n \\
      a_n & a_n & a_n & a_n&\none[\dots]
      & a_n \\
      \none[\vdots] & \none[\vdots]
      & \none[\vdots] \\ % TODO: ugly dots
      a_2 & a_2 \\
      a_2 & a_2 \\
      a_1 \\
      a_1 \\
      a_1
    \end{ytableau}
  \end{center}
  In this example, we have $a_1 = 3$, $a_2 = 2$ and $a_n = 2$.
\end{enumerate}

\begin{deff}
  For $d \in \IN$ a sequence $\lambda = (\lambda_1\ge \lambda_2\ge\ldots)$ with $\lambda_i \in \IZ_{\ge0}$ is a \emph{partition} of $d$ if $\sum_{i=1}^\infty \lambda_i = d$. We write $\abs \lambda := \sum_{i=1}^\infty$ and let $l(\lambda)$ be maximal such that $\lambda_i \neq 0$ and call it the \emph{length} of $\lambda$. We set \[ \Par(d) := \set{\text{partitions of $d$}} \quad\text{und}\quad \Par := \bigcup_{d \ge 0}\Par(d).\]
\end{deff}
\begin{deff}
  Define a partial ordering on $\Par$ by setting $\lambda \le \mu$ for $\lambda,\mu \in \Par$ if we have \[ \sum_{i=1}^r \lambda_i \le \sum_{i=1}^r\mu_i \] for all $r \ge 0$.
\end{deff}
\begin{deff}
  For $\lambda \in \Par$ we define the following elements in $k[X_1,\ldots,X_n]^{S_n}$.
  \begin{align*}
    e_\lambda^{(n)} &:= e_{\lambda_1}^{(n)}e_{\lambda_2}^{(n)}\cdots  \tag{$\lambda_1 \le n$} \\
    h_\lambda^{(n)} &:= h_{\lambda_1}^{(n)}h_{\lambda_2}^{(n)}\cdots \\
    p_\lambda^{(n)} &:= p_{\lambda_1}^{(n)}p_{\lambda_2}^{(n)}\cdots \\
    m_\lambda^{(n)} &:= \sum_{\mathclap{g \in S_n}}X_{g(1)}^{\lambda_1}X_{g(2)}^{\lambda_2}\cdots X_{g(n)}^{\lambda_n} \tag{$l(\lambda)\le n$}
  \end{align*}
  They are all homogeneous of degree $\abs\lambda$.
\end{deff}

\lecture{October 25, 2018}

\begin{deff}
  For $\lambda\in\Par$ let $\lambda^t$ be the \emph{transposed partition} given by $\lambda_i^t = \abs{\set{j \given \lambda_j = i }}$. In this case, the young diagram is \enquote{flipped}. % TODO tolles Bild hierfür?
\end{deff}

\begin{thm}
  The $\set*{e_\lambda^{(n)}}$ and $\set*{h_\lambda^{(n)}}$ for $\lambda \in \Par$ with $\lambda_i \le n$ form a $k$-vector space of $k[X_1,\ldots,X_n]^{S_n}$ for $k$ any field or $k= \IZ$. Moreover $\set*{m_\lambda^{(n)}}$ for $\lambda \in \Par$ with $l(\lambda) \le n$ is also basis.
\end{thm}
\begin{proof}
  By the \namereff{thm:symmetric polys} the monomials in the $e_j^{(n)}$'s are linearly independent, because the $e_j^{(n)}$'s are algebraically independent. Moreover, they generate as a vector space because the $e_j^{(n)}$'s generate as an algebra. Thus, the $\set*{e_\lambda^{(n)}}$ with $\lambda \in \Par$ and $\lambda_i \le n$ form a basis. Then the $\set*{h_\lambda^{(n)}}$ form a basis by applying the transformation of \cref{thm:III.13}.
  
  In $ e_\lambda^{(n)} = e_{\lambda_1}^{(n)}e_{\lambda_2}^{(n)}\cdots e_{\lambda_{l(\lambda)}}^{(n)} $ the maximum possible degree of $\lambda_2$ is $\lambda_2^t$ etc. In fact we have \[ e_\lambda^{(n)} = m_{\lambda^t}^{(n)} + \sum_{\mu \le \lambda^t} m_{\mu_t}^{(n)}. \] Therefore the $m_{\lambda^t}^{(n)}$ with $\lambda_i^t \le n$ form a basis, since the $e_\lambda^{(n)}$ with $\lambda_i \le n$ do. As one has $\set{\lambda \in \Par \given \lambda_i \le n} = \set{\lambda \in \Par \given l(\lambda^t) \le n}$ the $m_\lambda^{(n)}$ for $\lambda \in \Par$ with $l(\lambda) \le n$ form a basis.
\end{proof}

\subsection{Polynomial maps}
In this section $k$ is an infinite field, $V$ a finite-dimensional $k$-vector space and $v_1,\ldots,v_n$ a basis of $V$.

\begin{deff}
  We set $\Ps_k(V) = \set{f\colon V \to k \given \text{$f$ polynomial}}$ where $f$ is \emph{polynomial} if \[f\pa{\sum_{i=1}^n\alpha_iv_i} = p(\alpha_1,\ldots,\alpha_n)\] for some polynomial $p \in k[t_1,\ldots,t_n]$.
\end{deff}

\paragraph{Remark.}
\begin{itemize}
  \item Clearly $\Ps_k(V)$ is a $k$-vector space with pointwise addition and scalar multiplication.
  \item The property \enquote{polynomial} does not depend on the choice of a basis.
  \begin{proof}
    Let $w_1,\ldots,w_n$ be a basis of $V$ and $w_j = \sum_{i=1}^n \beta_{ij} v_i$. Then we get \begin{align*} f\pa{\sum_{j=1}^n\alpha_jw_j} &= f\pa{\sum_{j=1}^n\alpha_j \sum_{i=1}^n\beta_{ij}v_i} = f\pa{\sum_{i=1}^n \sum_{j=1}^n\alpha_j\beta_{ij}v_i} \\ &= p\pa{\sum_{j=1}^n\alpha_j\beta_{1j},\ldots,\sum_{j=1}^n\alpha_j\beta_{nj}} \end{align*} for some $p \in k[t_1,\ldots,t_n]$ as $f$ is polynomial. But the last expression depends polynomial on $\alpha_1,\ldots,\alpha_n$; it equals $p'(\alpha_1,\ldots,\alpha_n)$ for some polynomial $p'$.
  \end{proof}
\end{itemize}

\begin{lem}
  Let $W \subseteq V$ be a vector subspace. If $f \in \Ps_k(V)$ we get $f|_W \in \Ps_k(W)$.
\end{lem}
\begin{proof}
  We choose a basis $w_1,\ldots,w_m$ of $W$ and extend it to a basis $w_1,\ldots,w_n$ of $V$. Now $f\pa{\sum_{i=1}^m \alpha_1w_1} = p(\alpha_1,\ldots,\alpha_m,0,\ldots,0)$ for some $p\in k[X_1,\ldots,X_n]$ as $f \in \Ps_k(V)$. Consider the image $\tilde p$ of $p$ under the canonical map \[k[X_1,\ldots,X_n] \to \fak{k[X_1,\ldots,X_n]}{(X_{m+1},\ldots,X_n)} \cong k[X_1,\ldots,X_m].\] Then by construction $f\pa{\sum_{i=1}^m\alpha_iw_i} = \tilde p(\alpha_1,\ldots,\alpha_m)$ with $\tilde p \in k[X_1,\ldots,X_m]$.
\end{proof}

\begin{deff}
  For $f,g \in \Ps_k(V)$ define $fg$ as $(fg)(v) = f(v)g(v)$ for all $v \in V$. This turns $\Ps_k(V)$ into a $k$-algebra.
\end{deff}

\begin{thm} \label{thm:III.17}
  There is an isomorphism of $k$-algebras
  \begin{eqnarray*}
    k[X_1,\ldots,X_n] &\to& \Ps_k(V), \\
    p &\mapsto& f_p = \pa{ \sum_{i=1}^n\alpha_iv_i \mapsto p(\alpha_1,\ldots,\alpha_n)}.
  \end{eqnarray*}
\end{thm}
\begin{proof}
  Define for $1\le j \le n$ the $j$-th \emph{coordinate function} $\phi_j\colon V \to k$ by $\phi_j\pa{\sum_{i=1}^n\alpha_iv_i} = \alpha_j$. Obviously we have $\phi_j \in \Ps_k(V)$. By the universal property of the polynomial algebra $k[X_1,\ldots,X_n]$ there exists a unique algebra homomorphism
  \begin{eqnarray*}
    \beta\colon k[X_1,\ldots,X_n] &\to& \Ps_k(V), \\
    X_j &\mapsto& \phi_j.
  \end{eqnarray*}
  Then $\beta(X_1^{a_1}\cdots X_n^{a_n})(v) = (\phi_1^{a_1}\cdots\phi_n^{a_n})(v)$. By the definition of multiplication $\Ps_k(V)$ one gets $(\phi_1^{a_1}\cdots\phi_n^{a_n})\pa{\sum_{i=1}^n\alpha_iv_i} = \alpha_1^{a_1}\cdots\alpha_n^{a_n}$. Thus $\beta$ sends $p$ to $f_p$.

  By definition $\beta $ is surjective. Now assume $\beta(p) = 0$. Then $f_p\pa{\sum_{i=1}^n\alpha_iv_i} = 0$ for all $(\alpha_1,\ldots,\alpha_n)\in k^n$, hence $p(\alpha_1,\ldots,\alpha_n) = 0$ for all $(\alpha_1,\ldots,\alpha_n) \in k^n$. As $k$ is infinite we get $p=0$. Therefore $\beta$ is an isomorphism.
\end{proof}

\paragraph{Remark.}
The theorem does not hold for finite fields in general. For example, take $p(t) = t^2+t \in \IF_2[t]$. In this case we have $p(1) = 1+1 = 0 = 0+0 = p(0)$, so $p(\lambda) = 0$ for all $\lambda\in\IF_2$, but $p\neq 0$. Therefore the $\beta$ in the proof does not have to be injective.

\addtocounter{thmcounter}{1}
\paragraph{Remark \Roman{section}.\arabic{thmcounter}.}
At this point Professor Stroppel seems to have skipped a number in her notes.

\begin{deff}
  $f\in \Ps_k(V)$ is \emph{homogeneous} of degree $d$ if $f(\lambda v) = \lambda^df(v)$ for all $\lambda \in k$ and $v\in V$.
\end{deff}

\begin{prop} \label{prop:III.19}
  We have \[ \Ps_k(v) = \bigoplus_{d\ge0}{\Ps_k(V)}_d \quad\text{where}\quad {\Ps_k(V)}_d = \set{f\in \Ps_k \given \text{$f$ is homogeneous of degree $d$}} \] and $\Ps_k(V)$ becomes a non-negatively graded algebra.
\end{prop}
\begin{proof}
  Clearly ${\Ps_k(V)}_d \cap {\Ps_k(V)}_{d'} = 0$ if $d \neq d'$, as otherwise we have $\lambda^df(v) = f(\lambda v) = \lambda^{d'}f(v)$, or $\lambda^d - \lambda^{d'}=0$ for all $\lambda \in k$ and $v \in V$. But $t^d -t^{d'}$ only has finitely many roots which contradicts the infinity of $k$. We get $\bigoplus_{d\ge0}{\Ps_k(V)}_d \subseteq \Ps_k(V)$ via the isomorphism $\beta $ from \cref{thm:III.17} which maps a monomial $p = X_1^{a_1}\cdots X_n^{a_n} \in k[X_1,\ldots,X_n]$ to $f_p$ with $f_p\pa{\sum_{i=1}^n\lambda_iv_i} = p(\lambda_1,\lambda_n)$. Then $f_p(\lambda v) = p(\lambda\lambda_1,\ldots,\lambda\lambda_n) = \lambda^{a_1+\ldots+a_n}p(\lambda_1,\ldots,\lambda_n)$. Hence $f_p$ is homogeneous of degree $d = a_1+\dots+a_n$. Hence \begin{align*} \beta(k[X_1,\ldots,X_n]) &= \beta\pa{\bigoplus_{d\ge 0} k[X_1,\ldots,X_n]_d} = \bigoplus_{d\ge 0}\beta\pa{k[X_1,\ldots,X_n]_d} \\ &\subseteq \bigoplus_{d\ge0}{\Ps_k(V)}_d \subseteq \Ps(V). \end{align*} But \cref{thm:III.17} gives that $\im \beta = \Ps_k(V)$, hence $\bigoplus_{d\ge0}{\Ps_k(V)}_d = \Ps_k(v)$. Altogether $\beta$ is an isomorphism of graded algebras.
\end{proof}

\begin{deff}
  Let $W$ be a $k$-vector space. $f\colon W\to V$ is \emph{polynomial} if the functions $f_i\colon W \to k$ defined by \[f(w) = \sum_{i=1}^nf_i(w)v_i \] are polynomial. Denote $\Ps_k(W,V) := \set{f\colon W\to V \given\text{$f$ polynomial}}$.
\end{deff}

\paragraph{Remark.}
The property is independent of the choice of a basis. Let $w_1,\ldots,w_n$ be a basis of $V$ and $w_i = \sum_{j=1}^n\alpha_{ij}v_j$. Then we have for $w \in W$ \[ f(w) = \sum_{i=1}^n f_i(w) w_i = \sum_{i=1}^n\sum_{j=1}^n f_i(w)\alpha_{ji}v_j. \]
If $f$ is polynomial in the $w_i$ then it is also polynomial in the $v_i$.

\paragraph{Remark.}
Consider the special case $V=k$. Then $f\colon W \to V = k$ is polynomial iff $f \in \Ps_k(W)$.

\begin{lem} \label{lem:III.20}
  Finite dimensional maps together with polynomial maps form a category.
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{lem}
  $\Ps_k(W,V)$ for $W$ a finite-dimensional $k$-vector space is a $\Ps_k(W)$-module via \[ (f.g)(w) = f(w)g(w)  \] for all $w \in W$ for $f\in \Ps_k(W) $ and $g\in \Ps_k(W,V)$.
\end{lem}
\begin{proof}
  Clearly $\Maps(W,V)$ is a $\Maps(W,k)$-module via the same rule. We have to check that $\Ps_k(W,V)$ is preserved under the action of $\Ps_k(W) \subseteq \Maps(W,k)$. So let $f \in \Ps_k(W)$ and $g\in\Ps_k(W,V)$ and let $w_1,\ldots,w_m$ be a basis of $W$. Then
  \begin{align*}
    (fg)\pa{\sum_{i=1}^m\lambda_iw_i} &= f\pa{\sum_{i=1}^m\lambda_iw_i}g\pa{\sum_{i=1}^m\lambda_iw_i} = \sum_{j=1}^m p(\lambda_1,\ldots,\lambda_m) g_j\pa{\sum_{i=1}^m\lambda_iw_i}v_j \\
    &= \sum_{j=1}^m\underbrace{p(\lambda_1,\ldots,\lambda_m)q_j(\lambda_1,\ldots,\lambda_m)}_{=: (fg)_j\pa{\sum_{i=1}^m\lambda_iw_i}}v_j = \sum_{j=1}^m (fg)_j\pa{\sum_{i=1}^m\lambda_iw_i} v_j
  \end{align*}
  for some $p,q_1,\ldots,q_m \in k[X_1,\ldots,X_m]$ as $f$ and the $g_j$ are polynomial. As the $(fg)_j$ are polynomial in $\lambda_1,\ldots,\lambda_n$ we are done.
\end{proof}

\begin{prop} \label{prop:III.22}
  For $f \in \Ps_k(W,V)$ define $f^*\colon \Ps_k(V) \to \Ps_k(W)$ by $f^*(h) = h \circ f$, the \emph{comorphism attached to $f$}. $f^*$ is an algebra homomorphism.
\end{prop}
\begin{proof}
  For $f\in \Ps_k(W,V)$ and $h\in \Ps_k(V)$ we have $h\circ f\in\Ps_k(W)$ by \cref{lem:III.20}. For $h_1,h_2,h \in  \Ps_k(V)$, $\lambda\in k$ and $w\in W$ we get
  \begin{align*}
    (f^*(h_1+h_2))(w) &= (h_1+h_2)(f(w)) = h_1(f(w)) + h_2(f(w)) \\
    &= (f^*(h_1))(w) + (f^*(h_2))(w) = (f^*(h_1) + f^*(h_2))(w) \\
    \intertext{and}
    (f^*(\lambda h))(w) &= (\lambda h)(f(w)) = \lambda h (f(w)) = \lambda (f^*(h))(w) = ((\lambda f^*)(h))(w).
  \end{align*}
  Thus $f^*$ is linear. One easily checks that $f^*(h_1h_2) = f^*(h_1)f^*(h_2)$. Altogether $f^*$ is an algebra homomorphism.
\end{proof}

\lecture{October 29, 2018}

\begin{prop} \label{prop:III.23}
  There is a (contravariant) functor
  \begin{eqnarray*}
    F\colon \Pol_k := \set*{\substack{\text{finite-dimensional $k$-vector spaces}\\\text{with polynomial maps}}} &\to& \set*{\substack{\text{$k$-algebras with}\\\text{algebra homomorphisms}}}^{\op} := \Alg_k^{\op}, \\
    W &\mapsto& \Ps_k(W), \\
    f\in \Ps_k(W,V) &\mapsto& f^*\colon \Ps_k(V) \to \Ps_k(W).
  \end{eqnarray*}
\end{prop}
\begin{proof}
  We know that $\Ps_k(W)$ is a $k$-algebra and $f^*$ an algebra homomorphism by \cref{prop:III.22}. By definition we have $\id_W \mapsto \id_W^* = \id_{\Ps_k(W)}$. Finally we get for $f_1 \in \Ps_k(W,V)$, $f2 \in \Ps_k(Z,W)$ and $h\in \Ps_k(V)$ \[ (f_1 \circ f_2)^*(h) = (f_2^* \circ f_1^*)(h) = (h \circ f_1) \circ f_2 = h \circ (f_1 \circ f_2) = (f_1 \circ f_2)^*(h). \qedhere \]
\end{proof}

\begin{thm}
  The functor $F$ from \cref{prop:III.23} is fully faithful, i.e. the map
  \begin{eqnarray*}
    \Omega\colon \Ps_k(W,V) &\to& \Hom_{\Alg_k}(\Ps_k(V),\Ps_k(W))\\
    f &\mapsto& f^*
  \end{eqnarray*}
  is an isomorphism of $k$-vector spaces for all finite-dimensional $k$-vector spaces $V$ and $W$.
\end{thm}
\begin{proof}
  Clearly $\Omega$ is lineary. We have to show that it is invertible.
  
  Let $v_1,\ldots,v_n$ be a basis of $V$ and consider the isomorphism of algebras
  \begin{eqnarray*}
    \beta\colon k[X_1,\ldots,X_n] &\to& \Ps_k(V) \\
    x_j &\mapsto& \phi_j.
  \end{eqnarray*}
  By the universal property of the polynomial algebra we have
  \begin{eqnarray*}
    \Psi\colon \Ps_k(W)^{\oplus n} &\to& \Hom_{\Alg_k}(k[X_1,\ldots,X_n], \Ps_k(w)) \\
    (f_1,\ldots,f_n) &\mapsto& \Psi(f) := (X_j \mapsto f_j).
  \end{eqnarray*}
  On the other hand we have
  \begin{eqnarray*}
    \Phi\colon \Ps_k(W)^{\oplus n} &\to& \Ps_k(W,V) \\
    (f_1,\ldots,f_n) &\mapsto& f := {w \mapsto \sum_{i=1}^nf_i(w)w_i} \\
    (f_1,\ldots,f_n) &\mapsfrom& f = {w \mapsto \sum_{i=1}^nf_i(w)w_i}.
  \end{eqnarray*}
  As these maps are inverse $\Phi$ is a bijection. Again let $f\in \P_k(W,V)$, $w\in W$ and $f(w) = \sum_{i=1}^nf_i(w)w_i$. Then $f^*(\phi_j)(w) = (\phi_j \circ f)(w) = \phi_j(f(w)) = f_i(w)$, or $f^*(\phi_j) = f_j$ for alle $1\le j\le n$. Therefore by definition \[\Omega(\Psi(f_1,\ldots,f_n)) = \Omega(f) = f^* = \Psi(f_1,\ldots,f_n) \circ \beta^{-1}\] because $f^*(\phi_j) = \Psi(f_1,\ldots,f_n)(\beta^{-1}(\phi_j)$ for all $1\le j \le n$ (and $f^*$ is an algebra homomorphism, hence defined by the $f^*(\phi_j)$).
  
  Now $\Psi$ is invertible, and so is $\Omega \circ \Phi$ and finally $\Omega$.
\end{proof}

\subsection{Covariants}
Let $k$ be a field of infinite cardinality.

\paragraph{Remark.}
Let $\pi\colon W \to V$ be a linear map of finite-dimensional $k$-vector spaces. Then $\pi \in \Ps_k(W,V)$ is homogeneous of degree $1$. To see this choose bases $v_1,\ldots,v_n$ and $w_1,\ldots,w_m$ of $V$ and $W$, respectively. Now we get \[\pi\pa{\sum_{j=1}^m \lambda_jw_j} = \sum_{j=1}^m\lambda_j\underbrace{\pi(w_j)}_{\mathclap{\sum_{i=1}^n\beta_{ij}v_i}} = \sum_{i=1}^n\underbrace{\pa{\sum_{j=1}^m\beta_{ij}\lambda_j}}_{\mathclap{\text{polynomial in $\lambda_1,\ldots,\lambda_m$}}}v_i.\]

Let $G$ be a group and $V$ a finite-dimensional representation of $G$. Then $\Ps_k(V)$ is a representation of $G$ via \[ (g.f)(v) = f(g^{-1}.v) \] for all $g\in G$, $f\in\Ps_k(V)$ and $v \in V$.
We have to show that $g.f$ is again in $\Ps_k(V)$ (the rest is clear, since $V$ is a representation). Now $g .f = f \circ \pi_{g^{-1}}$ is a composition of polynomial maps and therefore by \cref{lem:III.20} polynomial.

\begin{deff}
  Let $G$ be a group and $V,W$ finite-dimensional representations of $G$ (over $k$). A map $f\colon W \to V$ is \emph{covariant} if it is polynomial and $G$-equivariant. Denote $\Cov_k(W,V) = \Cov(W,V) := \set{f\colon W \to V \given \text{$f$ covariant}}$. 
\end{deff}

\begin{enumerate}
  \setcounter{enumi}{-1}
  \item If $f\in \Hom_G(W,V)$ we have $f \in \Cov(W,V)$.
  \item Let $V$ be a finite-dimensional representation of $G$. Then $f \colon V \to V^{\tp d}$ given by $f(x) = x^{\tp d}$ is covariant and homogeneous of degree $d$ because \[ f\pa{\sum_{i=1}^n\lambda_iw_i} = \pa{\sum_{i=1}^n\lambda_iw_i}^{\tp d} = \sum_{{\substack{I=(i_1,\ldots,i_d)\\\in \set{1,\ldots,n}^d}}} \underbrace{\prod_{i\in I}\lambda_i}_{\lambda_I} \underbrace{\bigotimes_{i\in I} v_i}_{v_I}. \]
  Note that $\set*{v_i \given I \in \set{1,\ldots,n}^d}$ forms a basis of $V^{\tp d}$. Definite $p_I\in k[t_1,\ldots,t_n]$ by $p_I(t_1,\ldots,t_n) = t_1^{a_1}\cdots t_d^{a_d}$ where $a_k = \abs{\set{j \given i_j = h}}$. Then $p_I(\lambda_1,\ldots,\lambda_n) = \lambda_I$ and $f$ is polynomial. $f$ is $G$-equivariant since $f(g.v) = (g.v)^{\tp d} = g.v^{\tp d}$. Thus $f$ is covariant.
  \item Let $V = \Mat n k$ and $G = \GL_n(k)$ act on $V$ by conjugation. Then
  \begin{eqnarray*}
   f_m \colon V &\to& V \\ A &\mapsto& A^m
  \end{eqnarray*}
  is covariant for all $m\ge 1$.
\end{enumerate}

\begin{lem}
  Let $V,W$ be finite-dimensional representations of a group $G$. Then $f \colon W \to V$ is covariant if and only if $f^* \colon \Ps_k(V) \to \Ps_k(W)$ is $G$-invariant.
\end{lem}
Note: The action of $G$ on $\Hom_{\Alg_k}(\Ps_k(V), \Ps_k(W))$ is given by $(g.h)(\phi) = g.(h(g^{-1}.\phi))$ for all $g \in G$, $h \in \Hom_{\Alg_k}(\Ps_k(V), \Ps_k(W))$ and $\phi\in \Ps_k(v)$.
\begin{proof}
  Left to the reader.
\end{proof}

\begin{prop}
  Let $V,W$ be finite-dimensional representations of a group $G$ and $f \in \Cov_k(W,V)$. Then \[ f^*\pa{\Ps_k(V)^G} \subseteq \Ps_k(W)^G. \]
\end{prop}
\begin{proof}
  Let $h \in \Ps_k(V)^G$ and $g \in G$. For all $w \in W$ we have
  \begin{align*}
    (g.f^*(h))(w) &= (g.(h\circ f))(w) = (h\circ f)(g^{-1}.w) = h(f(g^{-1}.w)) = h(g^{-1}.f(w)) \\
    &= (g.h)(f(w)) = h(f(w)) = (f^*(h))(w). \qedhereb
  \end{align*}
\end{proof}

\begin{prop}
  Let $V,W$ be finite-dimensional $k$-vector spaces. The $\Ps_k(W)$-module structure on $\Ps_k(W,V)$ induces a $\Ps_k(W)^G$-module structure on $\Cov(W,V)$ if $V,W$ are representations of $G$ by restriction.
\end{prop}
\begin{proof}
  $\Ps_k(W)^G$ is a subring of $\Ps_k(W)$, and by \cref{lem:I.8} even a subalgebra. Let $f\in\Cov(W,V)$, $h\in \Ps_k(W)^G$, $g\in G$ and $w\in W$. Then we have
  \begin{align*}
    (h.f)(g.w) &= h(g.w)f(g.w) = h(w)f(g.w) = h(w)(g.f(w)) = g.(h(w)f(v)) \\ &= g.(h.f)(w),
  \end{align*}
  and hence $h.f$ is $G$-equivariant.
\end{proof}


\section{Invariants of matrix actions}
Let $k$ be a field of infinite cardinality.

\begin{thm}[Invariant Theorem I] \label{thm:inv thm I}
  Let $G = \SL_n(k)$ act on $\Mat n k$ by left multiplication. Then \[\det\colon \Mat n k \to k \] generates $\Ps_k(\Mat n k)^G$ as a $k$-algebra and it is algebraically independent, i.e.
  \begin{eqnarray*}
    k[t] &\to& \Ps_k(\Mat n k)^G \\
    t &\mapsto& \det
  \end{eqnarray*}
  is an isomorphism of $k$-algebras.
\end{thm}
\begin{proof}
  Obviously, $\det$ is polynomial. It is also $G$-invariant, as we have $(S .\det)(A) = \det(S^{-1}A) = \det A$ for all $S \in G$ and $A \in \Mat n k$.
  
  We have to prove that $\det$ is algebraically independent. Let $p \in k[t]$ with $p(\det) = 0$. We get $(p(\det))(A) = p(\det(A)) = 0$ for all $A \in \Mat n k$. Thus, $p(\lambda) = 0$ for all $\lambda \in k$ because $\det$ is surjective. But this implies $p=0$ as $k$ is of infinite cardinality.
  
  It is left to show that $\det$ generates $\Ps_k(\Mat n k)^G$ as an algebra. Let $f \in \Ps_k(\Mat n k)^G$. Since $f$ is polynomial there exists a $p \in k[t_{11},\ldots,t_{nn}]$ such that $f(A) = p(a_{11},\ldots,a_{nn})$ for all $A = \sum_{1\le i,j \le n} a_{ij}E_{ij}$ using a basis $E_{ij}$ ($1\le i,j\le n$).
  
  Consider the algebra homomorphism
  \begin{eqnarray*}
    \Psi\colon k[X_{11},\ldots,X_{nn}] &\to& k[t] \\
    X_{ij} &\mapsto& \begin{cases*}
      0 & if $i \neq j$\\
      1 & if $i = j \neq 1$ \\
      t & if $i = j = 1$.
    \end{cases*}
  \end{eqnarray*}
  Set $\ol p = \Psi(p)$. Then $\ol p(\lambda) = p(\diag(\lambda,1,\ldots,1))$ for $\lambda \in k$. Consider $A \in \GL_n(k)$, $B = \diag(\det A,1,\ldots,1)$ and $S := AB^{-1} \in G$. Then \[ f(A) = f(SB) = f(B) = \ol p(\det A) = (\ol p(\det))(A). \] Therefore $f=\ol p(\det) = 0$ when restricted to $\GL_n(k)$.
  
  We now claim the \emph{Zariski property I}: If $h\in \Ps_k(\Mat n k)$ such that $h|_{\GL_n(k)} = 0$ then $h=0$. We will prove this in \cref{cor:IV.8}.
  
  As a consequence $f=\ol p(\det)$ as elements in $\Ps_k(\Mat n k)^G$. Hence $f$ is contained in the subalgebra generated by $\det$, and $\Ps_k(\Mat n k)^G$ is generated as an algebra by $\det$.
\end{proof}

Let $\chi_A(t) = \det(tI_n-A)$ denote the characteristic polynomial of $A \in \Mat n k$. We can expand this to \[\chi_A(t) = t^n-s_1(A)t^{n-1} + s_2(A)t^{n-2} - \ldots + (-1^n)s_n(A) \] with $s_i \in \Ps_k(\Mat nk)$ for all $1\le i \le n$. For $A= \diag(d_1,\ldots,d_n)$ we have $s_i(A) = e_i^{(n)}(d_1,\ldots,d_n)$.

\lecture{November 5, 2018}

\begin{thm}[Invariant Theorem II] \label{thm:inv thm II}
  Let $G = \GL_n(k)$ act on $\Mat nk$ by conjugation $S.A = SAS^{-1}$ for $S \in \GL_n(k)$ and $A \in \Mat nk$. Then $\Ps_k(\Mat nk)^G$ is generated as a $k$-algebra by $s_1,\ldots,s_n$. Moreover these elements are algebraically independent over $k$, i.e.
  \begin{eqnarray*}
    \Ps_k(\Mat nk)^G &\to& k[t_1,\ldots,t_n] \\
    s_i &\mapsto& t_i
  \end{eqnarray*}
  is an isomorphism of $k$-algebras.
\end{thm}
\begin{proof}
  Obviously, $s_i \in \Ps_k(\Mat nk)$. They are $G$-invariant because $\chi_A(t)$ is invariant under conjugation. Thus $s_i \in \Ps_k(\Mat nk)^G$ for all $1\le i\le n$.
  
  Now let us show that the $s_i$ are algebraically independent. Take $p\in k[t_1,\ldots,t_n]$ such that $p(s_1,\ldots,s_n)=0$. Then $p(s_1,\ldots,s_n)(A) = 0$ for all $A \in \Ps_k(\Mat nk)$, so also for all diagonal matrices $\diag(d_1,\ldots,d_n)$. Using our observation from above we get $p\pa{e_1^{(n)},\ldots,e_n^{(n)}}(d_1,\ldots,d_n) = 0$ for all $d_i \in k$. Thus $p\pa{e_1^{(n)},\ldots,e_n^{(n)}} = 0$. By the \namereff{thm:symmetric polys} we get $p=0$ as the $e_i^{(n)}$ are algebraically independent.
  
  We still need to prove that the $s_i$ generate $\Ps_k(\Mat nk)^G$ as an algebra. Take $f\in \Ps_k(\Mat nk)^G$. Since it is polynomial, there exists a $p\in k[t_{11},\ldots,t_{nn}]$ such that $f(A) = p(a_{11},\ldots,a_{nn})$ for $A = (a_{ij})$. Define the algebra homomorphism
  \begin{eqnarray*}
    \Phi\colon k[t_{11},\ldots,t_{nn}] &\to& k[t_1,\ldots,t_n] \\
    t_{ij} &\mapsto& \begin{cases*} t_i & if $i=j$ \\ 0 & otherwise \end{cases*}
  \end{eqnarray*}
  and $\ol p := \Phi(p)$. Hence $f(\diag(d_1,\ldots,d_n)) = \ol p(d_1,\ldots,d_n)$ by definition.
  
  Now we want to show that $\ol p$ is symmetric, i.e. $\ol p \in k[t_1,\ldots,t_n]^{S_n}$. We already have an isomorphism of algebras
  \begin{eqnarray*}
    \beta\colon k[t_1,\ldots,t_n] &\to& \Ps_k(k^n) \\
    t_i &\mapsto& \phi_i\;\text{(coordinate function)}
  \end{eqnarray*}
  in standard basis. Now $\beta$ is $S_n$-equivariant if we let $S_n$ act on $k^n$ by permuting the standard basis vectors $e_i$. It is enough to show that $\beta(\ol p)$ is $S_n$ invariant. Realise $g \in S_n$ as a permutation matrix $A_g$ such that $A_gE_i = E_{g(i)}$. For $D=\diag(d_1,\ldots,d_n)$ we have $A_gDA_{g^{-1}} = \diag\pa{d_{g^{-1}(1)},\ldots,d_{g^{-1}(n)}}$. We gets
  \begin{align*}
    (g.\beta(\ol p))(d_1,\ldots,d_n) &= \beta(\ol p)\pa{g^{-1}.(d_1,\ldots,d_n)} = \beta(\ol p)\pa{d_{g^{-1}(1)},\ldots,d_{g^{-1}(n)}} \\
    &= f\pa{\diag\pa{d_{g^{-1}(1)},\ldots,d_{g^{-1}(n)}}} = f\pa{A_{g^{-1}}DA_g} \\
    &= f\pa{A_{g_{-1}}D\pa{A_{g^{-1}}}^{-1}} = f(D)
  \end{align*}
  for all $g\in S_n$ as $f$ is $G$-invariant. Thus $\ol p$ is a symmetric polynomial.
  
  By the \namereff{thm:symmetric polys} we have a $q\in k[t_1,\ldots,t_n]$ with $\ol p = q\pa{e_1^{(n)},\ldots,e_n^{(n)}}$. For $D = \diag(d_1,\ldots,d_n)$ we have \[f(D) = q\pa{e_1^{(n)},\ldots,e_n^{(n)}}(d_1,\ldots,d_n) = q(s_1,\ldots,s_n)(D).\] Therefore $f-q(s_1,\ldots,s_n) = 0$ whe restricted to diagonal matrices.
  
  We now claim the \emph{Zariski property II}: If $h\in \Ps_k(\Mat nk)^G$ such that $h|_{\substack{\text{\tiny diagonal}\\\text{\tiny matrices}}} = 0$ then $h = 0$. We will prove this later (see \cref{lem:IV.11}).
  
  As a consequence $f - q(s_1,\ldots,s_n)  = 0$ (on all matrices in $\Mat nk$). It follows that $s_1,\ldots,s_n$ generate $\Ps_k(\Mat nk)^G$.
\end{proof}

Another family of elements in $\Ps_k(\Mat nk)^{\GL_n(k)}$ (under conjugation action) are the \emph{power traces}
\begin{eqnarray*}
  \Tr_j\colon \Mat nk &\to& k \\
  A &\mapsto& \Tr(A^j).
\end{eqnarray*}
Obviously $\Tr_j \in \Ps_k(\Mat nk)$. They are $\GL_n(k)$-invariant as we have \[ (S.\Tr_j)(A) = \Tr_j(S^{-1}AS) = \Tr(S^{-1}A^jS) = \Tr(A^j) = \Tr_j(A) \] for all $S \in \GL_n(k)$ and $A \in \Mat nk$.

\begin{thm}
  Let $n\ge 1$ and $k$ an infinite field with $\chr k = 0$ or $\chr k > n$. Then $\Tr_1,\ldots,\Tr_n$ generate $\Ps_k(\Mat nk)^{GL_n(k)}$ as a $k$-algebra and are algebraically independent. Hence
  \begin{eqnarray*}
    k[t_1,\ldots,t_n] &\to& \Ps_k(\Mat nk)^{\GL_n(k)} \\
    t_j &\mapsto& \Tr_j
  \end{eqnarray*}
  defines an isomorphism of $k$-algebras.
\end{thm}
\begin{proof}
  Let $D = \diag(d_1,\ldots,d_n)$ be a diagonal matrix. Then \[\Tr_j(D) = \Tr(D^j) = \sum_{i=1}^nd_1^j = p_j^{(n)}(d_1,\ldots,d_n).\] By \cref{thm:III.14} the $p_i^{(n)}$ generate $k[X_1,\ldots,X_n]^{S_n}$ as a $k$-algebra (under the given assumptions in $k$) and they are algebraically independent. Now argue as in the proof of the \namereff{thm:inv thm II} with $e_j^{(n)}$ replaced by $p_j^{(n)}$.
\end{proof}

\begin{deff}
  Let $W$ be a finite-dimensional $k$-vector space ($k$ infinite field). $X \subseteq W$ is \emph{Zariski-dense} (over $k$) if $f|_X = 0$ implies $f = 0$ for all $f\in \Ps_k(W)$. Let $X \subseteq Y \subseteq W$. Then $X$ is \emph{Zariski-dense in $Y$} (over $k$) if $f|_X = 0$ implies $f|_Y = 0$ for all $f\in \Ps_k(W)$.
\end{deff}

\paragraph{Examples.}
\begin{enumerate}
 \setcounter{enumi}{-1}
 \item An infinite subset $X \subseteq k$ is Zariski-dense.
 \item Let $U \subsetneq W$ be a vector subspace. Then $U$ is not Zariski-dense in $W$.
 \begin{proof}
    Let $w_1,\ldots,w_u$ be a basis of $U$. Extend it to a basis $w_1,\ldots,w_n$ of $W$. Consider the map
    \begin{eqnarray*}
      \pi\colon W &\to& k \\
      \sum_{i=1}^n\lambda_iw_i &\mapsto& \lambda_nw_n.
    \end{eqnarray*}
    Obviously $\pi\in\Ps_k(W)$. Now note that $\pi|_U = 0$, but $\pi\neq 0$.
 \end{proof}
\end{enumerate}

\paragraph{Remark.}
Zariski density depends on $k$, e.g. $\IR \subseteq \IC$ is not dense over $\IR$ but it is over $\IC$.

\begin{lem} \label{lem:IV.4}
  Let $k$ be an infinite field and $k \subseteq L$ a field extension as well as $W$ a finite-dimensional $k$-vector space. Let $W_L := L \tp_k W$.
  \begin{enumerate}
    \item $k^n \subseteq L^n$ is Zariski-dense over $L$ for all $n\ge 1$.
    \item\label{lem:IV.4:2} $W \subseteq W_L$ (by $w \mapsto 1 \tp w$) is also Zariski-dense over $L$.
  \end{enumerate}
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{lem} \label{lem:IV.5}
  Let $k$ be an infinite field and $k \subseteq L$ a field extension as well as $W$ a finite-dimensional $k$-vector space. Let $W_L := L \tp_k W$. Then there exists a unique algebra homomorphism $\incl\colon\Ps_k(W) \to \Ps_L(W_L)$ such that the diagram
  \begin{center}
    \begin{tikzcd}
      W \arrow{r}{\can}[swap]{w\mapsto 1 \tp w}\arrow{d}[swap]{f} & W_L \arrow{d}{\incl(f)} \\
      k \arrow[hookrightarrow]{r} & L
    \end{tikzcd}
  \end{center}
  commutes for all $f\in \Ps_k(W)$. Moreover $\incl(f)$ is surjective.
\end{lem}
\begin{proof}
  Let $w_1,\ldots,w_n$ be a basis of $W$. Let $\phi_1,\ldots,\phi_n$ be the coordinate functions in $\Ps_k(W)$. Then $1\tp w_1,\ldots,1\tp w_n$ is a basis of $W_L$. Let $\psi_1,\ldots,\psi_n$ be the corresponding coordinate functions in $\Ps_L(W_L)$. Define $\incl(\phi_i) = \psi_j$. This results in a unique $k$-algebra homomorphism since the $\psi_1,\ldots,\psi_n$ are algebraically independent over $L$. The map is injective as the basis $\phi_i^a = \phi_i^{a_1}\cdots\phi_i^{a_n}$ with $a = (a_1,\ldots,a_n) \in \IZ_{\ge 0}^n$ is mapped to linearly independent elements.
 
  Now we show that the above diagram commutes. For $f\in\Ps_k(W)$ we write $f = p(\phi_1,\ldots,\phi_n)$ for some polynomial $p\in k[t_1,\ldots,t_n]$. Then
  \begin{align*}
    (\incl(f) \circ \can)\pa{\sum_{i=1}^n\lambda_iw_i} = p(\psi_1,\ldots,\psi_n)\pa{\sum_{i=1}^n\lambda_i(1\tp w_i)} &= p(\lambda_1,\ldots,\lambda_n), \\\intertext{but on the other hand}
    f\pa{\sum_{i=1}^n\lambda_iw_i} = p(\phi_1,\ldots,\phi_n)\pa{\sum_{i=1}^n\lambda_iw_i} &= p(\lambda_1,\ldots,\lambda_n).
  \end{align*}
  
  Finally, assume that $\incl'$ is another such algebra homomorphism. We have $\incl(f) = \incl'(f) \in \Ps_L(W_L)$ for all $f\in \Ps_k(W)$. By definition $(\incl(f) - \incl'(f))|_W = 0$. By \cref{lem:IV.4} \ref{lem:IV.4:2} $W \subseteq W_L$ is dense over $L$. Therefore $\incl(f) = \incl'(f)$ for all $f \in \Ps_L(W_L)$.
\end{proof}

\begin{cor}
  Let $k$ be an infinite field and $k \subseteq L$ a field extension as well as $W$ a finite-dimensional $k$-vector space. Let $W_L := L \tp_k W$. Then
  \begin{eqnarray*}
    \Phi\colon {\Ps_k(W)}_L &\to& \Ps_L(W_L) \\
    \lambda \tp f &\mapsto& \lambda\incl(f)
  \end{eqnarray*}
  is an isomorphism of $k$-algebras.
\end{cor}
\begin{proof}
  Take $k$-bases $\phi^a$ and $\psi^a$ of $\Ps_k(W)$ and $\Ps_L(W_L)$ for $a \in \IZ_{\ge0}^n$, respectively. Then $\Phi(1 \tp \phi^a) = \incl(\phi^a) = \psi^a$, a basis vector over $L$. Hence $\Phi$ is an isomorphism of $k$-vector spaces since it sends a basis to a basis. It is an algebra homomorphism by \cref{lem:IV.5}.
\end{proof}

\begin{lem} \label{lem:IV.7}
  Let $k$ be an infinite field and $W$ a finite-dimensional $k$-vector space. For $h\in\Ps_k(W)\setminus\set0$ define $W_h := \set{w\in W\given h(w) \neq 0}$. Then $W_h \subseteq W$ is Zariski-dense (over $k$).
\end{lem}
\begin{proof}
  Let $f \in \Ps_k(W)$ with $f|_{W_h} = 0$. Then $fh = 0$ as we have $(fh)(w) = f(w)h(w) = 0$ for all $w \in W$. Since $\Ps_k(W)$ is an integral domain we have $f=0$ since $h \neq 0$.
\end{proof}

\begin{cor} \label{cor:IV.8}
  $\GL_n(k) \subseteq \Mat nk$ is Zariski-dense (over $k$). This proves Zariski property I.
\end{cor}
\begin{proof}
  Use \cref{lem:IV.7} with $W = \Mat nk$ and $h= \det$.
\end{proof}

\lecture{November 8, 2018}

In the proofs of \nameref{thm:inv thm I} and \nameref{thm:inv thm II} we assumed the following properties:
\begin{description}
  \item[Zariski property I:] If $f\in\Ps_k(\Mat nk)$ such that $f|_{\GL_n(k)} = 0$ then $f=0$.
  \item[Zariski property II:] If $f\in\Ps_k(\Mat nk)^{\GL_n(k)}$ such that $f|_{\substack{\text{\tiny diagonal}\\\text{\tiny matrices}}} = 0$ then $f=0$.
\end{description}

We already proved Zariski property I in \cref{cor:IV.8}.

\begin{lem} \label{lem:IV.9}
  Let $G$ be a group, $W$ a finite-dimensional representation of $G$ over $k$ and $f\in\Ps_k(W)^G$.
  \begin{enumerate}
    \item If $X\subseteq W$ such that $G.X = \set{g.x \given g\in G,x \in X}$ is Zariski-dense and if $f|_X = 0$ then $f=0$. \label{lem:IV.9:1}
    \item If there exists a Zariski-dense orbit then $f$ is constant. \label{lem:IV.9:2}
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:IV.9:\arabic*}]
    \item As $f$ is $G$-invariant we have $f(g.x) = f(x) = 0$ for all $g\in G$ and $x\in X$. Thus, $f|_{G.X} = 0$, and $f=0$ as $G.X$ is Zariski-dense.
    \item As $f$ is $G$-invariant it is constant on $G$-orbits. Let $O$ be a dense $G$-orbit. Then there exists a $\lambda\in k$ such that $(f-\lambda)|_O = 0$. As $O$ is dense, we get $f-\lambda = 0$ or $f=\lambda$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{prop} \label{prop:IV.10}
  Let $k=\ol k$. Define \[ \Diag_n(k) := \set*{A\in \Mat nk\given \text{$A$ diagonizable}}. \] Then $\Diag_n(k)$ is Zariski-dense in $\Mat nk$.
\end{prop}
\begin{proof}
  Let $f\in\Ps_k(\Mat nk)$ such that $f|_{\Diag_n(k)}=0$. We show that $f=0$. Let $A \in \Mat nk$. As $k=\ol k$, $A$ has a Jordan normal form, i.e. $S \in \GL_n(k)$ such that $SAS^{-1}$ is in Jordan normal form with diagonal entries $b_1,\ldots,b_n \in k$ (not necessarily distinct). Define functions $D,M,\phi\colon k\to \Mat nk$ as follows. Fix pairwise distinct $a_1,\ldots,a_n \in k$ (possible since $\abs k = \infty$). Now set
  \begin{align*}
    D(z) &= z\diag(a_1,\ldots,a_n), \\
    M(z) &= SAS^{-1} + D(z), \\
    \phi(z) &= S^{-1}M(z)S = A + S^{-1}D(z)S.
  \end{align*}
  Note that the eigenvalues of $\phi(z)$ are $b_1 + a_1z,\ldots,b_n+a_nz$ and $\phi(0) = A$.
  
  The eigenvalues of $\phi(z)$ are pairwise distinct for all but finitely many $z\in k$. To see this choose $z\in k$ such that $b_i + a_iz = b_j+ a_jz$ for $i\neq j$. Then $z = \frac{b_i-b_j}{a_j-a_i}$. So $z$ is uniquely determined by this equation.
  
  Thus $\phi(z) \in \Diag_n(k)$ and $f(\phi(z)) = 0$ for all but finitely many $z\in k$. Now we have $f\circ \phi \in \Ps_k(W)$ such that $f\circ \phi$ vanishes on all but finitely many $z\in k$. But as $\abs k =\infty$ we get $f\circ\phi = 0$ and $0 = f(\phi(0)) = f(A)$.
\end{proof}

In particular Zariski property II holds for $k=\ol k$: Take $f\in\Ps_k(\Mat nk)^{\GL_n(k)}$ such that $f|_{\D_n(k)} = 0$ where $D_n(k)$ is the set of diagonal matrices in $\Mat nk$. By \cref{lem:IV.9} we get $f|_{\Diag_n(k)} = 0$ and by \cref{prop:IV.10} $f = 0$.

\begin{lem} \label{lem:IV.11}
  Let $k$ be an infinite field and $L=\ol k$. If $f\in\Ps_k(\Mat nk)^{\GL_n(k)}$ then $\incl(f)\in\Ps_L(\Mat nk)^{\GL_n(k)}$.
\end{lem}

\bigskip

We claim that this Lemma implies Zariski property II.
\begin{proof}
  Let $f\in\Ps_k(\Mat nk)^{\GL_n(k)}$ such that $f|_{\D_n(k)}=0$. Consider $\hat f = \incl(f)$. By definition of $\incl$ we have $\hat f(A) = f(A)$ for all $A \in \D_n(k)$ (note that $\D_n(k) \subseteq D_n(L) = {\D_n(k)}_L$ by scalar extension). Thus $\hat|_{\D_n(k)} = 0$. As $\D_n(k)$ is Zariski-dense in $\D_n(L) = {\D_n(k)}_L$ by \cref{lem:IV.4} \ref{lem:IV.4:2} we get $\hat f|_{D_n(L)} = 0$. Then $\hat f = 0$ by \cref{lem:IV.11} and the discussion above. As $\incl$ is injective by \cref{lem:IV.5} we have $f=0$.
\end{proof}

\begin{proof}[Proof of \cref{lem:IV.11}]
  Let $f\in\Ps_k(\Mat nk)^{\GL_n(k)}$. Denote $\hat f = \incl(f)$. Define
  \begin{eqnarray*}
    \gamma\colon \Mat nk \times \Mat nL &\to& L \\
    (A,B) &\mapsto& \hat f (AB) - \hat f(BA). % defect
  \end{eqnarray*}
  We want to show that $\gamma = 0$. For $S \in \GL_n(k)$ and $A\in\Mat nk$ we have $f(SA) = f(SASS^{-1}) = f(AS)$ as $f$ is $\GL_n(k)$-invariant. Thus $\hat f(AS) = f(AS) = f(SA) =\hat f(SA)$ and $\gamma(S,A) = 0$ for all $S \in \GL_n(k)$ and $A \in \Mat nk$.
  
  Fix $S \in \GL_n(k)$ and define
  \begin{eqnarray*}
    \gamma_S\colon \Mat nL &\to& L \\
    A &\mapsto& \gamma(S,A).
  \end{eqnarray*}
  We have $\gamma_S \in \Ps_L(\Mat nL)$ and $\gamma_S|_{\Mat nk} = 0$. As $\Mat nk$ is dense in ${\Mat nk}_L = \Mat nL$ (over $L$) we get $\gamma_S = 0$. Therefore $\gamma(S,A) = 0$ for all $S \in \GL_n(k)$ and $A \in \Mat nL$.
  
  Fix $A \in \Mat nL$ and define
  \begin{eqnarray*}
    \gamma^A\colon \Mat nL &\to& L \\
    B &\mapsto& \gamma(B,A).
  \end{eqnarray*}
  Again $\gamma^A\in \Ps_L(\Mat nL)$ and $\gamma^A|_{\GL_n(k)} = 0$. The reader may check that $\GL_n(k)$ is Zariski-dense in $\Mat nL$ over $L$. Then $\gamma^A = 0$. As $A$ as arbitrary we get $\gamma = 0$.
  
  Now let $S \in \GL_n(L)$ and $A\in\Mat nL$. Then $\hat f(SAS^{-1}) = \hat f (AS^{-1}S) = \hat f (A)$, and $\hat f \in\Ps_l(\Mat nL)^{\GL_n(L)}$.
\end{proof}

\section{Semisimple modules and the Artin-Wedderburn theorem}
In this section $R$ is a ring with $1$, but not necessarily commutative. Modules are left modules.

\subsection{Semisimple modules}
\begin{deff}
  An $R$-module $M$ is called \emph{irreducible} if $M\neq 0$ and if $M$ has no other submodules other than $0$ and $M$.
\end{deff}

\begin{prop} \label{prop:V.1}
  Let $M$ be an $R$-module. Then the following are equivalent:
  \begin{enumerate}
    \item $M$ is the sum off irreducible submodules, i.e. there exists a collection $(L_i)_{i\in I}$ of irreducible submodules $L_i \subseteq M$ such that $M= \sum_{i\in I}M_i$.
    \item $M$ is isomorphic to a direct sum of irreducible $R$-modules, i.e. there exists a collection $(L_i)_{i\in I}$ of irreducible $R$-modules $L_i$ such that $M \cong \bigoplus_{i\in I}L_i$.
    \item Every submodule of $M$ has a complement, i.e. for every submodule $M' \subseteq M$ there exists a submodule $M'' \subseteq M$ such that $M' \cap M''$ and $M' + M'' = M$.
  \end{enumerate}
\end{prop}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{deff}
  An $R$-module is called \emph{semisimple} if it satisfies one of the equivalent conditions from \cref{prop:V.1}.
\end{deff}

\paragraph{Examples.}
\begin{enumerate}
  \item Let $R=k$ a field. The irreducible $R$-modules are the $1$-dimensional $k$-vector spaces as every $k$-vector space has a basis. Thus every $k$-vector space is semisimple.
  \item Let $k$ be a field and \[R=\set*{\begin{pmatrix}a&b\\0&c\end{pmatrix} \given a,b,c\in k}.\] Let $M=k^2$ with the obvious $R$-module structure. Then $M' = \gen{\begin{pmatrix}1\\0\end{pmatrix}}_k$ is a proper submodule, and $M$ is not irreducible. But $M'$ does not have a complement, thus $M'$ does not have a complement, and $M$ is not semisimple.
  \item Let $G$ be a finite group and $R=kG$ such that $\chr k \nmid \abs G$. By \namereff{thm:maschke} every finite-dimensional $kG$-module is semisimple.
\end{enumerate}

\begin{lem} \label{lem:V.2}
  \leavevmode
  \begin{enumerate}
    \item If $(M_i)_{i\in I}$ is a collection of semisimple $R$-modules then $\bigoplus_{i\in I}M_i$ is semisimple. \label{lem:V.2:1}
    \item Let $M$ be semisimple and $N\subseteq M$ a submodule. Then $N$ and $\fak MN$ are semisimple. \label{lem:V.2:2}
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:V.2:\arabic*}]
    \item As the $M_i$ are semisimple there exist irreducible modules $L_i^{(j)}$ with $j \in J_i$ such that $M_i \cong \bigoplus_{j\in J_i}L_i^{(j)}$. Then we have \[\bigoplus_{i\in I}\bigoplus_{j\in J_i}L_i^{(j)} = \bigoplus_{i\in I} M_i.\]
    \item \begin{description}
      \item[$N$ is semisimple:] It is enough to show that any submodule of $N$ has a complement in $N$. Consider a submodule $U\subseteq N$ which also is a submodule of $M$. Since $M$ is semisimple there exists a complement $C$ of $U$ in $M$, i.e. $M= U \oplus C$ as $R$-modules. Set $C' = N\cap C$. We want to show that $N=U \oplus C'$. Take $y \in N$. Then we have $n\in U$ and $c \in C$ such that $y=u+c$. Now $c = y-u\in N$ since $u\in U \subseteq N$. Then $c \in C \cap N = C'$. We get $N = U+C'$ and then $N=U\oplus C'$ since $U\cap C=0$.
      \item[$\fak MN$ is semisimple:] We have $\fak MN \cong C'$ as $R$-modules. Since $C'$ is a submodule of $N$ it is semisimple by \ref{lem:V.2:1}. Hence $\fak MN$ is semisimple.
      \qedhere
    \end{description}
  \end{enumerate}
\end{proof}

\lecture{November 12, 2018}

\begin{deff}
  Let $M$ be an $R$-module and $L$ an irreducible $R$-module. Then \[\Iso_L(M) := \sum_{\mathclap{\substack{\text{$E \subseteq M$ submodule}\\\text{$E\cong L$ as $R$-modules}}}}E \] is the \emph{$L$-isotypic component} of $M$.
\end{deff}

\begin{lem}[Schur's lemma] \label{lem:schur mod}
  Let $M$ be an irreducible $R$-module. Then:
  \begin{enumerate}
    \item Let $N$ be an irreducible $R$-module and $f\colon M\to N$ an $R$-module homomorphism. Then $f=0$ or $f$ is an isomorphism. \label{lem:schur mod:1}
    \item $\End_R(M)$ is a skew field (i.e. a field, but the multiplication is not necessarily commutative). \label{lem:schur mod:2}
  \end{enumerate}
  If $R$ is moreover a $k$-algebra:
  \begin{enumerate}
    \setcounter{enumi}{2}
    \item $\End_R(M)$ is a division algebra (i.e. an algebra where all nonzero elements have a multiplicative inverse). \label{lem:schur mod:3}
    \item If $\ol k = k$ and $\dim_k M <\infty $ then $\End_R(M) \cong k$ by $\lambda{\id_M} \mapsfrom \lambda$. \label{lem:schur mod:4}
  \end{enumerate}
\end{lem}
\begin{proof}
  We omit the proofs of \ref{lem:schur mod:1}, \ref{lem:schur mod:2} and \ref{lem:schur mod:3} (see the proof of \namereff{lem:schur} for representations).
  
  Now we show \ref{lem:schur mod:4}. We claim that if $D$ is a division algebra (over $k$) and $\dim_kD<\infty$ we have $D=k$. To see this let $0\neq a \in D$. The elements $1,a,a^2,\ldots,$ are linearly dependent because $\dim_kD < \infty$. Therefore we have a $p \in k[t]$ with $p(a) = 0$ and $p\neq 0$. Since $k=\ol k$ we have $p(t) = \prod_{i=1}^n(t-a_i)$ for some $a_i \in k$. Now $0 = p(a) = \prod_{i=1}^n(a-a_i)$, and we get $a=a_i$ for some $i$. Thus $a \in k$ and $D=k$.
  
  Now $\End_R(M) \subseteq \End_k(M)$ is finite dimensional by assumption, hence by \ref{lem:schur mod:3} a finite dimensional divison algebra. Our claim implies \ref{lem:schur mod:4}.
\end{proof}

\begin{lem} \label{lem:V.4}
  Let $M$ be a semisimple $R$-module. Let $\phi\colon \bigoplus_{i\in I}L_i \to M$ be an isomorphism of $R$-modules with $L_i$ ($i\in I$) irreducible. Then \[ \Iso_L(M) = \phi\pa{\bigoplus_{j\in J}L_j}\] where $J=\set{i\in I\given L_i \cong L}$.
\end{lem}
\begin{proof}
  Since $\phi$ is an $R$-module isomorphism (hence injective) we have $\phi\pa{\bigoplus_{i\in I} L_i} = \bigoplus_{i\in I}\phi(L_i)$ and $\phi(L_i) \cong L_i$ for all $i\in I$ (by \namereff{lem:schur mod}).
  \begin{description}
    \item[\enquote{$\supseteq$}:] ${\displaystyle \phi\pa{\bigoplus_{j\in J}L_j} =\bigoplus_{j\in J}\underbrace{\phi(L_j)}_{\cong L_j \cong L} = \sum_{j\in J}\phi(L_j) \subseteq \Iso_L(M)}$.
    \item[\enquote{$\subseteq$}:] Assume $\Iso_L(M) \nsubseteq \phi\pa{\bigoplus_{j\in J}L_j}$. Then there exists a $i_0 \in I$ such that $i_0 \notin J$ and the map \[f\colon \Iso_l(M) \hookrightarrow M \to \phi(L_{i_0})\] ($M\to \phi(L_{i_0})$ by projection) is nonzero. Then there exists a submodule $L\subseteq M$ such that $f|_L \neq 0$ and $f$ defines a nonzero $R$-module homomorphism $L\to \phi(L_{i_0}) \cong L_{i_0}$, contradictory to \namereff{lem:schur mod} since $i_0\notin J$.
    \qedhere
  \end{description}
\end{proof}

\begin{deff}
  We define \[\Irr(R) := \set*{\substack{\text{isoclasses of irre-}\\\text{ducible $R$-modules}}} := \fak{\set*{\substack{\text{irreducible}\\\text{$R$-modules}}}}\sim\] where $L\sim L'$ if $L\cong L'$ as $R$-modules. We often fix a system of representatives for the isoclasses and identify the set of representatives with $\Irr(R)$.
\end{deff}

\paragraph{Remark.}
$\Irr(R)$ is indeed a set.
\begin{proof}
  Let $L$ be an irreducible $R$-module. Pick $0 \neq m\in L$. This generates $L$ as an $R$-module. We get a surjective $R$-module homomorphism
  \begin{eqnarray*}
    \phi\colon R &\to& L \\
    1 &\mapsto& m.
  \end{eqnarray*}
  Henc $\fak R{\ker\phi} \cong L$ and $\ker\phi = \Ann_R(m)$ is a left ideal. Since $L$ is irreducible, $\ker\phi$ is in fact maximal. But maximal left ideals form a set.
\end{proof}

\paragraph{Example.}
$R=k$ a field. If $V$ is an $R$-module (i.e. $k$-vector space) then $\gen v \subseteq V$ is a submodule of $V$ for all $v\in V$. Thus $\Irr(R) = \set k$.

\begin{lem}
  Let $M$ be a semisimple $R$-module. Then we have \[ M = \bigoplus_{\mathclap{L\in\Irr(R)}}\Iso_L(M), \] the \emph{isotypic decomposition}.
\end{lem}
\begin{proof}
  As $M$ is semisimple there exists an isomorphism of $R$-modules $ \phi\colon \bigoplus_{i\in I} L_i \to M $ with irreducible modules $L_i$ ($i \in I$). Now group summands which belong to the same isomorphism class in $\Irr(R)$ and use \cref{lem:V.4}.
\end{proof}

\paragraph{Example.}
If $R=k$ a field then \[ M = \bigoplus_{\mathclap{L\in\Irr(k) = \set k}}\Iso_L(M) = \underbrace{\Iso_k(M)}_{\mathclap{\text{$k$-isotypic component}}} \] and we get $M \cong \bigoplus_{i\in I}k$. The existence of such an isomorphism is equivalent to the existence of a basis. Each such iso corresponds to a choice of a basis.

\subsection{Hilbert's theorem}
\begin{thm}[Hilbert's theorem] \label{thm:hilbert}
  Let $G$ be a group and $W$ a finite-dimensional representation of $G$ over $k$ ($k$ an infinite field). Assume $\Ps_k(W) \cong \bigoplus_{i\in I}L_i$ as representations of $G$ with irreducible $L_i$ ($i\in I$). Then $\Ps_k(W)^G$ is finitely generated as a $k$-algebra.
\end{thm}

\paragraph{Remark.}
The assumption says precisely that $\Ps_k(W)$ is a semisimple $kG$-module.

\paragraph{Remarks.}
\begin{itemize}
  \item If $G$ is a finite group and $\chr k\nmid \abs G$ then $\Ps_k(W) = \bigoplus_{d\ge 0}{\Ps_k(W)}_d$ (see \cref{prop:III.19}) is a graded algebra with finite-dimensional homogeneous components ${\Ps_k(W)}_d$ with are then finite-dimensional representations of $G$.
  
  By \namereff{thm:maschke} $\Ps_k(W)$ is semisimple and so $\Ps_k(W) = \bigoplus_{d\ge0}{\Ps_k(W)}_d$ is semisimple by \cref{lem:V.2}.
  \item In the case $R=kG$ for some group $G$ the semisimplicity is often called \emph{complete reducibility}.
\end{itemize}

\paragraph{Goal.} We want to find examples where \namereff{thm:hilbert} holds. This will lead us to \emph{reductive groups} ($\SL_n(k)$, $\GL_n(k)$, algebraically closed fields, \ldots).

\begin{lem} \label{lem:V.7} % V.6
  Let $B=\bigoplus_{d\ge0}B_d$ be a non-negatively graded $k$-algebra. Consider the (two-sided) ideal $B_+ \cong \bigoplus_{d>0}B_d$. If $B_d$ is a finitely generated ideal in $B$, then $B$ is finitely generated as a $B_0$-algebra. Moreover one can finite a finite generating set of homogeneous elements.
\end{lem}
\begin{proof}
  Left to the reader.
\end{proof}

\begin{lem} \label{lem:V.8} % V.7
  Let $A$ be a commutative $k$-algebra, $G$ a group acting on $A$ by algebra automorphisms. Assume $A = \sum_{i\in I}L_i$ as representations of $G$ with the $L_i$ ($i\in I$) irreducible. (i.e. $A$ is a semisimple $kG$-module). Then:
  \begin{enumerate}
    \item $A = A^G \bigoplus N$ as representations where $A^G = \sum_{j\in J} L_j$ and $N = \sum_{i\in I\setminus J}L_i$ with $J = \set{i\in I\given L_i \cong T}$ and the trivial representation $T$. \label{lem:V.8:1}
    \item The \emph{Reynolds operator} $\pi\colon A \to A^G$ (projection) satisfies $\pi(ba) = b\pi(a)$ for all $b\in A^G$ and $a\in A$. \label{lem:V.8:2}
  \end{enumerate}
\end{lem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{lem:V.8:\arabic*}]
    \item This follows from the isotypic decomposition $A^G = \Iso_T(A)$ and \[N= \bigoplus_{\mathclap{\substack{L\in\Irr(kG)\\ L\ncong T}}}\Iso_L(A).\]
    \item For $s \in A^G$ consider $m_b\colon A \to A$ by $a \mapsto ba$. This is an morphism of representations as we have $m_b(g.a) = b(g.a) = (g.b)(g.a) = g.(ba) = g.m_b(a)$ for all $a \in A$ and $g\in G$. By \namereff{lem:schur mod} the restriction of $m_b$ to any $L_i$ has image isomorphic to $L_i$ or $0$. Thus $m_b(A^G) \subseteq A^G$ and $m_b(N) \subseteq N$. For $b\in A^G$ and $a \in A$ we have $\pi(ba) = \pi(ba_1+a_2) = ba_1 = b\pi(a)$ where $a = a_1+a_2$ with $a_1 \in A^G$ and $a_2 \in N$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{proof}[Proof of \namereff{thm:hilbert}]
  Set $A := \Ps_k(W)$. We know that $A = \bigoplus_{d\ge 0}A_d$. By \cref{lem:V.8} we have $A = A^G \oplus N$ (with the notation from there). If $I \subseteq A^G$ is an ideal then
  \begin{equation}
    \pi(IA) = I\pi(A) = IA^G = I \tag{*}\label{eq:thm:hilbert}
  \end{equation}
  using the definition of $\pi$ and $1\in A^G$. By \cref{lem:III.5/6} we have $A^G = \bigoplus_{d\ge0}A_d^G$ and we can take $I := A^G_+ = \bigoplus_{d>0}A_d^G$. Then $\tilde I = IA$ is the ideal in $A$ generated by $I$. Since $A$ is noetherial (because $A \cong k[X_1,\ldots,X_n]$) we can find $f_1,\ldots,f_m\in I$ which generate $\tilde I$ (for some $m\in\IN$).
  
  We claim that $f_1,\ldots,f_m$ generate $I$ as in ideal in $A^G$. By \eqref{eq:thm:hilbert} any $x\in I$ is contained in $\pi(IA)$, hence $x = \pi\pa{\sum_{i=1}^mf_ia_i}$ for some $a_i\in A$. Using \cref{lem:V.8} \ref{lem:V.8:2} we get $x = \sum_{i=1}f_i\pi(a_i)$. As $\pi(a_i)\in A^G$ for all $i$ the claim follows.
  
  Now apply \cref{lem:V.7} to $B = A^G$ with $B_+ = \bigoplus_{d\ge0}A_d^G$. Then $A^G$ is finitely generated as a $B_0$-algebra. But $B_0 = A_0^G =A_0 = k1 = k$. Hence $A^G$ is a finitely generated $k$-algebra.
\end{proof}

\subsection{Semisimple rings and algebras}
\begin{deff}
  A ring $R$ (with $1$) is semisimple if it is semisimple as a left mdoule over itself (via the regular action given by left multiplication). In this case $R=\bigoplus_{i\in \Irr(R)}\Iso_L(R)$. An algebra $A$ is semisimple if it is semisimple as a ring.
\end{deff}

\begin{deff}
  A ring $R$ (with $1$) is simple if $R\neq 0$ and $R=\Iso_L(R)$ for some irreducible $R$-module $L$. An algebra is simple if it is simple as a ring.
\end{deff}

\lecture{November 15, 2018}

\paragraph{Remark.} Simple rings are semisimple.

\paragraph{Example.}
\begin{enumerate}
  \item $R=k$ is a simple ring.
  \item Let $G$ finite group and $k$ a field with $\chr k\nmid \abs G$. By \namereff{thm:maschke} $kG$ is a semisimple ring.
  \item Let $R=\Mat nD$ with $n\in\IZ_{>0}$ and $D$ a division algebra. Then $R$ is a simple ring/$k$-algebra.
  \begin{proof}
    For $1\le i\le n$ let \[G = \set*{A\in\Mat nD \given \text{nonzero entries only in $i$-th column}}.\] Then $R=\Mat nD = \bigoplus_{i=1}^nC_i$ as $R$-modules because $E_{ab}E_{ji} = \delta_{jb}E_{ai}$ and $C_i\cong D^n$ as $R$-modules and $C_i\cong D^n$ as $R$-modules by $E_{ji}\mapsto e_j$ (the $j$-th basis vector). Now $D^n$ is an irreducible $R$-module since $R$ acts trasitively on $D^n$ (because then any nonzero submodule is already $D^n$). Thus $R\cong \bigoplus_{i=1}^nL$ with $L\cong D^n$ irreducible, and $R$ is simple.
  \end{proof}
\end{enumerate}

\begin{lem} \label{lem:V.9} % V.5
  Let $R$ be a simple ring. Then $\abs{\Irr(R)} = 1$.
\end{lem}
\begin{proof}
  As $R$ is simple we have $R=\Iso_L(R)$ for some irreducible $R$-module $L$ by definition. Assume that $L'$ is another irreducible $R$-module with $L\ncong L'$. Then pick $0\neq m\in L'$ and obtain a surjective $R$-module homomorphism $R\to L'$ by $1\mapsto m$. Hence we get a nonzero $R$-module homomorphism $\Iso_L(R) \to L'$. Thus there exists a nonzero $R$-module homomorphism $L\to L'$ which is a contradiction to \namereff{lem:schur mod}. We get $L \cong L'$.
\end{proof}

% TODO insert: $D^n$ is the unique (up to isomorphism) irreducible presentation.

\begin{prop} % V.7
  Let $R$ be a semisimple ring and $M$ an $R$-module homomorphism. Then $M$ is semisimple as an $R$-module.
\end{prop}
\begin{proof}
  Let $\set{m_i}_{i\in I}$ be a set of generators of the $R$-module $M$. We get a surjective $R$-module homomorphism
  \begin{eqnarray*}
    \bigoplus_{i\in I}R &\to& M \\
    (0,\ldots,0,1,0,\ldots,0) &\mapsto& m_j.
  \end{eqnarray*}
  Now $R$ is semisimple, and it is also semisimple as a left $R$-module. By \cref{lem:V.2} $\bigoplus_{i\in I} R$ is a semisimple $R$-module and then also the quotient $M$.
\end{proof}

\begin{prop} \label{prop:V.11} % V.8
  Let $R$ be a semisimple ring. Then we can find irreducible $R$-modules $L_i$ with $i\in I$ finite such that \[R \cong \bigoplus_{i\in I}L_i.\]
\end{prop}
\begin{proof}
  As $R$ is a semisimple ring we can find irreducible $R$-modules $L_i$ ($i\in J$) such that $\phi\colon \bigoplus_{i\in J}L_i \to R$ is an isomorphism of $R$-modules. Write $1 = \sum_{i\in J}e_i$ with $e_i\in L_i$ and finitely many $e_i$ nonzero. Let $I=\set{i\in J\given e_i\neq 0}$. Then \[f= \phi\left|_{\bigoplus_{i\in I}}\right.\colon \bigoplus_{i\in I}L_i \to R.\] $f$ is injective (because $\phi$ is) and $1\in\im f$. We get $R1 \subseteq \im f$ because it is an $R$-module homomorphism. Thus $f$ is surjective and an isomorphism.
\end{proof}

\paragraph{Motivation.}
Assume $R$ is a ring and $M$ an $R$-module. Then $M$ is an $R' := \End_R(M)$-module via $f.m = f(m)$ for all $f\in R'$ and $m\in M$. We call $R'$ the \emph{centralizer} of the $R$-action on $M$. What is now the centralizer of the $R'$-action on $M$? By definition we have $R'' = \End_{R'}(M) = \Endd RM$. We are interested in situations where $R'' = R'$ (the \emph{double centralizer property}).

\begin{thm}[Jacobson density theorem I] \label{thm:jacobson density I}
  Let $R$ be a ring with $1$ and $M$ a semisimple $R$-module. Consider the map
  \begin{eqnarray*}
    \Phi\colon R &\to& \Endd RM \\
    r &\mapsto& (m \mapsto rm).
  \end{eqnarray*}
  Then the image of $\Phi$ is \enquote{dense} in the following sense: For all $f\in \Endd RM$ and $m_1,\ldots,m_s\in M$ there exists an $a\in R$ such that $f(m_i) = am_i$ for all $1\le i\le s$.
\end{thm}

\paragraph{Remark.}
\begin{enumerate}
  \item Consider $\Phi\colon R \to \Endd RM \subseteq \Maps(M,M)$ with the discrete topology. Then $\im\Phi$ is dense in $\Endd RM$ in the topological sense.
  \item In the special case $M=R$ (an $R$-module via left multiplication) the \namereff{thm:jacobson density I} gives an isomorphism of algebras
  \begin{center}
    \begin{tikzcd}[column sep=large]
      R\arrow[mapsto]{r}{m\mapsto rm} & \Endd RM\arrow[mapsto]{r}{\id} & \End_RR \arrow[mapsto]{r}{f \mapsto f(1)} & R.
    \end{tikzcd}
  \end{center}
\end{enumerate}

\begin{proof}[Proof of \namereff{thm:jacobson density I}]
  As we have $\Phi(r)(f.m) = \Phi(r)(f(m)) = rf(m) = f(rm) = f.(\Phi(r)(m))$ for all $f\in \End_R(M)$, $m\in M$ and $r\in R$, $\Phi$ is well-defined.
  
  First we assume $s=1$. Let $m=m_1\in M$. Since $M$ is a semisimple $R$-module the submodule $Rm$ has a complement, i.e. $M=Rm \oplus C$ as $R$-modules. Consider $\pi\colon M = Rm \oplus C \to Rm \hookrightarrow R$ by projection. Clearly $\pi\in\End_R(M)$. For any $f\in \Endd RM$ we have $\pi\circ f = f\circ \pi$. Thus $f(m) = f(\pi(m)) = \pi(f(m)) \in Rm$, so there exists an $a\in R$ such that $f(m) = am$.
  
  For the general case let $m_1,\ldots,m_s\in M$ and $f\in \Endd RM$. Define
  \begin{eqnarray*}
    \hat f := \bigoplus_{i=1}^sf\colon M^s &\to& M^s \\
    (n_1,\ldots,n_s) &\mapsto& (f(n_1),\ldots,f(n_s)).
  \end{eqnarray*}
  The reader may check that $\hat f \in \Endd R{M^s}$. Using the case $s=1$ there exists an $a\in R$ such that $\hat f((m_1,\ldots,m_s)) = a(m_1,\ldots,m_s)$. But we also have $\hat f((m_1,\ldots,m_s) = (f(m_1),\ldots,f(m_s))$, so we get $f(m_i) = am_i$ for all $1\le i\le s$.
\end{proof}

\begin{cor} \label{cor:V.13} % V.10
  Let $k$ be a field and $A$ a $k$-algebra with $1$. Let $M$ be a finite-dimensional semisimple $A$-module. Then
  \begin{eqnarray*}
    \Phi\colon A &\to& \Endd AM \\
    a &\mapsto& (m \mapsto am)
  \end{eqnarray*}
  is surjective.
\end{cor}
\begin{proof}
  We have $k\subseteq \End_A(M)$, hence $\Endd AM \subseteq \End_k(M)$. Let $m_1,\ldots,m_s\in M$ be a basis of $M$. For $f\in  \Endd AM$ we find an $a\in A$ such that $f(m_i) = am_i$ for all $1\le i\le s$ by the \namereff{thm:jacobson density I}. Now $f$ is determined on a basis of $M$, and we get $f(m) = am$ for all $m\in M$.
\end{proof}

\begin{thm}[Jacobson density theorem II] \label{thm:jacobson density II} % V.11
  Let $R$ be a ring with $1$ and $N$ a semisimple $R$-module. Let $n_1,\ldots,n_s\in N$ be linearly independent over $\End_R(M)$ and $n_1',\ldots,n_s'\in N$ arbitrary. Then there is an $r\in R$ such that $rn_i = n_i'$ for all $1\le i\le s$.
\end{thm}

\paragraph{Remark.} That means that $N^s$ is generated by $n_1,\ldots,n_s$.

\begin{proof}
  Let $x=(n_1,\ldots,n_s) \in N^s$. Now $N^s$ is semisimple. Hence $Rx$ has a complement in $N^s$, say $N^s = Rx \oplus C$. Consider $\pi\colon N^s \to C \hookrightarrow N^s$ by projection. Clearly $\pi \in \End_r(N^s)$. We can realize $\pi$ as a matrix $A=(a_{ij})\in \Mat s {\End_R(N)}$. Then $a_{i1}n_1 + a_{i2}n_2 + \ldots + a_{is}n_s = 0$ for all $1\le i\le s$ since $\pi(Rx) = 0$. Therefore $a_{ij} = 0$ for all $1\le i,j\le s$ because $n_1,\ldots,n_s$ are linearly independent over $\End_R(N)$. We get $A=0$, $\pi=0$ and $C=0$, so $N^s=Rx$. The claim follows.
\end{proof}

\begin{cor}[Burnside theorem -- coordinate form] % V.12
  Let $k=\ol k$ a field, $V$ a finite-dimensional $k$-vector space and $A\subseteq \End_k(V)$ a subalgebra such that $V$ is an irreducible $A$-module. Then $A = \End_k(V)$.
\end{cor}
\begin{proof}
  We have $\End_k(V) = k$ by \namereff{lem:schur mod}. Now $\Phi\colon A \to \Endd AV = \End_k(V)$ is surjective by the \cref{thm:jacobson density II}, hence an isomorphism.
\end{proof}

\begin{cor}[Burnside theorem -- coordinate free] % V.13
  Let $k=\ol k$ and $A \subseteq \Mat nk$ be a subalgebra such that $k^n$ is irreducible as an $A$-module. Then $A = \Mat nk$.
\end{cor}

\begin{cor} \label{cor:V.17} % V.14
  Let $k=\ol k$, $A$ be a $k$-algebra and $M$ a finite-dimensional $A$-module. Then the following are equivalent:
  \begin{enumerate}
    \item $M$ is an irreducible $A$-module. \label{cor:V.17:1}
    \item $\Phi\colon A \to \Endd AM$ is surjective. \label{cor:V.17:2}
  \end{enumerate}
\end{cor}
\begin{proof}
  \leavevmode
  \begin{description}
    \item[\ref{cor:V.17:1} $\Rightarrow$ \ref{cor:V.17:2}:] By \namereff{lem:schur mod} we have $\End_A(M) = k$, and by the \namereff{thm:jacobson density II} $\Phi$ is surjective.
    \item[\ref{cor:V.17:2} $\Rightarrow$ \ref{cor:V.17:1}:] Let $0\neq m\in M$. For all $m' \in M$ we have an $\phi \in \End_k(M)$ such that $\phi(m) = m'$. Since $\Phi$ is surjective there exists an $a\in A$ with $\Phi(a) = \phi$. Now $m' = \phi(m) = am$, and $M$ is irreducible.
    \qedhere
  \end{description}
\end{proof}

\begin{cor} % V.15
  Let $k=\ol k$, $A$ be a $k$-algebra and $M$ a finite-dimensional irreducible $A$-module. Then $(\dim_kM)^2 \le \dim_kA$.
\end{cor}
\begin{proof}
  This follows from the surjectivity of $A \to \Endd AM = \End_k(M)$ (using \cref{cor:V.17}) because of $\dim_k\End(M) = (\dim_kM)^2$.
\end{proof}

\lecture{November 19, 2018}

\begin{lem} \label{lem:V.19} % V.16
  Let $R_i$ ($1\le i\le n$) be rings (with $1$) and $R := R_1 \times \cdots \times R_n$. Let $1_i$ be the unit in $R_i \subseteq R$ (i.e. $(1_i)_j = \delta_{ij}$). Let $M$ be an $R$-module. Then we have:
  \begin{enumerate}
    \item $1 = \sum_{i=1}^n1_i$ is the unit in $R$.
    \item $1_iM$ is an $R_i$-module via restriction of the $R$-module structure.
    \item $M = \sum_{i=1}^n1_iM$ as $R$-modules where $R$ acts on the right-hand side by \[ (r_1,\ldots,r_n) . \sum_{i=1}^nm_i = \sum_{i=1}^nr_im_i. \] Moreover the sum is direct.
    \item \label{lem:V.19:4} $\displaystyle\End_R(M) = \prod_{i=1}^n \End_R(1_iM)$.
    \item If $M_i$ is an $R_i$-module for $1\le i\le n$ then $\bigoplus_{i=1}^n M_i$ is an $R$-module via \[(r_1,\ldots,r_n).(m_1,\ldots,m_n) = (r_1m_1,\ldots,r_nm_n).\]
    \item \label{lem:V.19:6} $M$ is irreducible if and only if $M = 1_iM$ for some (unique) $1\le i\le n$ and $1_iM$ is irreducible as an $R_i$-module.
    \item $R$ is semisimple if and only if each $R_i$ ($1\le i\le n$) is semisimple.
  \end{enumerate}
\end{lem}
\begin{proof}
  The proof is left to the reader. It is advisable to construct a bijection of sets \[ S_1 \times S_2 \times \cdots \times S_n \xleftrightarrow{1:1} S \] where \[ S_i := \set{\text{$R_i$-submodules of $1_iM$}} \quad\text{and}\quad S_i := \set{\text{$R$-submodules of $M$}}. \qedhere \]
\end{proof}

\newpage

\begin{cor} \label{cor:V.20} % V.17
  Let $R$ be a ring such that \[R \cong \Mat {n_1}{D_1} \times \cdots \times \Mat{n_r}{D_r}\] as rings where $n_i \in \IN$ and the $D_i$ are skew fields. Then $R$ is a semisimple ring. Moreover we have $\abs{\Irr(R)} = r$.
\end{cor}
\begin{proof}
  We saw that $\Mat{n_i}{D_i}$ is a simple ring. Thus it is semisimple, and $R$ is semisimple too.
  
  By \cref{lem:V.9} we have $\abs{\Irr(\Mat{n_i}{D_i})} = 1$ since $\Mat{n_i}{D_i}$ is simple. Due to \cref{lem:V.19} \ref{lem:V.19:6} every irreducible $R$-module is of the form $1_iM$ for some $1\le i\le n$ with $1_i M$ is irreducible as an $\Mat{n_i}{D_i}$-module (where $\Mat{n_i}{D_i}$ acts by zero). This implies $\abs{\Irr(r)} \le r$. It is now enough to show that $1_iM\ncong 1_jM'$ as $R$-modules for $i\neq j$. Assume we have an isomorphism $\phi\colon 1_iM \to 1_j M'$. For all $m\in 1_i M$ we get $\phi(m) = \phi(1_im) = 1_i \phi(m) = 1_i(1_j \phi(m)) = (1_i1_j) \phi(m)$. But $1_i1_j = 0$ as $i \neq j$. Therefore equality holds.
\end{proof}

\subsection{Applicatons of the density theorems}

\begin{prop} \label{prop:V.21} % V.18
  Let $k=\ol k$ be a field and $A$ and $k$-algebra. Assume that $M_1,\ldots,M_s$ are finite-dimensional pairwise non-isomorphic irreducible $A$-modules. Then
  \begin{eqnarray*}
    \hat\Phi\colon A &\to& \bigoplus_{i=1}^s \End_k(M_i) \\
    a &\mapsto& ((m_1,\ldots,m_s) \mapsto (am_1,\ldots,am_s))
  \end{eqnarray*}
  is surjective.
\end{prop}
\begin{proof}
  Clearly $\hat\Phi$ is well defined since multiplication with $a \in A$ is $k$-linear.
  
  Now let $M=\bigoplus_{i\in I}^s M_i$. By \namereff{lem:schur mod} we have
  \begin{eqnarray*}
    \bigoplus_{i=1}^s\End_A(M_i) &\cong& \End_A(M) \\
    (\phi_1,\ldots,\phi_s) &\mapsto& \hat\phi \colon (m_1,\ldots,m_s) \mapsto (\phi_1(m_1),\ldots,\phi_s(m_s)).
  \end{eqnarray*}
  and since $k$ is algebraically closed one has $\End_A(M_i) \cong k$ by $\lambda\id_{M_i} \mapsfrom \lambda$. Thus $End_A(M) = k^s $ as rings where $(\lambda_1,\ldots,\lambda_s)$ acts on $M=\bigoplus_{i=1}^sM_i$ by multiplication. By \cref{cor:V.13} (since $M_i$ and then $M$ are finite-dimensional) we get a surjective map $\Phi\colon A \to \Endd AM$. But as $\End_A(M) = k^s$ and $k^s \cong \prod_{i=1}^s \End_{k}(M_i)$ by \cref{lem:V.19} \ref{lem:V.19:4} we get $\Phi=\hat\Phi$.
\end{proof}

% If $A$ is a finite dimensional $k$-algebra ($k=\ol k$) then we have ????

\begin{prop} \label{prop:V.22} % V.19
  Let $K$ be a field and $A$ be a finite-dimensional $k$-algebra.
  \begin{enumerate}
    \item \label{prop:V.22:1} Any irreducible $A$-module is finite-dimensional.
    \item \label{prop:V.22:2} If $k=\ol k$ then $A$ has only finitely many irreducible $A$-modules up to isomorphism.
  \end{enumerate}
\end{prop}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{prop:V.22:\arabic*}]
   \item If $M$ is an irreducible $A$-module then there exists a surjective $A$-module homorphism $A \to M$. We have $\dim_kM\le\dim_k A <\infty$.
   \item Let $L_i$ ($1\le i\le r$ be pairwise non-isomorphic $A$-modules. As $k=\ol k$ and the $L_i$ are finite-dimensional by \ref{prop:V.22:1} we can apply \cref{prop:V.21} to get a surjection $A \to \bigoplus_{i=1}^r \End_k(L_i)$. But the $\End_k(L_i)$ are finite-dimensional because the $L_i$ are irreducible. We now have a surjection $A \to \bigoplus_{i=1}^r k^{\dim L_i}$. Thus $r \le \dim_k A$, so the number of irreducible $A$-modules (up to isomorphism) is less than $\dim_k A$.
   \qedhere
  \end{enumerate}
\end{proof}

\begin{deff}
  Let $R$ be a ring (not necessarily with $1$). Then $R^{\op}$ denotes the opposite ring (i.e. $R^{\op} = R$ as abelian groups but with multiplication $a \circ_{\op} b = ba$.
\end{deff}

\paragraph{Facts.}
\begin{enumerate}
  \item $R$ is unitary iff $R^{\op}$ is unitary.
  \item $(R^{\op})^{\op} = R$
  \item $R^{\op} = R$ iff $R$ is commutative.
  \item $D$ is a skew field iff $D^{\op}$ is a skew field.
  \item ${\displaystyle \pa{\prod_{i=1}^s R_i}^{\op} = \prod_{i=1}^sR_i^{\op}}$ for rings $R_i$ ($1\le i\le s$).
\end{enumerate}

\begin{lem} \label{lem:V.23} % V.20
  Let $D$ be a skew field and and $n\in\IN$. Then
  \begin{eqnarray*}
    \alpha\colon \Mat nD &\to& (\Mat n{D^{\op}})^{\op} \\
    A &\mapsto& A^T
  \end{eqnarray*}
  is an isomorphism of rings.
\end{lem}
\begin{proof}
  \begin{align*}
    \qedherea
    (\alpha(AB))_{ij} &= ((AB)^T)_{ij} = \sum_{k=1}^na_{jk}b_{ki} \\
    (\alpha(A)_{ij}\alpha(B))_{ij} &= (A^T \circ_{\op} B^T)_{ij} = (B^TA^T)_{ij} = \sum_{k=1}^n b_{ki}\circ_{\op} a_{jk} = \sum_{k=1}^na_{jk}b_{ki}
    \qedhereb
  \end{align*}
\end{proof}

\begin{lem} \label{lem:V.24} % V.21
  Let $R$ be a ring with $1$. Then
  \begin{eqnarray*}
    \Phi\colon \End_R(R) &\cong& R^{\op} \\
    r &\mapsto& (r' \mapsto r'r) \\
    f(1) &\mapsfrom& f.
  \end{eqnarray*}
\end{lem}
\begin{proof}
  Obviously, $\Phi$ is well-defined, has an inverse and is additive. We have to show that $\Phi$ is multiplicative.
  \[ \Phi(r\circ_{\op}s)(x) = \Phi(sr)(x) = x(sr) = \Phi(r)(xs) = (\Phi(r) \circ \Phi(s)(x))(x) \qedhere \]
\end{proof}


\paragraph{Observation.}
Let $D$ be a skew field. By \namereff{lem:schur mod} $\End_{\Mat nD}(D^n)$ ($D^n$ is an irreducible module) is again a skew field. We want to study the connections between the two.

Special cases:
\begin{description}
  \item[$n=1$:] $\End_D(D) \cong D^{\op}$.
  \item[$D=k$:] We get $\End_{\Mat nk}(k^n)\cong k$ by $\lambda\id_{\Mat nk} \mapsfrom \lambda$ because
  \begin{align*}
    \End_{\Mat nk}(k^n) &= \set{f\in\End_k(k^n) \given \forall B \in \Mat nk : A_f B = BA_f} \\
    &\cong \set{A \in \Mat nk \given \forall B \in \Mat nk : A B = BA} \\
    &= \Z(\Mat nk) \cong k.
  \end{align*}

\end{description}


\begin{lem} \label{lem:V.25} % V.22
  Let $D$ be a skew field and $n\in \IN$. Then
  \begin{eqnarray*}
    \Phi\colon D^{\op} &\to& \End_{\Mat nD} (D^{n}) \\
    d &\mapsto& \phi_d \colon \mat{x_1\\\vdots\\x_n} \mapsto \mat{x_1d\\\vdots\\x_nd}
  \end{eqnarray*}
  is an isomorphism of rings.
\end{lem}
\begin{proof}
  Let $\pi_i\colon D^n\to D$ be the projection onto the $i$-th component. $\Phi$ is well-defined as we have \[ \phi_d\pa{A\mat{x_1\\\vdots\\x_n}} = \mat{\pa{\sum_{i=1}^na_{1i}x_i}d\\\vdots\\\pa{\sum_{i=1}^na_{ni}x_i}d} = \mat{\sum_{i=1}^na_{1i}(x_id)\\\vdots\\\sum_{i=1}^na_{ni}(x_id)} = A\phi_d\pa{\mat{x_1\\\vdots\\x_n}}. \]
  Clearly, $\Phi$ is additive. We show that it is multiplicative.
  \begin{align*}
    \Phi(d_1\circ_{\op}d_2)\pa{\mat{x_1\\\vdots\\x_n}} &= \Phi(d_2d_1)\pa{\mat{x_1\\\vdots\\x_n}} = \mat{x_1d_2d_1\\\vdots\\x_nd_2d_1} = (\phi_{d_1}\circ \phi_{d_2})\pa{\mat{x_1\\\vdots\\x_n}}\\ &= (\Phi(d_1)\circ\Phi(d_2))\pa{\mat{x_1\\\vdots\\x_n}}
  \end{align*}
  For injectivity assume that $\Phi(d_1) = \Phi(d_2)$. We get $d_1 = \pi_i(\phi_{d_1}(e_i)) = \pi_i(\phi_{d_2}(e_i)) = d_2$.
  For surjectivity let $f\in \End_{\Mat nD}(D^n)$. Then $f$ is $D$-linear with $D \subseteq \Mat nD$ via $d\mapsto \diag(d,\ldots,d)$. Let $d_i := \pi(f(e_i))$. Then $f(e_i) = f(E_{ij}e_i = d_ie_i$. Now we get \[f\pa{\mat{x_1\\\vdots\\x_n}} = \sum_{i=1}^nf(x_ie_i) = \sum_{i=1}^nx_ie_id_i = \mat{x_id_i\\\vdots\\x_nd_n}.\] But for all $i,j$ we have $d_i = \pi_i(f(e_i)) = \pi_i(f(E_{ij}e_j)) = \pi_i(E_{ij}f(e_j)) = \pi_i(E_{ij}e_jd_j) = d_j$. Thus $f = \Phi(d)$ with $d = d_1 = \ldots = d_n$.
\end{proof}

\begin{thm}[Artin-Wedderburn theorem] \label{thm:aw} % V,23
  Let $R$ be a semisimple ring with $1$. Then there is an isomorphism of rings \[ R \cong \Mat{n_1}{D_1}\times \cdots \times \Mat{n_r}{D_r}\] for some $n_i \in \IN$, $r\in \IN$ and some skew fields $D_i$ ($1\le i\le r$). Moreover the $(n_1,D_1),\ldots,(n_r,D_r)$ are unique up to permutation and isomorphism of skew fields.
\end{thm}

\begin{cor}
  Let $R$ be a semisimple ring. Then $R^{\op}$ is semisimple.
\end{cor}
\begin{proof}
  This follows from the \namereff{thm:aw}, \cref{cor:V.20} and \cref{lem:V.23}.
\end{proof}

\begin{cor}
  Let $A$ be a finite-dimensional semisimple $k$-algebra with $k=\ol k$. Then there exists an isomorphism of $k$-algebras $A\cong \Mat{n_1}{k}\times \ldots \times \Mat{n_r}{k}$ for some $n_i,r\in \IN$.
\end{cor}
\begin{proof}
  By the \namereff{thm:aw} we have $A \cong \Mat {n_1}{D_1} \times\cdots\times \Mat {n_r}{D_r}$ as rings and also as $k$-algebras (we will show this in the proof) for some skew fields $D_i$ and $n_i,r\in\IN$. It is finite-dimensional since $A$ is finite-dimensional. Now $k=\ol k$ implies $D_i = k$ for all $1\le i\le r$.
\end{proof}


\begin{cor} \label{cor:V.29} % V.26
  Let $A$ be a finite-dimensional semisimple $k$-algebra with $k=\ol k$. Then $A$ has finitely many pairwise non-isomorphic left ideals $I_1,\ldots,I_r$ and $A\cong \Mat{n_1}{I_1}\times \ldots \times \Mat{n_r}{I_r}$.
\end{cor}

\lecture{November 22, 2018}

\begin{proof}[Proof of the \namereff{thm:aw}]
  \leavevmode
  \begin{description}
    \item[Existence:] As $R$ is semisimple there exists a finite set $I$ and irreducible $R$-modules $L_i'$ ($i\in I$) such that $R\cong\bigoplus_{i\in I}L_i'$ by \cref{prop:V.11}. We group isomorphic summands and get $R \cong L_i^{\oplus n_1}\oplus \ldots \oplus L_r^{\oplus n_r}$ for irreducible pairwise non-isomorphic $R$-modules $L_i$ and $n_i\in \IN$ (isotypic decomposition).
    
    By \namereff{lem:schur mod} $\End_R(L_i)$ is a skew field. We set $D_i := \End_R(L_i)^{\op}$. Using $\End_R (L_i^{\oplus n_i}) \cong \Mat{n_i}{\End_R(L_i)} \cong \Mat{n_i}{D_i^{\op}}$ (as rings), \cref{lem:V.23} and \cref{lem:V.24} we get
    \begin{align*}
      R & \cong \pa{R^{\op}}^{\op} \cong \pa{\End_R(R)}^{\op} \\
      &\cong \pa{\End_R\pa{L_i^{\oplus n_1}\oplus \ldots \oplus L_r^{\oplus n_r}}}^{\op} \\
      &\cong \pa{\Mat {n_1}{D_i^{\op}}\times \cdots \times \Mat {n_r}{D_i^{\op}}}^{\op} \\
      &\cong \pa{\Mat {n_1}{D_i^{\op}}}^{\op}\times \cdots \times \pa{\Mat {n_r}{D_i^{\op}}}^{\op} \\
      &\cong \Mat{n_1}{D_1}\times \cdots \times \Mat{n_r}{D_r} \tag{1} \label{eq:proof aw 1}
    \end{align*}
    as rings.
    \item[Uniqueness:] Assume \begin{equation}R\cong \Mat{m_1}{C_1}\times\cdots\times \Mat{m_s}{C_s}\tag{2}\label{eq:proof aw}\end{equation} for some skew fields $C_i$ and $m_i,s\in\IN$. By \cref{cor:V.20} we have $r = \abs{\Irr(R)} = s$ and $D_i \cong \End_R(L_i)^{\op}$ (see above) where $\Irr(R) = \set{L_1,\ldots,L_r}$. Now consider \eqref{eq:proof aw}. The irreducible modules are exactly the irreducible $\Mat{m_i}{C_i}$-modules $C_i^{m_i}$ viewed as modules for \eqref{eq:proof aw 1} (use $\Irr(\Mat{m_i}{C_i}) \cong C^{m_i}$). But due to \cref{lem:V.25} we have $\End_{\Mat{m_i}{C_i}}(C_i^{m_i})\cong C_i^{\op}$. Thus there exists a permutation $\sigma\in S_r$ such that $D_i\cong C_{\sigma(i)}$ and also $n_i=m_{\sigma(i)}$ since the dimensions of the irreducible modules agree.
    \qedhere
  \end{description}
\end{proof}

Hence we proved: If $R\cong L_1^{\oplus n_1}\oplus \ldots \oplus L_r^{\oplus n_r}$ with irreducible pairwise non-isomorphic $R$-modules $L_i$ then $\abs{\Irr(R)} = r$ and \[ R \cong \Mat{n_1}{\End_R(L_1)^{\op}}\times\cdots\times \Mat{n_r}{\End_R(L_r)^{\op}}. \]

\paragraph{Remark.} If $R$ is also a finite-dimensional $k$-algebra then $\End_R(L_i)$ is a divison algebra. All involved isomorphisms are linear, hence we get an algebra homomorphism.

\begin{proof}[Proof of \cref{cor:V.29}]
  As $A$ is semisimple there exists an isomorphism $\phi\colon A \cong L_1^{\oplus n_1}\oplus\ldots\oplus L_r^{\oplus n_r}$ where the $L_i$ are irreducible pairwise non-isomorphic $A$-modules ($r$ is finite since $A$ is finite-dimensional). Then $\phi^{-1}(L_i) \subseteq A$ is an $A$-submodule, hence a left ideal $I_i$ of $A$ and $I$ is minimal, since $L_i$ is irreducible. The $I_i$ are pairwise non-isomorphic as the $L_i$ are so. Moreover these must be all minimal ideals (up to isomorphism) since $A = \bigoplus_{i=1}^rI_i^{\oplus n_i}$ and by the \namereff{thm:aw} $A$ has precisely $r$ irreducible representations (up to isomorphism).
\end{proof}

\begin{cor}
  Let $R$ be a simple ring. Then $R\cong \Mat nD$ as rings for some unique $n\in\IN$ and (up to isomorphism) unique skew field $D$.
\end{cor}
\begin{proof}
  As $R$ is simple it is semisimple and $\abs{\Irr(R)} = 1$. Then we apply the \namereff{thm:aw}.
\end{proof}

\subsection{Application: Brauer groups}
\begin{deff}
  A $k$-algebra is \emph{central-simple} if it is a finite-dimensional simple algebra and $\Z(A) = k$.
\end{deff}

\paragraph{Examples.} Consider $A=k$ or $A = \Mat nk$.

\begin{lem}
  Let $A,B$ be finite-dimensional $k$-algebras. Then $\Z(A)\tp \Z(B) = \Z(A\tp B)$ (as subsets of $A\tp B$).
\end{lem}
\begin{proof}
  \leavevmode
  \begin{description}
    \item[\enquote{$\subseteq$}] Clear.
    \item[\enquote{$\supseteq$}] Let $z\in \Z(A\tp B)$. We write $z=\sum_{i=1}^na_i\tp b_i$ where $a_i\in A$, $b_i\in B$ and the $b_i$ are linearly independent. For all $a\in A$ we have \[ az = \sum_{i=1}^n aa_i\tp b_i  = (a\tp 1)z = z(a\tp 1) = \sum_{i=1}^na_ia\tp b_i \] and $aa_i = a_ia$ for all $1\le i\le n$ since the $b_i$ are linearly independent. This implies $a_i\in \Z(A)$ for all $1\le i\le n$, and similarly $b_i\in\Z(B)$ for all $1\le i\le n$. Therefore $z=\sum_{i=1}^na_i\tp b_i \in\Z(A)\tp Z(B)$.
    \qedhere
  \end{description}
\end{proof}

\begin{lem} \label{lem:V.32} % V.29
  Let $A$ and $B$ be central-simple algebras. Then $A \tp B$ is central-simple.
\end{lem}
\begin{proof}
  It is clear that $A \tp B$ is finite dimensional. We have $\Z(A\tp B) = \Z(A)\tp \Z(B) = k\tp k = k$. We still have to show that $A\tp B$ is a simple algebra. It is enough to show that $A\tp B$ is \enquote{simple} (i.e. $0$ and $A\tp B$ are the only two-sided ideals).
  
  Now let $0\ne I \subseteq A\tp B$ be a two-sided ideal. We want to show that $I=A \tp B$. Any $0\neq u \in I$ can be written as $u=\sum_{i=1}^na_i\tp b_i$ where $a_i\in A$, $b_i\in B$ and the $b_i$ are linearly independent. We pick $u$ with a minimal such representation (with respect to $n$). Now $a_i \neq 0$ for all $1\le i\le n$ and $Aa_1A = A$ because $A$ is simple and therefore \enquote{simple}. Hence there exist $c,c'\in A$ with $ca_1c' = 1$. Let $x := (c\tp 1)a(c'\tp1) = \sum_{i=1}^nca_ic'\tp b$ and we have $x = 1\tp b_1 + a_2'\tp b_2 + \ldots + a_n' \tp b_n$ for some $a_i' \in A$. Note that $x\neq 0$ since the $b_i$ are linearly independent. We get \[ (a \tp 1)x - x(a\tp 1) = (aa_2' - a_2'a) \tp b_2 + \ldots + (aa_n' -a_n'a)\tp b_n = 0 \] by assumption for all $a\in A$. Thus $aa_i' -a_i'a = 0$ for all $2\le i\le n$ since the $b_i$ are linearly independent and $a_i' \in \Z(A) = k$ since $A$ is central simple. Now we can write $ x = 1 \tp b$ for some $b\in B$ ($b\neq 0$ as $x\neq 0$). We have $BbB = B$ since $B$ is simple and hence \enquote{simple}. This implies $I \supseteq (1\tp B) x(1 \tp B) = I\tp B$ and $I \supseteq (A \tp 1)(1\tp B) = A\tp B$. Therefore we get $I = A \tp B$.
\end{proof}


\begin{deff}
  Let $A$ and $B$ be central-simple algebras. We call $A$ and $B$ \emph{Brauer equivalent} ($A \sim B$) if $A \cong \Mat nD$ and $B \cong \Mat mC$ with $C \cong D$ as skew fields.
\end{deff}

\begin{deff}
  The \emph{Brauer group} $\Br(k)$ ($k$ a field) has the equivalence classes of $\sim$ as elements. The composition is given by $[A]\circ [B] = [A\tp B]$. The neutral element is $[k]$, and the inverse of $[A]$ is $[A^{\op}]$.
\end{deff}
\begin{proof}[Proof that $\Br(k)$ is indeed a group]
  By \cref{lem:V.32} $A \tp B$ is again central-simple, hence $[A]\circ[B] = [A \tp B]$ is defined. The reader may check that $[A]\circ [B]$ is independent of the choice of the representants.
  
  The composition is commutative ($A \tp B \cong B\tp A$). Thus $\Br(k)$ is abelian.
  
  $k$ is the neutral element, since $[A\tp k] = [A]$.
  
  For the inverse we use the folowing claim: For any finite-dimensional central-simple algebra $A$ with $n = \dim_kA$ we have an isomorphism
  \begin{eqnarray*}
    \gamma\colon A \tp A^{\op} &\cong& \End_k(A) \\
    a \tp b &\mapsto& (x \mapsto axb).
  \end{eqnarray*}
  We check that $\gamma$ is injective. Obviously $\gamma \neq 0$. $\ker\gamma$ is a two-sided ideal (the calculation is left to the reader). But $A$ and $A^{\op}$ and hence $A \tp A^{\op}$ are central-simple, thus $\ker\phi = 0$. As $\dim_k (A\tp A^{\op}) = \dim_k(\End_k(A))$ we get that $\gamma$ is indeed bijective. % TODO insert?
\end{proof}

\paragraph{Examples.}
Let $k$ be an algebraically closed field. By the \namereff{thm:aw} we get $\Br(k) = \set{[k]}$.

Without going into detail one has $\Br(\IR) = \set{[\IR],[\IH]} \cong \fak\IZ{2\IZ}$.

\lecture{November 26, 2018}

\section{The double centralizer theorem}
\begin{deff}
  Let $k$ be a field, $W$ a $k$-vector space and $S \subseteq \End_k(W)$ a subset. Then \[ S' := \set{\phi\in\End_k(W) \given \forall s\in S: \phi\circ s = s\circ \phi}\] is the \emph{commutant} or \emph{centralizer} of $S$ in $\End_k(W)$. We abbreviate $(S')' = S''$ and so on.
\end{deff}

\paragraph{Facts.}
\begin{enumerate}
  \item \label{fact:commutant:1} $S' \subseteq \End_k(W)$ is a subalgebra.
  \item \label{fact:commutant:2} Let $T\subseteq S \subseteq \End_k(W)$ be subsets. Then $S' \subseteq T'$.
  \item \label{fact:commutant:3} $S\subseteq T' \Rightarrow T \subseteq S'$.
  \item \label{fact:commutant:4} $S \subseteq S''$.
  \item \label{fact:commutant:5} $S = S'''$.
  \item \label{fact:commutant:6} $S = T' \Leftrightarrow T = S'$.
\end{enumerate}
\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{fact:commutant:\arabic*}]
    \item[\ref{fact:commutant:1}, \ref{fact:commutant:2}] Clear.
    \setcounter{enumi}{2}
    \item $S \subseteq T' \Leftrightarrow \forall s\in S:\forall t\in T: st = ts \Leftrightarrow \forall t \in T:\forall s\in S st = ts \Leftrightarrow T \subseteq S'$.
    \item $S' \subseteq S'\Rightarrow S \subseteq S''$.
    \item $S' \subseteq (S')'' = S'''$ and $S \subseteq S''$ implies $(S'')' \subseteq S'$.
    \item $S = T' \Rightarrow S'' = (T')'' = T' \Rightarrow T = S'$.
    \qedhere
  \end{enumerate}
\end{proof}

\paragraph{Remark.}
Let $V$ be an $A$-module ($A$ a $k$-algebra) and also a $B$-module ($B$ a $k$-algebra). If the actions of $A$ and $B$ commute (i.e. $ab = ba $ for all $a\in A,b\in B$) where $a\in $ and $b\in B$ denote the corresponding action in $\End_A(V)$ then $V$ is an $A \tp B$-module given by $a\tp b .v = abv = bav$ for all $v\in V$. The reader may check the details.

\begin{lem} \label{lem:VI.1}
  Let $A$ and $B$ be $k$-algebras ($k$ any field), $M$ an $A$-module and $N$ a $B$-module. Then $M\tp N$ is an $A\tp B$-module via $a\tp b . m\tp n = am\tp bn$ for all $m\in M$ and $n\in N$.
\end{lem}
\begin{proof}
  One could do explicit calculations, but we will give a better proof. $M$ being an $A$-modue means a choice of an algebra homomorphism $\phi\colon A \to \End_k(M)$. Similarly we get an algebra homomorphism $\psi\colon B \to \End_k(N)$. Then consider
  \begin{align*}
    \begin{tikzcd}[ampersand replacement=\&]
      A\tp B \arrow{r}{\phi\tp\psi} \arrow[dashed]{rd} \& \End_k(M) \tp \End_k(N) \arrow[Cong]{d}\\
      \& \End_k(M\tp N).
    \end{tikzcd}
    \qedhereb
  \end{align*}
\end{proof}

\paragraph{Example.}
Let $G$ and $H$ be groups with representations $M$ and $N$ over a fixed field $k$, respectively. Note that
\begin{eqnarray*}
  kG \tp kH &\cong& k(G\tp H) \\
  g\tp h &\mapsto& (g,h)
\end{eqnarray*}
as algebras. $M\tp N$ is an $kG\tp kH$-module and hence a representation of $G\tp H$.

\begin{thm}[Double centralizer theorem] \label{thm:dct} % VI.3
  Let $k$ be a field and $W$ a finite-dimensional $k$-vector space. Let $A \subseteq \End_k(W)$ be a subalgebra. Then the following holds:
  \begin{enumerate}
    \item \label{thm:dct:1} $A'$ is a semisimple algebra (a subalgebra of $\End_k(W)$).
    \item \label{thm:dct:2} $A'' = A$.
  \end{enumerate}
  Now let $k$ be algebraically closed.
  \begin{enumerate}
    \setcounter{enumi}2
    \item \label{thm:dct:3} There is a decomposition of $A\tp A'$-modules \[ \Phi\colon W \cong \bigoplus_{i=1}^rL_i\tp L_i'\] (isomorphism as $A\tp A'$-modules) such that $L_1,\ldots,L_r$ are pairwise non-isomorphic irreducible $A$-modules and $L_1',\ldots,L_r'$ are pairwise non-isomorphic irreducible $A'$-modules.
    \item \label{thm:dct:4} The $L_1,\ldots,L_r $ and $L_1',\ldots,L_r'$ are precisely the irreducible $A$-modules and $A'$-modules up to isomorphism. Hence in particular $\abs{\Irr(A)} = \abs{\Irr(A')}$.
  \end{enumerate}
\end{thm}

\paragraph{Remark.}
More generally if $k$ is an arbitrary field we can replace $\Phi$ by $\Phi'\colon W\cong \bigoplus_{i=1}^rL_i\tp_{D_i}L_i'$ for division algebras $D_i := \End_A(L_i)$. Moreover this isomorphism is the isotypic decomposition for $W$ as an $A$-module, but also as an $A'$-module.

\paragraph{Remark.}
Let $A$ be a $k$-algebra, $M$ an $A$-module and $N$ a $k$-vector space. Then \cref{lem:VI.1} gives an $A$-module structure on $M\tp N$ ($A$-modules are $A\tp k$-modules), the \emph{multiplicity space}. Note that $M\tp N \cong M^{\bigoplus \dim N}$ as $A$-modules if $N$ is finite-dimensional. To see this choose bases $\set{m_i}$ of $M$ and $\set{n_i}$ of $N$ and send $m_i\tp n_j$ to $\delta_jm_i$.

\begin{proof}[Proof of the \namereff{thm:dct}]
  As $A$ is a semisimple algebra any $A$-module is semisimple. We get \begin{equation}W\cong\bigoplus_{i=1}^sL_i^{\oplus n_i}\tag{*}\label{eq:dct}\end{equation} for some $n_i,s\in \IN$ and pairwise non-isomorphic irreducible $A$-modules $L_i$.
  \begin{enumerate}[label=\arabic*.]
    \item $s = \abs{\Irr(A)}$.
    
    By the \namereff{thm:aw} we have $A \cong \prod_{i=1}^rR_i$ for some $m\in\IN$ and $R_i \cong \Mat{m_i}{C_i}$ where $C_i$ is a division algebra and the $(m_i,C_i)$ are unique up to permutation and isomorphism of division algebras. Then $\abs{\Irr(A)} = m$ and so $s \le m$ (by definition of $s$). Since $A \subseteq \End_k(W)$ is a subalgebra with have that $1_iW \neq 0$ for any $1\le i \le s$ ($1_i$ is the unit in $R_i$). Therefore $1_iW$ contains an irreducible $R_i$-module. For any irreducible $R_i$-module $U_i$ ($1\le i\le s$) there is an $R$-submodule in $W$ which is isomorphic to $U_i$ as an $R_i$-module. Thus $s=m$ and $\abs{\Irr(A)} = s$.
    \item \label{thm:dct:proof:2} $A'$ is a semisimple algebra and $\abs{\Irr(A')} = \abs{\Irr(A)}$.
    
    Using the \namereff{thm:aw}, \namereff{lem:schur mod} and \eqref{eq:dct} we get an isomorphism of algebras
    \begin{align*} A' &= \set{b\in\End_k(W) \given \forall a \in A\colon ba = ab} = \End_A(W) \\&\cong \prod_{i=1}^s \Mat{n_i}{\End_A(L_i)} = \prod_{i=1}^S \Mat{n_i}{D_i} \end{align*} where $D_i := \End_A(L_i)$ are division algebras. By \cref{cor:V.20} $A'$ is semisimple and $\abs{\Irr(A')} = \abs{\Irr(A)}$.
    \item \label{thm:dct:proof:3} If $U\subseteq W$ is an irreducible $A$-module, then $\Hom_A(U,W)$ is an irreducible $A'$-module with action given by $(\beta.f)(u) = \beta(f(u))$ for $f\in\Hom_A(U,W)$, $\beta\in A'$ and $u\in U$.
    
    This action is well-defined as we have \[(\beta.f).(au) = \beta(f(au)) = \beta(af(u)) = a\beta(f(u)) = a (\beta.f)(u) .\]
    
    For irreducibility it is enough to show that for any nonzero $f_1,f_2 \in\Hom_A(U,W)$ there exists a $\beta\in A'$ such that $\beta .f_1=f_2$. For $0\neq u\in U$ set $v_1 := f_1(u)$ and $v_2 := f_2(u)$. Since $W$ is semisimple we get $W = Av_1 \oplus C$ for some $A$-module $C$. Now define
    \begin{eqnarray*}
      \beta\colon W = Av_1 \oplus C &\to& W \\
      av_1 &\mapsto& v_2 \\
      c &\mapsto& c.
    \end{eqnarray*}
    This is obviously $k$- and $A$-linear, hence $\beta\in A'$. Now $(\beta.f_1)(u) =\beta(f_1(m)) = v_2 = f_2(u)$ and thus $f_1(au) = f_2(au)$ for all $a\in A$ because $\beta$ and $f_1$ are $A$-linear. As $U$ is irreducible we get $\beta f_1 = f_2$.
    \item $L_i' \cong \Hom_A(L_i,W)$ is an irreducible $A'$-module by \ref{thm:dct:proof:3}. Since $L_i$ is a left $D_i$-module, $L_i'$ is a right $D_i$-module and hence a left $D_i^{\op}$-module. Therefore $L_i\tp_{D_i^{\op}}L_i'$ makes sense.
    \item $L_i \tp_{D_i^{\op}} L_i'$ is an $A\tp A'$-module via $(a\tp b) . (m\tp n) = am\tp bn$ for all$m\in M$, $n\in N$, $a\in A$ and $b\in A'$.
    
    If $k$ is algebraically closed then $D_i = k = D_i^{\op}$ and it is clear by \cref{lem:VI.1}. For the general case we have to check that the action is well-defined. Let $\phi\in D_i^{\op}$, $f\in L_i'$, $a\in A$ and $b\in A'$. On the one hand, we have
    \begin{align*}
      (a\tp b)(x\phi \tp f) &= (a\tp b) (\phi(x)\tp f) = a\phi(x) \tp bf, \\
      \intertext{on the other hand, }
      (a\tp b)(x\tp \phi f) &= (a\tp b)(x\tp (f\circ\phi)) = (ax \tp (f\circ\phi)) = ax \tp (bf)(\phi) \\ &= ax \tp \phi . (bf) = ax\tp \tp bf = \phi(ax) \tp bf = a\phi(x) \tp bf.
    \end{align*}
    \item \label{thm:dct:proof:6} The map % TODO r or s???
    \begin{eqnarray*}
      \Phi_i\colon L_i \tp_{D_i^{\op}}L_i' &\to& W \\
      x \tp f &\mapsto& f(x)
    \end{eqnarray*}
    is an $A$-module homomorphism (since $\Phi_i(ax\tp f) = f(ax) = af(x) = a\Phi_i(x\tp f)$. By \namereff{lem:schur mod} we have $\im \Phi_i \subseteq \Iso_{L_i}(W)$. We claim $\im \Phi_i = \Iso_{L_i}(W)$.
    
    Let $f_1,\ldots,f_s$ be a basis of $\Hom_A(_i,W) \cong \bigoplus_{i=1}^s L_i^{\tp n_i}$. Then
    \begin{align*}
      f_i(x) = \begin{cases*} x_i := (0,\ldots,0,x,0,\ldots,0)  & $\substack{\text{if $f_i$ is contained in the $i$-th copy}\\\text{of $L_i' = \bigoplus_{i=1}^{n_i}\Hom_A(L_i,L_i)$,}}$ \\ 0 & otherwise. \end{cases*} \in L_i^{\oplus n_i}
    \end{align*}
    \item \label{thm:dct:proof:7} $\Phi_i$ is injective and we get an isomorphism \begin{eqnarray*} \Phi := \bigoplus_{i=1}^s\Phi_i\colon \bigoplus_{i=1}^sL_i\tp_{D_i^{\op}}L_i' &\to& W \\ x_i \tp f_i &\mapsto& f_i(x_i) \end{eqnarray*} and moreover $\Phi_i$ and $\Phi$ are $A\tp A'$-module homomorphisms.
    
    First, assume that $k$ is algebraically closed. Then by \ref{thm:dct:proof:6} $\Phi_i$ is surjective and we have \[ \dim(L_i \tp L_i') = (\dim L_i)\underbrace{(\dim L_i')}_{n_i} = \dim \underbrace{L_i^{\oplus n_i}}_{\Iso_{L_i}(W)}. \]
    Thus $\Phi_i$ and then $\Phi$ is bijective.
    
    Now let $k$ be arbitrary. By \ref{thm:dct:proof:3} $L_i'$ is an irreducible $A'$-module on $\Mat{n_i}{D_i}$ (see \ref{thm:dct:proof:2} acts non-trivially. We get $L_i' \cong D_i^{n_i}$ as $\Mat{n_i}{D_i}$-modules. In particular one has $L_i\tp_{D_i^{\op}} D_i^{n_i} \cong L_i^{\oplus n_i}$ and we get $\dim (L_i \tp_{D_i^{\op}} D_i^{n_i} = n_i \dim L_i = \dim \Iso_{L_i}(W)$.
    
    We still have to show that $\Phi$ is an homomorphism of $A\tp A'$-modules. It suffices to show that the $\Phi_i$ are $A\tp A'$-module homomorphisms. Let $x_i \in L_i$, $f_i\in L_i'$, $a\in A$ and $b\in A'$. Then
    \begin{align*}
      \Phi_i(a.(x_i\tp f_i)) &= \Phi_i(ax_i \tp f_i) = f_i(ax_i) = af_i(x_i) = a.\Phi_i(x_i\tp f_i) \\ &= \Phi_i(b.(x_i\tp f_i)) = \Phi(x_i\tp bf_i) = (bf_i)(x_i) = b.f_i(x_i) \\&= b.\phi(x_i\tp f_i).
    \end{align*}
    \item $A = A''$.
    
    It is clear that $A \subseteq A''$. As $A$ is semisimple we have $A \cong \prod_{i=1}^s \Mat{m_i}{C_i}$ by the \namereff{thm:aw} for some division algebras $C_i$, $n_i \in\IN$ and $r=\abs{\Irr(A)}$. Also $W \cong \bigoplus_{i=1}^sL_i^{n_i}$ and we get $L_i\cong C_i^{m_i}$ after renumbering. Now
    \begin{align*}
      D_i = \End_A(L_i) \cong \End_{\prod_{j=1}^s\Mat{m_j}{C_j^{m_j}}}\pa{C_i^{m_i}} = \End_{\Mat{m_i}{C_i}}(C_i^{m_i}) = C_i^{\op}.
    \end{align*}
    By \ref{thm:dct:proof:2} one has \[ A' = \prod_{i=1}^s \Mat{n_i}{D_i} \cong \prod_{i=1}^s\Mat{n_i}{C_i^{\op}}. \]
    
    We can now apply the same argument for $A'$ instead of $A$ and get \[ A'' \cong \prod_{i=1}^s\Mat{q_i}{{{(C_i^{\op})}^{\op}}}\quad\text{and}\quad W \cong \bigoplus_{j=1}^s \pa{L_i'}^{q_i} \] as $A$-modules. But by \ref{thm:dct:proof:7} we have \[ W \cong \bigoplus_{i=1}^sL_i\tp_{D_i^{\op}}L_i' \cong \bigoplus_{i=1}^s C_i^{m_i} \tp_{C_i}L_i' \cong \bigoplus_{i=1}^s\pa{L_i'}^{m_i} \] and therefore $a_i = m_i$ for all $1\le i\le s$. Therefore $A \cong A''$, which implies $A = A''$ as they are finite-dimensional and $A \subseteq A''$.
    \qedhere
  \end{enumerate}
\end{proof}

\lecture{November 29, 2018}

\begin{cor}
  Let $G$ and $H$ be finite groups and $k$ an algebraically closed field with $\chr k \nmid \abs G \cdot \abs H$. Then for any two irreducible finite-dimensional representations $V$ of $G$ and $W$ of $H$ we have an irreducible representation $V \tp W$ of $G \times H$ given by $(g,h)(v\tp w) = gv \tp hw$. Every irreducible finite-dimensional representation of $G\times H$ is of this form.
\end{cor}
\begin{proof}
  Consider the algebra homomorphisms $kG \to \End_k(V)$ and $kH \to \End_k(W)$. As $V$ and $W$ are irreducible and finite-dimensional they are surjective. Now
  \begin{center}
    \begin{tikzcd}
      kG \tp kH \arrow[twoheadrightarrow]{r} \arrow[Cong]{d} & \End_k(V) \tp \End_k(W) \arrow[Cong]{d} \\
      k(G\times H) \arrow[twoheadrightarrow]{r} & \End_k(V\tp W).
    \end{tikzcd}
  \end{center}
  Thus $V \tp W$ is an irreducible representation of $G \tp H$. % TODO note?
  
  The converse (to be shown using the \namereff{thm:dct}) is left to the reader.
\end{proof}

\subsection*{Motivation and applications of the next result}
Let $k=\IC$, $V = \IC^2$ and $v_1,v_2$ the standard basis. Consider two actions on $V \tp V$:
\begin{itemize}
  \item Let $G = \GL(V) = \GL_2(\IC)$ act on $V$ in a natural way. Consider the action on $V\tp V$ by $g.(v\tp w) = gv \tp gw$ for $g\in G$ and $v,w\in V$. This yields a group homomorphism
  \begin{eqnarray*}
    \alpha\colon \GL(V) &\to& \GL(V\tp V) \subseteq \End_k(V\tp V) \\
    g &\mapsto& \alpha(g) \colon v\tp w \mapsto gv \tp gw.
  \end{eqnarray*}
  Let $\gen{\GL(\gen v)}$ be the subalgebra of $\End_k(V\tp V$ generated by $\im\alpha = \im(k\GL(V) \to \End_k(V\tp V))$.
  \item Define an action of $S_2 = \set{e,s}$ on $V\tp V$ by $s.(v\tp w) = w\tp v$. Consider the group homomorphism \begin{eqnarray*}\beta\colon S_2 &\to& \GL(V\tp V) \subseteq \End_k(V\tp V).\end{eqnarray*} Let $\gen{S_2}$ be the subalg of $\End_k(V\tp V)$ generated by $\im\beta = \im(kS_2 \to \End_k(V\tp V)$.
\end{itemize}
Note that for $g\in \GL(V)$ we have
\begin{align*}
  (\alpha(g)\circ \beta(s))(v\tp w) &= \alpha(g(w\tp v)) = gw \tp gv = (\beta(s)\circ \alpha(g))(v\tp w).
\end{align*}
and hence $\im\alpha \subseteq (\im\beta)' = \gen{S_2}'$ or $\gen{\GL(V)} \subseteq \gen{S_2}'$. One can show that equality holds.

Decompose $V\tp V$ as a representation of $S_2$.
\[V\tp V = \IC(v_1\tp v_1) \oplus \IC(v_2\tp v_2) \oplus \IC(v_1\tp v_2 + v_2 \tp v_1) \oplus \IC(v_1\tp v_2 - v_2 \tp v_1). \]
The first three summands are isomorphic to $\triv$ (the $1$-dimensional trivial representation) and the last one is isomorphic to $\sign$ (the $1$-dimensional sign representation). Therefore (using multiplicity spaces) \[ V\tp V \cong \triv \oplus \triv \oplus \triv \oplus \sign \cong \triv \tp \,\IC^3 \oplus \sign \tp\, \IC.\]

Decompose $V\tp V$ as a representation of $\GL(V)$. Consider
\begin{align*}
  S^2V &= \pa{\fak{\T(v)}{(v\tp w - w \tp v)}}_2 = \fak{V\tp V}{(v\tp w - w\tp v)}, \\
  \Lambda^2V &= \pa{\fak{\T(v)}{(v\tp w + w \tp v)}}_2 = \fak{V\tp V}{(v\tp w + w\tp v)}.
\end{align*}
One can see \[ S^2V \cong \gen{v_1\tp v_1,v_2\tp v_2,v_1\tp v_2+ v_2\tp v_1} \quad\text{and}\quad \Lambda^2V \cong \gen{v_1\tp v_2 - v_2 \tp v_1} \] as representations of $\GL(V)$.

We get a decomposition of $V\tp V$ as a representation of $S_2 \tp \GL(V)$ (or as $\gen{S_2}\tp \gen{\GL(V)}$-modules) \[ V\tp V \cong \triv \tp\, S^2V \oplus \sign \tp\, \Lambda^2V. \] One can show that $S^2V$ and $\Lambda^2V$ are irreducible representations of $\GL(V)$. Then the above decomposition is the decomposition into isotypic components.

\paragraph{Generalization.}
Let $k$ be any field, $V$ a finite-dimensional $k$-vector space and $d\in\IZ_{\ge0}$. Consider $V^{\tp d}$ as a representation of $\GL(V)$ via $g(v_1\tp\ldots\tp v_d) = gv_1\tp \ldots \tp gv_d$. Let $\alpha\colon \GL(V) \to \GL(V^{\tp d}) \subseteq \End_k(V^{\tp d})$ and $\gen{\GL(v)}$ be the subalgebra generated by $\im\alpha$. $V^{\tp d}$ becomes a representation of $S_d$ via $\sigma(v_1\tp \ldots\tp v_d) = v_{\sigma^{-1}(1)}\tp \ldots\tp v_{\sigma^{-1}(d)}$. Consider the group homomorphism $\beta\colon S_d \to \GL(V^{\tp d}) \subseteq \End_k(V^{\tp d})$ and the subalgebra $\gen{S_d}$ generated by $\im\beta$. For $g\in \GL(V)$ and $\sigma\in S_d$ we obtain
\begin{align*}
  (\alpha(g) \circ \beta(\sigma))(v_1\tp \ldots\tp v_d) = (\beta(\sigma) \circ \alpha(g))(v_1\tp \ldots\tp v_d)
\end{align*}
and thus $\gen{\GL(V)} \subseteq \gen{S_d}'$ and $\gen{S_d}\subseteq \gen{\GL(V)}'$.

\begin{thm}[Schur-Weyl duality] \label{thm:schur weyl}
  Let $k$ be an infinite field, $V$ a finite-dimensional $k$-vector space and $d\in\IZ_{\ge0}$.
  \begin{enumerate}
    \item \label{thm:schur weyl:1} $\End_{S_d}(V^{\tp d}) = \gen{\GL(V)}$.
    \item \label{thm:schur weyl:2} If $\chr k = 0$ or $\chr k > d$ we have $\End_{\GL(V)}(V^{\tp d}) =\gen{S_d}$.
  \end{enumerate}
\end{thm}

\lecture{December 3, 2018}

\paragraph{Remark.}
Assume that $\chr k = 0$ or $\chr k > d$. Then it follows from the \namereff{thm:schur weyl} that the double commutant property holds, as we have $\gen {\GL(V)}'' = \End_{\GL(V)}\pa{V^{\otimes d}}' = \gen{S_d}' = \End_{S_d}(V^{\otimes d})$ and similarly $\gen{S_d}'' = \gen {S_d}$.

\begin{proof}
  \leavevmode
  \begin{enumerate}[label=\ref{thm:schur weyl:\arabic*}]
    \item The isomorphism of isomorphism of vector spaces
    \begin{eqnarray*}
      \Phi\colon \End_k(V)^{\otimes d} &\to& \End_k\pa{V^{\otimes d}} \\
      f_1 \tp \ldots \tp f_d &\mapsto& (v_1 \tp \ldots\tp v_d \mapsto f_1(v_1) \tp \ldots f_d(v_d))
    \end{eqnarray*}
    is $S_d$-equivariant where $S_d$ acts on $\End_k\pa{V^{\otimes d}}$ by $(\sigma f)(x) = \sigma(f(\sigma^{-1}x))$ with $\sigma \in S_d$, $x \in V^{\otimes d}$ and $f\in \End_k\pa{V^{\otimes d}}$ and on $\End_k(V)^{\otimes d}$ by $\sigma (f_1 \tp \ldots \tp f_d) = f_{\sigma^{-1}(1)} \tp \ldots \tp f_{\sigma^{-1}(d)}$. To show this take $\sigma \in S_d$. On the one hand,
    \begin{align*}
      \Phi(\sigma f)(v_1 \tp \ldots \tp v_d) &= \Phi\pa{f_{\sigma^{-1}(1)} \tp \ldots \tp f_{\sigma^{-1}(d)}}(v_1 \tp \ldots \tp v_d) \\ &= f_{\sigma^{-1}(1)}(v_1) \tp \ldots \tp f_{\sigma^{-1}(d)}(v_d), \\\intertext{and on the other hand,}
    (\sigma\Phi(f))(v_1 \tp \ldots \tp v_d) &= \sigma\pa{\Phi(f)(v_{\sigma(1)} \tp \ldots \tp v_{\sigma(d)})} \\ &= \sigma\pa{f_1(v_{\sigma(1)}) \tp \ldots \tp f_d(v_{\sigma(d)})} \\ &= f_{\sigma^{-1}(1)}(v_1) \tp \ldots \tp f_{\sigma^{-1}(d)}(v_d).
    \end{align*}
    \begin{cor}
      $\Phi$ induces an isomorphism of $k$-vector spaces \[\pa{\End_k(V)^{\tp d}}^{S_d} \cong \pa{\End_k\pa{V^{\tp d}}}^{S_d} = \End_{S_d}\pa{V^{\tp d}}.\]
    \end{cor}
    \begin{proof}
      Take invariants for the isomorphism above.
    \end{proof}
    Now $\gen{\GL(V)} \subseteq \End_{S_d}\pa{V^{\tp d}} = S_d'$ by definition since the $\GL(V)$- and the $S_d$-action commute. The image of the map
    \begin{eqnarray*}
      F\colon \GL(V) &\to& \Aut\pa{V^{\tp d}} \subseteq \End_k\pa{V^{\tp d}} \cong \End_k(V)^{\tp d} \\
      \phi &\mapsto& \phi^{\tp d}
    \end{eqnarray*}
    is obviously contained in $\pa{\End_k(V)^{\tp d}}^{S_d}$. It is now enough to see that the image of $\gen{\GL(V)}$ is the whole of $\End_k\pa{V^{\tp d}}^{S_d} = \End_{S_d}\pa{V^{\tp d}}$. Now $E := \End_k\pa{V}$ is a finite-dimensional vector space and $\GL(V) \subseteq E$ is a Zariski-dense subset. Then by \cref{lem:VI.8} we get an isomorphism of vector spaces $\gen{\GL(V)} \cong \pa{\End_k(V)^{\tp d}}^{S_d} \cong \End_{S_d}\pa{V^{\tp d}}$ via $F$ and $\Phi$.
    \item As $\chr k \nmid \abs{S_d} = d!$, $kS_d$ is a semisimple algebra, and $A := \gen{S_d}$ is semisimple (note that $\gen{S_d}$ is a quotient of $kS_d$). By \ref{thm:schur weyl:1} we get $A' = \End_{S_d}\pa{V^{\otimes d}} = \gen{\GL(V)}$. Thus $\End_{\GL(V)}\pa{V^{\otimes d}} = \gen{\GL(V)}' = A'' = A$ be the \namereff{thm:dct}.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{lem} \label{lem:VI.8}
  Let $k$ be an infinite field, $d \ge 1$, $E$ a finite-dimensional vector space and $X \subseteq E$ a Zariski-dense subset (over $k$). Then the vector space $\pa{E^{\tp d}}^{S_d}$ (the vector space of symmetric tensors) is generated as a vector space by the elements $ \set*{x^{\tp d}\given x \in X} \subseteq \pa{E^{\tp d}}^{S_d}$.
\end{lem}
\begin{proof}  
  Let $e_1, \ldots,e_n$ be a basis of $E$. Then $B = \set{e_{i_1} \tp \ldots \tp e_{i_d} \given 1\le i_j \le n }$ is a $k$-basis of $E^{\tp d}$. Obviously $B$ is an invariant subset of $E^{\tp d}$ under $S_d$-action (by permuting the factors). Two vectors from $B$ are in the same $S_d$-orbit if and only if the number of factors equal to $e_i$ agree in the two basis vectors for each $i$. In particular every orbit contains a (unique) element of the form $e^\mu = e_1^{\tp \mu_1} \tp \ldots \tp e_n^{\tp\mu_n}$ for some $\mu=(\mu_1,\ldots,\mu_n)\in \IN_0^n$ with $\sum_{i=1}^n\mu_i = d$. Let $a ^\mu := \sum_{{\omega\in \fak{S_d}{S_{\mu_1}\times \ldots \times S_{\mu _n}}}} \omega (e^\mu)$. It is easy to see that $\set*{a^\mu \given \mu \in \IN_0^n, \sum_{i=1}^n\mu_1 = d}$ forms a basis of $\pa{E^{\tp d}}^{S_d}$.
  
  Let $\Sym := \pa{E^{\tp d}}^{S_d}$ and $U := \set*{x^{\tp d}\given x \in X}$. We have to show that $U = \Sym$.
  \begin{description}
    \item[\enquote{$\subseteq$}] Obvious.
    \item[\enquote{$\supseteq$}] It is enough to show that if $f \colon \Sym \to k$ is $k$-linear then $f|_u = 0$ implies $f = 0$. To see this, assume $U \subsetneq \Sym$ and pick a basis $\set{u_i\given i\in I}$ of $U$ and extend it by $u_j$ ($j\in J$) to a basis of $\Sym$. Then \[ f(u_s) = \begin{cases*}0 & if $s \in I$\\ 1 & if $s \in J$\end{cases*} \] with $s \in I\cup J$ defines a map $\Sym \to k$ such that $f|_U =0$ but $f\neq 0$.
    
    Let now $f\colon \Sym \to k$ be $k$-linear such that $f|_U = 0$. Then $f(x\tp \ldots \tp x) =0$ for all $x \in X$. Write $x = \sum_{i=1}^nx_ie_i$. Then
    \begin{align*}
      x \tp \ldots \tp x &= \sum_{\mathclap{\substack{\mu \in \IN_0^n, \\ \sum_{i=1}^n\mu_i = d}}} x_1^{\mu_1}\cdots x_n^{\mu_n} a^\mu.
    \end{align*}
    Consider $p\in\Ps_k(E)$ defined by \[ p\pa{\sum_{i=1}^ny_ie_i} = \sum_{\mathclap{\substack{\mu \in \IN_0^n, \\ \sum_{i=1}^n\mu_i = d}}} f(a^\mu)y_1^{\mu_1}\cdots y_n^{\mu_n}. \]
    Then in particular
    \begin{align*}
      0 = f(x \tp \ldots \tp x) = \sum_{\mathclap{\substack{\mu \in \IN_0^n, \\ \sum_{i=1}^n\mu_i = d}}} f\pa{x_1^{\mu_1}\cdots x_n^{\mu_n}a^\mu} = \sum_{\mathclap{\substack{\mu \in \IN_0^n, \\ \sum_{i=1}^n\mu_i = d}}} f(a^\mu)x_1^{\mu_1}\cdots x_n^{\mu_n} = p(x).
    \end{align*}
    Therefore $p(x) = 0$ for all $x\in X$, and $p=0$ (as an element in $\Ps_k(E)$). This implies $f(a^\mu) = 0$ for all $\mu \in \IN_0^n$ with $\sum_{i=1}^n\mu_i = d$. Thus $f = 0$ since the $a^\mu$ form a basis of $\Sym$.
    \qedhere
  \end{description}
\end{proof}

\begin{cor}
  Let $k$ be a field of $\chr = 0$ (in particular $\abs k =\infty$). Let $V$ be a finite-dimensional $k$-vector space and $d \in \IN$. Then $V^{\tp d}$ is a representation of $S_d \times \GL(V)$ and we have a decomposition of representations of $S_d \times \GL(V)$ \[V^{\tp d} \cong \bigoplus_{\lambda \in \Lambda}S_\lambda L(\lambda) \] where $S_\lambda$ are the pariwise non-isomorphic representations of $S_d$ and the $L(\lambda)$ are the pariwise non-isomorphic representations of $\GL(V)$ for some labelling set $\Lambda$. If $\dim V \ge d$ then $\set{S_\lambda \given \lambda \in \Lambda} =\Irr(S_d)$. 
\end{cor}
\begin{proof}
  The \namereff{thm:dct} and the \namereff{thm:schur weyl} imply all statements except of the last one by applying \cref{lem:VI.10} to $kS_d \to \gen{S_d}$ and $k\GL(V) \to \gen{\GL(V)}$.
  
  For the last statement assume $\dim_kV \ge d$. Then we can pick a basis $e_1,\ldots,e_n$ of $V$ ($n \ge d$). Then
  \begin{eqnarray*}
    \beta \colon kS_d &\to& \End_k\pa{V^{\tp d}} \\
    g &\mapsto& \pa{v_1 \tp \ldots v_d \mapsto v_{g^{-1}(1)} \tp \ldots \tp v_{g^{-1}(d)}}
  \end{eqnarray*}
  is injective since the action of $\sum_{g\in S_d} a_g g \in kS_d$ on $e_1 \tp \ldots \tp e_d$ is given by $\sum_{g \in S_d} a_ge_{g^{-1}(1)} \tp \ldots e_{g^{-1}(d)}$ and the summands are linearly independent. Thus  $kS_d\subseteq \End_k(V^{\tp d})$ is a subalgebra. Hence the assumptions of the \namereff{thm:dct} hold for $A = kS_d$ and we get $\set{S_\lambda\given \lambda\in\Lambda} = \Irr(S_d)$ (Specht modules). % \im \beta??
\end{proof}

\begin{lem} \label{lem:VI.10}
  Let $\gamma\colon A \to B$ be a surjective algebra homomorphisms over a field $k$. If $M$ is an irreducible $B$-module then it is also an irreducible $A$-module by pulling back the action via $\gamma$.
\end{lem}
\begin{proof}
  If $M$ has no proper $B$-submodule then it has also no proper $A$-submodule because $\gamma$ is surjective.
\end{proof}

\paragraph{Problem.}
We want to describe the labelling set of irreducible representations of $S_d$ (up to isomorphism)

\begin{deff}
  Let $k$ be a field and $A$ a $k$-algebra.
  \begin{itemize}
    \item $[A,A] := \gen{\set{ab-ba\given a,b\in A}} \subseteq A$.
    \item If $V$ is a finite-dimensional $A$-module then its \emph{character} $\chi_V$ is defined as
    \begin{eqnarray*}
      \chi_V \colon A &\to& k \\
      a &\mapsto& \Tr(\pi_a)
    \end{eqnarray*}
    where $\pi_a\colon V\to V, v\mapsto av$.
  \end{itemize}
\end{deff}

\begin{thm} \label{thm:VI.10}
  Let $k$ be an algebraically closed field and $A$ a $k$-algebra.
  \begin{enumerate}
    \item \label{thm:VI.10:1} If $V_i$ ($i\in I$) are pairwise non-isomorphic finite-dimensional irreducible $A$-modules then $\chi_{V_i}\colon A \to k$ ($i\in I$) define linearly independent elements in $\pa{\fak A{[A,A]}}^*$.
    \item \label{thm:VI.10:2} If $A$ is a finite-dimensional semisimple algebra then the characters $\chi_V$ for $V \in \Irr(A)$ form a basis of $\pa{\fak A{[A,A]}}^*$.
  \end{enumerate}
\end{thm}

A special case is
\begin{thm}
  Let $k$ be an algebraically closed field with $\chr k = 0$ and $G$ a finite group.
  \begin{itemize}
    \item $\abs{\Irr(kG)}$ is the number of conjugacy classes of $G$.
    \item $\abs{\Irr(kG)} = \dim \Z(kG)$.
  \end{itemize}
\end{thm}

Consider the special special case $G = S_d$. Then $g,h \in S_d$ are in the same conjugacy class iff $g$ and $h$ have the same cycle type. Hence
\[
  \set{\text{cycle types of $S_d$}} \xlongleftrightarrow{1:1} \set{\text{partitions of $d$}} \xlongleftrightarrow{1:1} \Irr(S_d).
\]

\begin{proof}[Proof of \cref{thm:VI.10}]
  \leavevmode
  \begin{enumerate}[label=\ref{thm:VI.10:\arabic*}]
    \item If $V$ is a finite-dimensional irreducible $A$-module then $\chi_V(ab-ba) = \Tr(\pi_a\pi_b - \pi_b\pi_a) = 0$. Therefore $\chi_V$ factors through $[A,A]$ and $\chi_V$ induces an element in $\pa{\fak A{[A,A]}}^*$.
    
    Let $\sum_{i\in J}\lambda_{V_i}\chi_{V_i} = 0$ with $J \subseteq I $ finite. By \cref{prop:V.21}
    \begin{eqnarray*}
      A &\to& \sum_{i\in J}\End_k(V_i) \\
      a&\mapsto& \pa{(v_i)_{i\in J} \mapsto (av_i)_{i\in J} }
    \end{eqnarray*}
    is surjective. In particular the identity $1_j \in \End_k(V_j)$ has a preimage $a_j \in A$ for all $j\in J$. Hence \[0 = \sum_{i\in J}\lambda_{V_i} \chi_{V_i}(a_j) = \lambda_{V_j} \underbrace{\dim V_j}_{\neq 0} \] and thereore $\lambda_{V_j} = 0$ for all $j \in J$.
    \item Left to the reader.
    \qedhere
  \end{enumerate}
\end{proof}


\lecture{December 6, 2018}

\newpage
\part*{Algebraic groups}

\paragraph{Motivation.}
If $G$ is a finite group then $G$ is a subgroup of some permutation group $S_n$ (e.g. $n = \abs G$). We want to generalize this by replacing $S_n$ with $\GL_n(\IR)$ and finite groups by compact subgroups of $\GL_n(\IR) \subseteq \IR^{n^2}$.

\section{Linear algebraic groups and affine algebraic groups}

\paragraph{Fact.}
Let $K\subseteq \GL_n(\IR)$ be a compact subgroup. Then there exist $f_1,\ldots,f_s \in k[X_{11},\ldots,X_{nn}]$ such that $K = \set{A\in\GL_n(\IR) \given \forall 1\le i\le s : f_i(A) = 0 }$.

\medskip

For example $\OO_n(\IR) = \set{A \in \GL_n(\IR) \given A^TA = 1 = AA^T}$.

\medskip

Warning: The converse is not true, e.g. \[ \SL_2(\IR) = \set{A \in \GL_2(\IR) \given \det A = 1} = \set*{\mat{a&b\\c&c} \in \GL_2(\IR) \given ad-bc-1=0}. \]

\paragraph{Convention.} From now on, let $k$ be an algebraically closed field.

\begin{deff}
  A \emph{linear algebraic group} $G$ (over $k$) is a subgroup of $\GL_n(k)$ which is the common zero set of a set $M$ of polynomials in $k[X_{11},\ldots,X_{nn}]$, i.e. \[ G = \set{A \in \GL_n(k) \given \forall f\in M : f(A) = 0 } .\]
\end{deff}

\paragraph{Examples.}
\begin{enumerate}
  \item $\GL_n(k)$ is the zero set of the zero polynomial.
  \item $\SL_n(k) = \set{A \in \GL_n(k) \given \det(A) - 1 = 0}$.
  \item Finite subgroups of $\GL_n(k)$.
  \item Diagonal matrices in $\GL_n(k)$, as we can write them as $\set{A\in \GL_n(k) \given \forall 1\le i \neq j\le n : P_{ij}(A) = 0}$ with $P_{ij}(X_{11},\ldots,X_{nn}) = X_{ij}$.
  \item Uper triangular matrices in $\GL_n(k)$. More generally \emph{standard parabolic subgroups}. % TODO insert def
  \item The orthogonal group $\OO_n(k) = \set{A \in \GL_n(k) \given A^T = 1_n=AA^T}$.
  \item Symplectic groups \[ \Sp_{2n} = \set{A \in \GL_{2n}(k) \given A^TJA = J } \quad\text{with}\quad  J = \mat{0& E_n \\ -E_n & 0} \]
  \item Intersections of linear algebraic groups are again linear algebraic.
\end{enumerate}

We now want for instance that $\GL_1(k) = k^\times $ is isomorphic to \[ \set*{\mat{a&0\\0&1}\given a \in k^\times} \subseteq \GL_2(k). \]

\begin{deff}
  An \emph{affine algebraic group} (over $k$) is an affine algebraic variety $(G,k[G])$ (over $k$) together with a group structure such that
  \begin{xalignat*}{2}
    \mu\colon G \times G &\to G & \qquad \inv\colon G &\to G \\
    (g,h) &\mapsto gh & \qquad g &\mapsto g^{-1}
  \end{xalignat*}
  are morphisms of affine algebraic varieties.
\end{deff}

\begin{deff}
  An \emph{affine algebraic variety} (over $k$) is a pair $(X,k[X])$ where
  \begin{itemize}
    \item $X$ is a set and
    \item $k[X]$, the \emph{algebra of regular functions}, is a finitely generated subalgebra of $\Maps(X,k)$ such that
      \begin{eqnarray*}
        \Phi\colon X &\to& \Hom_{\Alg}(k[X],k) \\
        x &\mapsto& \ev_x
      \end{eqnarray*}
      is bijective. Here, \enquote{subalgebra} means a subalgebra with $1$, elements in $\Hom_{\Alg}(k[X],k)$ send $1$ to $1$, and $\ev_x$ is the evaluation at $x$.
  \end{itemize}
\end{deff}

\paragraph{Examples.}
\begin{enumerate}
  \item Consider $X = k^n$ and $k[X] := k[X_1,\ldots,X_n]$ identified with the subalgebra $\Ps_k(k^n) \subseteq \Maps(k^n,k)$. We want to show that $(X,k[X])$ is an affine variety, the affine space of dimension $n$.
  \begin{proof}
    Obviously $k[X]$ is finitely generated. The map
    \begin{eqnarray*}
      \Phi\colon X &\to& \Hom_{\Alg}(k[X_1,\ldots,X_n],k) \\
      y &\mapsto& \ev_y
    \end{eqnarray*}
    is a bijection by \textsc{Hilbert's Nullstellensatz} as we have
    \begin{center}
      \begin{tikzcd}
        \set{\text{points in $X=k^n$}} \arrow[leftrightarrow]{d}{1\,\mbox{\scriptsize :}\,1}[swap]{\beta} \arrow[leftrightarrow]{r}{1\,\mbox{\scriptsize :}\,1} &  \arrow[leftrightarrow]{d}{1\,\mbox{\scriptsize :}\,1}[swap]{k = \ol k}\set{\text{maximal ideals in $k[X_1,\ldots,X_n]$}} \\
        \set*{\substack{\text{algebra homomorphisms}\\ k[X_1,\ldots,X_n] \to k}} \arrow[leftrightarrow]{r}{1\,\mbox{\scriptsize :}\,1}  & \set*{\substack{\text{kernels of algebra homomorphisms}\\ k[X_1,\ldots,X_n] \to k}}
      \end{tikzcd}
    \end{center}
    with $\beta$ given by $y \mapsto \ev_y$.
  \end{proof}
  \item $X = \point$ and $k[X] = \Maps(X,k) = \Maps(\point,k) = k$. Obviously $k$ is a finitely generated subalgebra of $k = \Maps(\point,k)$ and $\Phi\colon\point \to \Hom_{\Alg}(k[X],k)$ is a bijection.
  \item $X$ a finite set and $k[X] = \Maps(X,k)$. Then $(X,k[X])$ is an affine algebraic variety.
  \item Let $\aav X$ be an affine algebraic variety. Consider a subset $M\subseteq k[X]$ and define the \emph{vanishing set} of $M$ by \[ \Vs(M) := \set{x\in X \given \forall f\in M : f(x) = 0} \] and set $k[\Vs(M)] = k[X]|_{\Vs(M)}$. We want to show that $\aav {\Vs(M)}$ is an affine algebraic variety.
  \begin{proof}
    We have a restriction map $\res\colon k[X]\to k[\Vs(M)]$ which is obviously an surjective algebra homomorphism by definition. By assumption $k[X]$ is finitely generated, and thus its quotient $k[\Vs(M)]$ is a finitely generated subalgebra.

    It is left to show that
    \begin{eqnarray*}
      \tilde\Phi\colon \Vs(M) &\to& \Hom_{\Alg}(k[\Vs(M)],k) \\
      x &\mapsto& \ev_x
    \end{eqnarray*}
    is bijective.

    If $f\colon k[\Vs(M)] \to k$ is an algebra homomorphism then
    \[
      \begin{tikzcd}
        k[X] \arrow{r}{\res} \arrow[dashed]{dr}[swap]{\tilde f} & \arrow{d}{f} k[\Vs(M)] \\
        & k
      \end{tikzcd}
    \]
    defines an algebra homomorphism $\tilde f = f \circ \res$. In particular we have $\tilde f = \ev_x$ for some $x\in X$ because $\aav X$ is an affine algebraic variety.

    For injectivity let $x,y\in \Vs(M)$ with $\ev_x = ev_y\colon k[\Vs(M)] \to k$. Then $\tilde\ev_x = \tilde\ev_y$. But $\tilde\ev_x$ must be $\ev_x\colon k[X] \to k$, and the same holds for $\tilde\ev_y$. Thus $\ev_x = \ev_y \colon k[X] \to k$, and as $\Phi$ is bijective, we get $x = y$.

    For surjectivity let $h\in \Hom_{\Alg}(k[\Vs(M)],k)$. Define $\tilde h := h \circ \res$, and we have $\tilde h = \ev_x$ for some $x\in X$.
    \begin{description}
      \item[$x \in \Vs(M)$:] For $f\in k[\Vs(M)]$ pick $f' \in k[X]$ such that $f'|_{\Vs(M)} = f$. Then $\ev_x(f) = f(x)$ and $h(f) = h(\res(f)) = \tilde h (f) = \ev_x(f) = f(x)$ for all $f\in k[\Vs(M)]$. Thus $\ev_x = h$.
      \item[$x\notin \Vs(M)$:] Then there exists an $f\in M \subseteq k[X]$ with $g(x) \neq 0$ but $g|_{\Vs(M)} = 0$. Now consider
        \[
          \begin{tikzcd}
            k[X] \arrow{r}{\res} \arrow{dr}[swap]{\ev_x} & \arrow{d}{h} k[\Vs(M)] \\
            & k
          \end{tikzcd}
        \]
        and we get $g \mapsto \res(g) = 0 \mapsto h(0) = 0$ and $g \mapsto \ev_x(g) = g(x) \neq 0$ which is a contradiction.
    \end{description}
    Thus any $h\in \Hom_{\Alg}(k[X], k)$ has a preimage.
  \end{proof}
  \item Let $\aav X$ be an affine algebraic variety and $f\in k[X]$. Define $X_f := \set{x \in X \given f(x) \neq 0}$ and $k[X_f] := k[X]|_{X_f}\br{f^{-1}}$ (localisation at $f$). Then $\aav {X_f}$ is an affine algebraic variety.
\end{enumerate}
As a consequence every linear algebraic group is an affine algebraic group. % TODO d) e)

\begin{prop}
  Given a linear algebraic group $X = G$ (over $k$) we can find some $k[X]$ such that $(X,k[X])$ is an affine algebraic variety.
\end{prop}
\begin{proof}
  Consider $Y = k^{n^2} = \Mat nk$. Now $\aav Y$ with $k[Y] = k[X_{11},\ldots,X_{nn}]$ and $\GL_n(k) \subseteq Y$ with $k[\GL_n(k)] = k[X_{\det}]$ are affine algebraic varieties. Thus $(\Vs(M) = G, k[\Vs(M)] = k[G])$ is an affine algebraic variety.
\end{proof}

\begin{deff}
  Let $\aav X$ and $\aav Y$ be affine algebraic varieties. A \emph{morphism} (of affine algebraic varieties) from $\aav X$ to $\aav Y$ is a map $f\colon X \to Y$ such that $f^*\colon k[Y] \to k[X]$ where 
  \begin{eqnarray*}
    f^*\colon k[Y] \subseteq \Maps(Y,k) &\to& \Maps(X,k) \\
    h &\mapsto & h \circ f.
  \end{eqnarray*}
  If $\im f^* \subseteq k[X]$ we also write $f^\natural$. Hence a morphism is a pair $(f,f^\natural)$.
\end{deff}

\paragraph{Warning.} Consider $k =\ol{\IF_p}$ and the Frobenius map $\Fr\colon k \to k$. Then $\Fr$ is a morphism $\aav k$ which is bijective, but not an isomorphism.

\lecture{December 10, 2018}

\begin{lem} \label{lem:VII.2}
  There is a bijection
  \begin{eqnarray*}
    \set*{\substack{\text{morphisms of affine}\\\text{algebraic varieties}\\ f\colon (X,k[X]) \to (Y,k[Y]) }} & \xlongleftrightarrow{1:1} & \set*{\substack{\text{algebra homomorphisms}\\ k[Y]\to k[X]}} \\
    (f,f^\natural) &\mapsto& f^* = f^\natural \\
    (\phi_g \colon X \to Y ,\phi_g^*) &\mapsfrom& g
  \end{eqnarray*}
  where $\phi_g(x) \in Y$ for $x \in X$ such that
  \[
    \begin{tikzcd}
      k[Y] \arrow[dashed]{dr}[swap]{\ev_{\phi_g(x)}}\arrow{r}{g} & k[X] \arrow{d}{\ev_x} \\
      & k
    \end{tikzcd}
  \]
  commutes. The bijection is compatible with composition and the identities are mapped to each other.
\end{lem}

\paragraph{Notation.} We denote \[\Hom_{\Var}(X,Y) = \set*{f\colon \aav X \to \aav Y \given \substack{\text{$f$ is a morphism of}\\\text{affine algebraic varieties}}}.\]

\paragraph{Remark.}
Behind \cref{lem:VII.2} is an equivalence of categories
\begin{eqnarray*}
  \set*{\substack{\text{affine algebraic varieties}\\\text{over $k$ with morphisms}}} &\xlongleftrightarrow{1:1}& \set*{\substack{\text{finitely generated $k$-algebras}\\\text{without nilpotent elements}}} \\
  \aav X &\mapsto& k[X] \\
  (f,f^\natural) &\mapsto& f^* = f^\natural
\end{eqnarray*}
identifying $\Hom_{\Var}(X,Y)$ with $\Hom_{\Alg}(k[Y],k[X])$.

\begin{proof}[Proof of \cref{lem:VII.2}]
  We show that the maps are inverse to each other.
  \begin{description}
    \item[$(f,f^\natural)\mapsto f^\natural \mapsto \phi_{f^\natural}$:] Let $h\in k[Y]$ and $x \in X$. Then we have
    \begin{align*}
      \ev_{\phi^\natural(x)}(h) = \ev_x \circ f^\natural(h) = \ev_x \circ f^*(h) = ev_x(h\circ f) = (h \circ f)(x) = \ev_{f(x)}(h)
    \end{align*}
    which yields $\ev_{\phi_{f^\natural}(x)} = \ev_{f(x)}$ and $\phi_{f^\natural}(x) = f(x)$ as $\aav Y$ is an affine algebraic variety. Thus $f^\natural = f$.
  \item[$g \mapsto \phi_g \mapsto \phi_g^*$:] Let $h \in K[Y]$ and $x \in X$. We get \[ \phi_g^*(h)(x) = (h\circ \phi_g)(x) = \ev_{\phi_g(x)}(h) = \ev_x(g(h)) = g(h)(x) = \phi_{g}^*(h) = g(h) \] and therefore $\phi_g^* = g$ (in particular also $\phi_g^* \colon k[Y] \to k[X]$, so $\phi_g^* = \phi_g^\natural$ and the inverse map is well-defined).
  \end{description}
  The compatibility with composition and identity maps is obvious.
\end{proof}

\begin{thm}
  Every affine algebraic variety is isomorphic to some $\aav{\Vs(M)}$ where $M\subseteq k[T_1,\ldots,T_n]$.
\end{thm}
\begin{proof}
  Let $\aav X$ be an affine algebraic variety. Then $k[X]$ is a finitely generated commutative $k$-algebra. Let $a_1,\ldots,a_n$ be generators. Then there exists a surjective algebra homomorphism $\pi\colon k[T_1,\ldots,T_n]$ sending $T_i$ to $a_i$. Now define
  \begin{eqnarray*}
    f\colon X &\to& k^* \\
    x &\mapsto& (\pi(T_1)(x),\ldots,\pi(T_n)(x)).
  \end{eqnarray*}
  We get $f^* = \pi$ (with $k[k^n] = k[T_1,\ldots,T_n]$) as we have $f^*(T_i)(x) = T_i(f(x)) = \pi(T_i)(x) =$ for all $x\in X$ and $1\le i\le n$ and both $f^*$ and $\pi$ are algebra homomorphisms.

  Let $M = \ker\pi$. Hence $\im f \subseteq \Vs(M)$, as we have $\phi(f(x)) = f^*(\phi)(x) = \pi(\phi)(x) = 0$ for $\phi \in M = \ker\pi$ and $x \in X$. Note that $\sqrt{\ker\pi} = \ker\pi$ (since $p^r \in \ker\pi \Leftrightarrow \pi(p^r) = 0 \Leftrightarrow (\pi(p))^r = 0 \Leftrightarrow \pi(p) = 0$).

  We have a surjective algebra homomorphism
  \begin{eqnarray*}
    k[T_1,\ldots,T_n] &\to& k[\Vs(M)] \\
    f &\mapsto& f|_{\Vs(M)}
  \end{eqnarray*}
  with the kernel
  \begin{align*}
    \Is(\Vs(M)) = \set{f\in k[T_1,\ldots,T_n]\given \forall x \in \Vs(M): f(x) = 0} = \sqrt{M} = \sqrt{\ker\pi} = M
  \end{align*}
  using Hilbert's Nullstellensatz. Hence $k[\Vs(M)] = \fak{k[T_1,\ldots,T_n]}M = \fak{k[T_1,\ldots,T_n}{\ker\pi}$, and $(f,f^\natural)$ defines an isomorphism $\aav X \to \aav{\Vs(M)}$ using \cref{lem:VII.2}.
\end{proof}

\paragraph{Consequence.}
Let $\aav X$ be an affine algebraic variety. Via this identification $X$ is a topological space with the Zariski topology. One can show that this is independent (up to isomorphism of topological spaces) from the chosen realisation.

\begin{lem}
  Every morphism of affine algebraic varieties is continuous.
\end{lem}
\begin{proof}
  Let $f\colon \aav X \to \aav Y$ be a morphism. We have to show that the preimages of closed subset are closed. Let $Z\subseteq Y$ be closed. Then $Z = \Vs(N) \cap Y$ for some subset of polynomials $N$.  Now
  \begin{align*}
    f^{-1}(Z) &= \set{x\in X \given f(x) \in \Vs(N)} = \set{x\in X \given \forall\phi\in N:\phi(f(x)) = 0} \\&= \set{x\in X \given \forall \phi\in N:f^*(\phi)(x) = 0} = \set{x\in X \given x \in \Vs(f^*(N)) }.
  \end{align*}
  Using $f^* = f^\natural$ we get $f^*(N) \subseteq k[X] = k[T_1,\ldots,T_n]|_{\Vs(M)}$ and thus $f^{-1}(Z) = \Vs(f^*(N)) \cap X$ is closed.
\end{proof}

\section{Products and Hopf algebras}
\paragraph{Goal.}
We are interested in relations between linear algebraic groups and affine algebraic groups as affine algebraic varieties. % TODO why product?

\begin{deff}
  Let $\aav{X_i}$ for $i\in I=\set{1,2}$ be affine algebraic varieties. Then let \[ \aav{X_1\dotcup x_2} \quad\text{with}\quad k[X_1\dotcup X_2] := \set{f\colon X_1 \dotcup X_2 \to k \given \forall i \in I : f|_{X_i} \in k[X_i]} \] be the \emph{coproduct} of $\aav{X_1}$ and $\aav{X_2}$ and \[ \aav{X_1\times X_2} \quad\text{with}\quad k[X_1\times X_2] := \gen{\bigcup_{i\in I}\im \pa{\left.p_i^*\right|_{k[X_i]}}} \subseteq \Maps(X_1\times X_2, k)  \] the \emph{product} where $p_i\colon X_1\times X_2 \to X_i$ are the canonical projections.
\end{deff}

\begin{prop}
  Let $\aav {X_i}$ for $i\in I=\set{1,2}$ be affine algebraic varieties.
  \begin{enumerate}
    \setcounter{enumi}{-1}
    \item \label{prop:VIII.1:0} The (co)product is an affine algebraic variety and satisfies the following universal properties for any affine algebraic variety $\aav Z$.
    \item \label{prop:VIII.1:1} If $f_i \in \Hom_{\Var}(X_i,Z)$ then there exists a unique $h\in \Hom_{\Var}(X_1\dotcup X_2, Z)$ such that
    \[\begin{tikzcd}
        X_1 \arrow[hookrightarrow]{r}{\incl_1} \arrow{dr}[swap]{f_1} & X_1 \dotcup X_2 \arrow[dashed]{d}{\exists!h} & X_2 \arrow[hookrightarrow]{l}[swap]{\incl_2} \arrow{dl}{f_2}  \\
        & Z
    \end{tikzcd}\]
  commutes.
  \item \label{prop:VIII.1:2} If $f_i \in \Hom_{\Var}(Z,X_i)$ then there exists a unique $h\in \Hom_{\Var}( Z,X_1\times X_2)$ such that
    \[\begin{tikzcd}
        X_1   & \arrow[twoheadrightarrow]{l}[swap]{p_1} X_1 \times X_2  \arrow[twoheadrightarrow]{r}{p_2}& X_2   \\
        & Z \arrow{ul}{f_1}\arrow{ur}[swap]{f_2} \arrow[dashed]{u}{\exists!h}
    \end{tikzcd}\]
    commutes.
  \end{enumerate}
\end{prop}

\end{otherlanguage}
\end{document}
